
Recent advances in Artificial Intelligence (AI), particularly deep learning, are having an enormous impact on
our society today. Record numbers of jobs previously held by people have been automated, from manufacturing to transportation to customer services. The concerns of AI replacing humans by taking over people’s
jobs need to be urgently addressed. This article investigates some promising different directions of AI development: Instead of using AI to replace people, we should use AI to team up with people so that both
can work better and smarter. Human–AI symbiosis refers to people and AI working together to jointly solve
problems and perform specific tasks. The recent developments in deep learning models and frameworks have
significantly improved the efficiency and performance of human and AI collaborations. In this article, some
research work on human–AI collaborative environments has been extensively studied and analyzed to reveal
the progress in this field. Although the teaming of humans and machines includes many complex tasks, the
development has been very promising. One of the main goals in this field is to develop additional capabilities
in machines capable of being successful teammates with a human partner. The correctness of the outcomes is
often determined by the underlying technology and how performance and human satisfaction are measured
through the collaborative nature of the system. We conclude that the teaming of humans and AI, particularly
deep learning, has the advantage of combining the power of AI with the human domain expertise to improve
performance and create value. Human–AI symbiosis could be a promising future direction for AI’s continuing
integration into the world.
CCS Concepts: • Human-centered computing → Collaborative and social computing systems and
tools;
Additional Key Words and Phrases: Human–AI collaboration, human–AI teaming, artificial intelligence,
collaborative concept development
ACM Reference format:
Bahar Mahmud, Guan Hong, and Bernard Fong. 2023. A Study of Human–AI Symbiosis for Creative Work:
Recent Developments and Future Directions in Deep Learning. ACM Trans. Multimedia Comput. Commun.
Appl. 20, 2, Article 47 (September 2023), 21 pages.
https://doi.org/10.1145/3542698

1 INTRODUCTION
The development of artificial intelligence, which includes the study of machine learning, particularly deep learning and neural networks, brings rapid changes in our human lives. Automation
Authors’ addresses: B. Mahmud and G. Hong, Western Michigan University,1903 W Michigan Ave, Kalamazoo, MI 49008,
USA; emails: {baharuddin.mahmud, guanyue.hong}@wmich.edu; B. Fong, Providence University, Shalu District, Taichung
City, Taiwan 433; email: bfong1@pu.edu.tw.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from permissions@acm.org.
© 2023 Association for Computing Machinery.
1551-6857/2023/09-ART47 $15.00
https://doi.org/10.1145/3542698
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

47:2

B. Mahmud et al.

enabled by the rapid advancement in Artificial Intelligence (AI) has been replacing record
amounts of jobs previously held by people, from manufacturing to transportation to customer
services. As AI is continuing to integrate into our society, the concerns of AI competing or replacing humans need to be urgently addressed. This article investigates some promising different
directions of AI development where humans and AI can team up together to work smarter and better. We investigated recent research work aiming at creating a team of machines and people that
can make intelligent judgments, understand, and react intelligently to their teammates’ actions.
Human–AI symbiosis thus refers to people and AI working together to jointly solve problems and
perform specific tasks. The development of AI also makes possible the concept of smart living
with smart devices [1–4]. Deep learning techniques play a significant role in easing humans from
painstakingly tedious tasks [5]. At present, there are many commercially available intelligent devices serving users smartly and helping humans for multiple purposes. However, most of these
intelligent devices are still either highly dependent on humans for performing tasks or lack selfcommunicative and cognitive abilities [6]. Some recent research also focuses on how to establish a
reliable and trustworthy collaborative environment between humans and machines. Our research
focuses on analyzing the latest developments in the human–AI collaborative environment, as well
as the technologies that underpin them.
The recent developments in team collaboration, simulations, audio-visual assistance, interactive
gaming, multi-sensory settings for gathering temporal inter-dynamic log-data, and other technologies have enabled us to deliver learning opportunities in a remarkably effective and efficient
manner [7]. AI-powered intelligent support through various rules and AI techniques showed improvements in the collaborative learning experience for both students and instructors in a webbased collaborative environment [8]. Although the advancement of AI systems has contributed
much to boosting the production management of a business, when the human-in-the-loop methodology was applied, it improves productivity and efficiency as human creativity, and flexibility are
not always replaceable by machines [9]. There is evidence that shows machines perform better
when they work collaboratively with humans. Much research work has been done, and more is
ongoing to evaluate the human–AI system in a collaborative environment [10, 11].
In this article, we focus on several significant human–AI collaborative works to understand the
field more deeply. There are strong debates on whether intelligent machines can make effective
decisions or are prone to misguidance or making mistakes. For example, a major problem with
AI automation is its inability to team with humans and its failure to understand human intention.
AI-powered autonomous systems have been widely criticized for social media misguidance, car
accidents, and increased polarization. Researchers are hopeful of avoiding all these barriers by
combining the system with both human and machine efforts. Considering human decisions in the
loop is important for the successful development of a collaborative environment, the performance
of both humans and machines in a collaborative environment depends on several factors, including
the understanding of physical and internal structure. Moreover, the design concept of human–AI
collaboration is more complex as it involves many factors, including the machine’s understanding
of human behaviors, intentions, cognitive characteristics, and vice versa [12].
The primary objective of this research is to assess the current state of research in the field of
human–machine teaming. Intelligent devices have historically served as tools rather than collaborators. We have built increasingly sophisticated remote-control technologies, but these devices
require a human user’s entire attention [13]. From human personal assistants to search and rescue operations, robotic assistants have been developed in a variety of disciplines and applications
[14–16]. Recent developments in AI, like self-driving cars, technical assistance chatbots, and virtual
assistants like Siri and Alexa, are useful tools for extending human capabilities, but their communicative and cognitive capacities are insufficient to be productive and trusted teammates. As we
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

A Study of Human–AI Symbiosis for Creative Work

47:3

Fig. 1. Workflow of human–AI symbiosis.

know, machines have numerous capabilities such as doing repetitive work, solving complex computations with a higher level of vigilance that humans can hardly perform. The development of
autonomous machines that use these capabilities to work with human partners has the potential
to revolutionize a wide range of commercial and military applications [17].
As an individual’s skills and expertise can be used by a team to achieve goals that would be
impossible for a single person to achieve on their own, human–AI symbiosis could utilize a human member’s unique skills and abilities. Our goal is to give potential researchers a solid overview
of human–machine teaming development through the discussion of possible collaboration of humans and machines. Section 1.1 of this article introduces the human–AI collaborative environment, while Section 1.2 describes the importance of a collaborative system. Section 2 explains the
review methodology. Subsequently, Sections 3–6 describe the extensive review and analysis of recent developments in human–AI teaming for creative and collaborative work, like text generation,
creative drawing, and augmented reality. Section 7 discusses the results of the analysis, with some
key findings and future directions, and, finally, Sections 8 and 9 conclude the article with more
detailed discussions on the future directions of this field.
1.1 A Review of Human–AI Symbiosis
Human interaction with intelligent machines is quite a common technology nowadays. For instance, an intelligent system like a chatbot or a virtual assistant increases human capabilities with
interaction. However, there are some disagreements about how interactive these kinds of systems
are. Are they considered true teammates of humans? To develop a true human–AI collaborative
environment, some key factors need to be addressed very rigorously. First, understanding human
cognitive capabilities is very crucial for this field. Second, the improvement of machine capabilities is also important for the collaborative system. Moreover, the development of human–machine
collaboration broadly depends on our understanding of human cognitive development. Figure 1
shows the development process of human–AI collaboration. For example, during disaster response,
human–machine teams can work collaboratively to save more lives and restore more material.
There are numerous autonomous systems that work along with humans to search for survivors,
move rubble, and deliver medical treatment. Intelligence-enhanced systems in such teams would
be able to respond to new in the environment and learn from their interactions with human collaborators through experience. Once human capabilities are addressed properly, it will lead to the
improvement of machine capabilities. Once these factors are addressed properly, then the improvement of the machine model and human model will come, and so it continues. The challenging part
of the human–AI symbiosis is the integration of several factors such as cognition, understandings,
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

47:4

B. Mahmud et al.

Fig. 2. Decision-making process with a predictive model using historical data.

team desires, objectives, and trust among team members [18]. Communication between team members is one of the key factors for successful teaming. Communication means not only dealing with
words but also with other factors like understanding, emotions, expressions, gestures, and so on.
Progress in this area is still limited, but it is considered one of the active areas of research [19]. Robust machine learning techniques are crucial to developing a machine’s capabilities to cope with a
human’s cognitive capabilities. Unsupervised learning could be a viable alternative to supervised
learning to accelerate the learning process of machines in a collaborative environment [20].
1.2 Why Collaboration?
Human–AI teaming is a combined concept of interactions between humans and intelligent agents.
Different research shows that human–AI teaming has diverse applications in the fields of defense,
healthcare, disaster response, and so on [21]. Many intelligent tools have been invented so far,
but they are not capable of becoming teammates for humans. To become true teammates, they
must make some contributions in a critical problem-solving process, such as making decisions,
choosing options intelligently, using past memory to make decisions, identifying problems, and
so on [22]. Automation enhanced by the advancement in deep learning has diverse applications in
improving productivity and making our daily life easier. Image recognition, traffic prediction, autonomous driving, natural language processing, and many others are well documented and proven
applications of machine learning techniques [23–26]. Although machine learning has significant
impacts on decision-making, it still has several limitations. One of the most common pitfalls of
machine learning models is its inability to balance decisions between humans and machines. Automation using machine learning techniques is blamed for many failures, including fake news,
traffic accidents, misleading social media, and so on. The main reasons behind these failures are
the autonomous decision making by AI, the imbalanced inputs of humans and AI, the lack of collaboration, no human in the loop, and failure to perceive human cognitive capabilities, and so on.
These are valid reasons that demonstrate the importance of human–AI collaboration.
Taking human decisions into consideration and establishing feedback processes in the loop of
human–machine decisions are the focus for the researchers to deal with the shortcomings of machine learning automation alone. Many intelligent tools have been invented so far, but they are not
capable of becoming teammates for humans. Teaming of humans and AI involves interactions and
collaborations between humans and intelligent agents in decision making. To become true teammates, they must contribute to the critical problem-solving process, e.g., by identifying problems,
choosing options intelligently, and making optimal decisions using past experience [15]. Various
research works show that human–AI symbiosis has diverse applications in defense, healthcare,
disaster response, and so on.
The above expression in Figure 2 describes the general setup for decision making with decision
rules that are informed by a machine learning predictive model. Here, decision(a), a ∼ P(a), where
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

A Study of Human–AI Symbiosis for Creative Work

47:5

a is a feature, π (decision | a) denotes a set of decision rules, b is the feature from historical data, and
Y = {0,1} is the prediction. P(b|a) denotes the prediction model. So, the decision depends on the set
of rules and historical data combined. For instance, whether a person gets a loan or not depends on
both historical data and bank policy according to the above predictive model. The main objective
is to maximize the benefits that the decision-maker ensures by applying decision policies. CorbettDavies et al. [27] explained that deterministic threshold rules are optimal decisions under certain
specific constraints.
So, according to the above expression, the decision is perfect as the predictive model P(b|a) is
perfect, features and policies are independent factors, and individuals cannot influence the decision. But this ideal situation rarely occurs; most of the time the constraints are violated. The
most frequent problem is with datasets, as the model trained with historical data is more likely to
be imperfect and suffer from limitations [28]. According to Kilbertus et al. [29] exploring a new
set of rules can achieve the optimal solution by creating feedback loop between human decisions
and system decisions. In that case, the ground truth distribution combined with historical data assists in getting new exploring policies for decision making. According to De et al. [30], optimizing
the machine learning model during training by distributing the fraction of policymaking between
machine and human could be a solution with optimal results.
2 REVIEW METHODOLOGY AND LITERATURE SELECTION
To continue the discussion on specific fields that demonstrate significant contributions in the context of a collaborative platform, we focus on presenting and analyzing some practical and recent
developments in human–AI collaboration. It is very crucial to analyze the existing work to understand the future development in a particular field. By the end of this review, our understanding
would have been solidified in the context of having diverse knowledge of human–AI development.
This article tries to answer the following questions to better understand the platforms:
(1) Why is a collaborative environment significant?
(2) How far has it reached and how much is left to achieve?
(3) Which fields show significant development in collaboration?
(4) What are the main factors that need to be satisfied to be considered as a collaborative
platform?
Literature selection criteria are a crucial part of any research work. There are several literature
selection methods available, including traditional literature review, integrative literature review,
systematic literature review, and so on [31]. Among them, we have used a systematic literature
review method for our selection process. A systematic review is a study that examines a clearly
defined subject using systematic and explicit procedures to find, select, and critically appraise
relevant literature, as well as gather and analyze data from the studies included in the review [32].
The following steps are used in selecting the literature.
Selection of keywords: This depends on the area of research and the questions authors want to
address. In our case, some examples of keywords we have tried for literature finding are human–AI
collaboration, creative work and AI, collaborative work, human–AI interaction, and so on.
Selection of search strings: Search strings are generated with the combination of the keywords and their synonyms [33], for instance (collaborative work AND AI), human-AI interaction
OR human-AI collaboration), (human-AI AND collaboration).
We have set up some inclusion and exclusion criteria for our review that includes for inclusion
practical implementation of our selected topic, closely related to our keywords, must have been
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

47:6

B. Mahmud et al.

Fig. 3. Demonstration of keyword search and string formation in ACM digital library.

published within the last 5 years. For exclusion, older than 5 years, do not have any experimental
explanation, and published in a language other than English.
Search databases: We have considered multiple databases for our literature selection process.
The following is the list of databases we consider:
(1) ACM Digital Library (https://dl.acm.org/).
(2) Scopus (www.scopus.com).
(3) Google Scholar (https://scholar.google.com/).
(4) IEE Explore (ieeexplore.ieee.org).
(5) ScienceDirect (www.sciencedirect.com).
(6) Arxiv (https://arxiv.org/).
Figure 3 illustrates the search criteria formation in one of the databases mentioned above.
The different fields are selected to review extensively including human–AI collaboration in text
generation, human–AI collaboration in artistic design, creative AI using Generative Adversarial
Networks, and augmented reality.
We searched a sizable number of papers related to this research topic, and a total of 120 papers
were selected initially. Then, we applied several parameters considering the relevancy of the work
and date of publication. As a result, 80 articles have been selected for final review and used in this
work. Table 1 describes the breakdown of article selection in the above four focus areas in the final
review.
3 HUMAN–AI COLLABORATION IN TEXT GENERATION
3.1 Wordcraft: A Human–AI Collaborative Editor for Story Writing
This is an AI-powered text editor that creates a human–AI collaborative environment to draft
stories more interactively. Neural language models are gaining more popularity in the field of
natural language processing. The Wordcraft editor offers a user-friendly environment to draft a
story with several options like rewriting, elaboration, continuation, synonyms, and so on. So the
main idea of this work is to draft a story in a human–AI collaborative environment where the
underlined language model will help to shape the story more logically.
The authors [34] here used the few-short learning technique for building their story assistant
tools with Meena, a popular language model for dialog generation. Meena is a neural conversational model that learns to reply appropriately to a particular conversational situation from beginning to end. The goal of training is to reduce perplexity or the risk of incorrect anticipation
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

A Study of Human–AI Symbiosis for Creative Work

47:7

Table 1. Study Breakdown of the Review

Study Breakdown
Field of study
No. of paper studied
Human–AI collaboration in text generation
10
Human–AI collaboration in artistic design
8
Creative AI using Generative Adversarial
8
Networks
Augmented Reality
14

Publication year
Between 2019 and 2021
Between 2016 and 2019
Between 2019 and 2021
Between 2019 and 2022

Fig. 4. Meena conversation: Context and response generation.

of the next token. The Evolved Transformer seq2seq architecture [35] and the neural architecture
search [36] are the main concepts behind the development of the dialog-based Meena language
model. As shown in Figure 4, it includes a unique Evolved Transformer encoder block and 13
Evolved Transformer decoder blocks. The encoder can interpret the discussion context and assist
Meena in comprehending what has already been stated. The information is used in a decoder to
create a truthful answer. We determined that a more powerful decoder was the key to greater
conversational quality by adjusting the hyper-parameters. Few-shot learning is a popular technique that applies to several language models, and it helps models to give demonstrations with
the help of only a few available examples rather than huge chunks of data [37]. The main idea
of few-short learning is to find the best result within limited examples of given data [38]. A set
of context and completion tasks given through the system is represented as K (number of examples). The value of K varies from 10 to 100 examples depending on the model’s capacity. Few-shot
learning techniques comprise of three parts: task description, examples, and prompt (output). For
instance, Figure 5 describes how the few-shot learning technique works to translate English to
French. They showed the implementation of both language models Meena and General Purpose
Language Model (GPLM), then chose Meena for its simplicity. Moreover, in terms of dialogue
generation, Meena is more interactive in comparison to any GPLM. Meena was designed in such a
way that it would generate the next conversation interactively based on the previous conversation
or text. In contrast, GPLM just continued the previous passage on its own.
Although the authors do not specifically analyze GPLM for dialogue, they claim that Meena’s
dialog is more interpretable than GPLM’s. Meena creates discussions that are humanlike and familiar. Meena exhibited a strong response by structuring the story after providing a single new piece
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

47:8

B. Mahmud et al.

Fig. 5. Few-shot learning technique.

of information or enquiry; however, GPLM’s story was unclear. Following significant research, it
was shown that GPLM performs admirably when the task is simply to continue a text line, but
Meena dialog performs better when extra information is provided. The authors demonstrated that
Meena dialog outperforms the general-purpose language model in many circumstances, but they
did not create GPLM specifically for this study. As a result of this research, it was discovered that
Meena dialog produced relevant results in generating the proper next line of text to build a story,
even though other GPLM would produce similar or better results if intended for conversation.
3.2

STORIUM: A Collaborative Story Generation Platform

Storium [39] is a gamified storytelling platform that enables a small group of users to collaboratively draft a single story. The writing process is transformed into a turn-based game. With a rich
database of stories with fine-grained annotations and proper evaluation methods. A fine-tuned
language model was applied to datasets and integrated with Storium where users can search for
new models to write up their next few lines of the story. Existing datasets lack rich enough context
to meaningfully guide models. Existing evaluations are unreliable for assessing long-form creative
text. The Storium dataset contains 6k lengthy stories tokens (125M) with fine-grained natural language annotations. Its evaluation metric is suitable for long-form creative text generation. In this
story generation system, all stories are broken into discrete scenes annotated with narrative elements such as character goals or abilities. The Storium platform has two players; one is the narrator
and multiple characters. Characters can choose cards that are available and contain several challenges. The narrator initiates the game and introduces new challenges anytime to continue the
game.
For topic modeling, they used a simplified version of RMN [40] that illustrates the changes
and relationships between characters over time. The Storium model uses the idea of GPT-2 [41],
a fine-tuned language model that has some limitations such as handling length of context and
implementation of human judgment for huge configurations.
Storium used a new evaluation metric named user story edit ratings (USER). User’s entry text
is evaluated by USER metric that is based on thelongest common sub-sequence and is a variant
of ROUGE [42]. Storium is highly interactive, and the proposed USER metric is highly correlated
with human judgment.
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

A Study of Human–AI Symbiosis for Creative Work

47:9

Fig. 6. An example of a real STORIUM game [39].

3.3

Meena: Humanlike Open-Domain Chatbot

Meena is a more interactive chatbot than other existing chatbots. Training data for Meena is filtered
through several processes, and they use the byte-pair-encoding [43] technique for tokenization.
The final Meena dataset contains 40B words, which is claimed to be larger than any system data.
Meena chatbot text generation has three parts, including training data, architecture model, and
decoding of text. They used a blended architecture model with the help of seq2seq [35] and evolved
transformer [36] as their main architecture. The main objective of the decoding part is generating
text with less perplexity with more Sensibleness and Specificity Average (SSA) metrics. They
used a simple sample-an-rank decoding strategy that showed significant results compared to many
complex decoding strategies like variational autoencoding [44].
4 HUMAN–AI COLLABORATION IN ARTISTIC DRAWING
The role of AI in artistic creation is a popular discussion among researchers. There are many debates about whether the software replaces the artist or whether it is another way to help artists
fine-tune their art. Deep Dream is a technology that helps people to draw their imaginary vision and generate new images using a trained artificial neural network. The development of this
technique came to light and gradually became popular soon after the Google engineer Alexander
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

47:10

B. Mahmud et al.
Table 2. Analysis of Interactive Chatbot “MEENA”

Authors
D. Adiwardana
et al. [34]

Input
A dataset containing
341 GB text with 41B
words

Methodology
Training
Data-Architecture
Model-Decoding

Output
Text with low perplexity,
79% SSA that is 23% greater
than existing chatbots

Table 3. Studies and Analysis of Collaborative Drawing Research
Authors
Davis et al.
2016 [47]

Measurement
Drawing Apprentice:
a freestyle drawing
agent that evaluates
the user’s input and
responds by adding
its own artistic
efforts to a shared
digital canvas

Underlying technology
(1) Deep neural networks
(2) VGG-CNNs to classify the
artist’s drawing and predict
the intention of the artist
(3) Use end to end learning
mechanisms instead of a
bag of words to classify the
object and predict the next
move in drawing

Karimi
et al. 2019
[48]

(1) Implementation
of deep learning
technology in
co-creative art
design
(2) Check the
novelty of
artwork by
comparing it
with existing
artworks
Collabdraw:
collaborative
environment for
drawing sketch
using RNN
(Recurrent Neural
Network)

(1) Detecting visual and
conceptual similarity of
artwork
(2) Used VGG-CNNs for the
design of the system
(3) CNN-LSTM is more
accurate in classification of
similar work than VGG-16

Fan et al.
2019 [49]

Conney
et al. 2019
[50]

Collaborative
artwork with robot.
Tried to incorporate
creativity and
emotions of artist
that is crucial for
novelty in art

(1) Used recurrent neural
network model
sketch-RNN as an
underlined model that was
trained with predeclared
sketches
(2) Used popular deep learning
technique CNN to extract
semantic properties of
sketches
(1) Used deep learning
algorithms
(2) DC-GAN used as the
underlying technology for
image creation
(3) Used sentiment analysis to
recognize emotions for
drawing by integrating the
predefined databases

Findings
(1) Sketch classification is the main
challenge in this collaborative
environment
(2) Used Stochastic gradient
descent for optimization of
training datasets
(3) Realizing an artist’s intention is
sometimes difficult when the
input is not clear
(4) So, predicting the artist’s
creative view and adding it
simultaneously is challenging as
they used only a single pipeline
of conceptual categories and
still needs a lot of research.
(1) Summarizing the novelty of
computer-assisted artwork is
not so easy
(2) Calculating conceptual shifts is
found difficult as concepts
cannot be represented
numerically.
(3) Visual shift of two images can
be detected easily with image
processing technique to
understand the novelty.
(1) allow continuation of partial
sketches that satisfy the
concept of collaboration
(2) Their experimental results
showed that collab sketches are
better than solo sketches
(3) A big question arises about how
meaningful the artwork is.

(1) Try to present artistic views by
incorporating emotions and
interactions.
(2) Efficiency in terms of times
requirement to generate the
new image is not impressive

ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

A Study of Human–AI Symbiosis for Creative Work

47:11

Fig. 7. The five functions of DuetDraw.

Mordvintsev tried using neural networks [45]. So the main idea of his work was to train a Convolutional Neural Network (CNN) with chunks of images and go deeper into the layers to see
the outcomes, which turned out to be a completely new artistic view that they called Inceptionism
[46].
However, the main motive behind the above discussion is to understand whether the neural
networks collaboratively work with artists as a tool to make something more surprising than
artists could hardly imagine. Many researchers have tried to present a cooperative environment
where the artist and AI tool work together to generate fine-grained artworks.
Although the development of collaborative artistic tools still has many limitations, the way it is
progressing is impressive. Deep learning neural networks show significant promise in DuetDraw
[51], which proposes some basic drawing tools that use the concept of recurrent neural networks to
draw in a collaborative environment. DuetDraw has five AI functions that were built using sketchRNN [52], which is based on Google’s TensorFlow. As shown in Figure 7, the five functionalities
of DuetDraw include drawing a similar object, drawing a matching object, filling an empty space,
colorizing sketches, and drawing the rest of the object. Figure 8 shows some demonstrations of
collaborative drawing using sketch-RNN.
The above system incorporates sketch-capabilities RNN’s into a range of tools that the AI can
use in collaborative drawing with varying degrees of initiative. It can finish the artist’s sketch,
change the style of the sketch, and suggest blank space on the drawing canvas for the artist to
fill. Furthermore, it applies to the style-transfer model to colorize a sketch. During the sketching
process, the drawing agent also interacts with the artist to explain why it is performing actions.
DuetDraw is another method that integrates existing AI drawing models into a single interface.
However, the workspace of the above-mentioned tool is extremely limited and diversion in terms
of drawing is very few.
5 CREATIVE AI USING GENERATIVE ADVERSARIAL NETWORKS
Generative Adversarial Networks (GANs) [53] have been used to produce photorealistic images that are often indistinguishable from real-world imagery. GANs can be utilized in a variety
of fields to provide genuine experiences, such as in the retail industry, where it may be feasible to
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

47:12

B. Mahmud et al.

Fig. 8. Experimental results using DuetDraw (which was built on the idea of sketch-RNN).

Fig. 9. Workflow diagram of general adversarial networks.

physically view the real things that we see in stores [54]. Recently, Reuters teamed with AI company Synthesis to create the world’s first synthesized news presenter, which was created using
GAN technology and could be useful for tailored news for individuals [55]. GAN has also demonstrated significant growth potential in the healthcare market. Instead of exchanging genuine data
from patients and research, this technology might be used to generate fictitious data [56]. Figure 9
describes the general workflow of generative adversarial networks.
The primary concept is to pit a generator against a discriminator. The generator attempts to
draw a sample from the training data, whereas the discriminator attempts to determine whether
the sample originated from the generator or the real world. Both the generator and the discriminator are deep networks that have been trained via backpropagation.
GAN Dissection [57] is a visualization approach for deep networks based on the GAN analytic
methodology. To observe how the network models the world, it manipulates the neurons to turn
them into generators. To alter photos with object-level control, the approach employs a GAN. It
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

A Study of Human–AI Symbiosis for Creative Work

47:13

Fig. 10. Experimental results of GANpaint. Panels 1 and 2: with and without grass object. Panels 3 and
4: with and without tree object. Panels 5 and 6: with and without door object. Panels 7 and 8: with and
without dome object. Panels 9 and 10: with and without clouds.

uses neurons instead of pixels to create its artwork. To locate individual units of the generator that
match meaningful object classes, such as trees, GAN dissection employs a segmentation network
and a dissection approach. The authors of this paper use GAN to create many images. They find
units inside the networks that correlate with things and test them to determine if ablating those
units (turning them to zero) removes the object from the image and adding it back (setting it to 1).
The authors have loaded a GAN that generates lifelike images of churches with a large number of
neural units that represent various sections of the church in this work. For example, if you want to
decorate a church with trees, then you can accomplish it by increasing or decreasing the tree unit
as needed. Because each neuron is particular to a single unit, ablation will not cause any disruption
to other units. The authors show how to insert items into photos using an interactive interface.
Internally, the procedure will activate neurons in any location that corresponds to an item.
Figure 10 shows the experimental results of GAN Dissection using the online tool of the work
named GANpaint. The fact that the same neurons govern the same object class in different circumstances, even though the item’s ultimate form differs dramatically, is a fascinating observation. The same neurons can activate the concept of a “door” whether a massive stone wall needs
a large heavy door facing to the left or a little hut that necessitates a small curtain door facing to
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

47:14

B. Mahmud et al.

the right. The network can also tell when it is possible to put goods together and when it is not.
For example, turning on neurons for a door at the proper location of a building will add a door.
Doing the same thing in the sky or on a tree, however, usually has no effect. This structure can
be measured. Understanding a network’s internal concepts is important for a number of reasons,
one of which is that the insights may help the network behave better. A GAN, for example, might
produce very unrealistic graphics on occasion, and the origin of these faults was previously unknown. According to this study, these inaccuracies can be induced by certain types of neurons that
cause visual distortions. By identifying and suppressing specific neurons, the output quality of a
GAN could be enhanced.
The GAN approach holds many promises for developing collaborative AI technologies. It is
regarded as one of the most innovative and effective methods for creating false data. For example,
by generating movies of well-known persons appealing for aid or cash for a pioneering endeavor,
this technology offers a lot of promise for fundraising and increasing awareness [58]. Although
this technology is making a significant contribution to the development of interactive AI, it is
also being misused. GAN, for example, has shown promise in the production of Deepfake videos,
which have been exploited for nefarious reasons. Blackmailing and exploiting a specific person by
creating a bogus video are two examples that can be readily made with GAN [59–61].
6

AUGMENTED REALITY AND CREATIVE WORK

Augmented reality (AR) is a multisensory interactive experience in which real-world items are
supplemented with computer-generated perceptual information, sometimes across many sensory
modalities such as visual, hearing, haptic, somatosensory, and olfactory [62]. Facebook, one of the
top frontiers in augmented reality, defines the technology as follows: “Consider a world where
you could use a set of lightweight, attractive glasses to replace your computer or Smartphone.
You would be able to be physically present with friends and family no matter where they were on
the planet, and you would have contextually aware AI to help you navigate the environment, as
well as rich three-dimensional (3D) virtual knowledge at your fingertips. Most importantly, they
would allow you to look up and be present in the world around you instead of focusing on the
peripheral of your palm. This technology will not force you to choose between the real and virtual
worlds.” Chief scientist Michael Abrash from Facebook Reality Labs has called AR interaction
“one of the hardest and most interesting multi-disciplinary problems around.” In order for allday wearable AR glasses to perform in every setting an individual encounters during a day, a new
paradigm is needed. Human avatars have enabled augmented and virtual reality applications, such
as telepresence, for increased communication and entertainment and have helped reconstruct and
perceive individuals in photos [63]. However, creating photorealistic animatable full-body codec
avatars is still difficult. Understanding of proper representation of the shape of the avatars needs
explicit implementation of complex geometric techniques and pixel mapping [64, 65].
Several works have been done to model the clothing of humans in avatar mode. For example, In
references [66, 67] the authors tried to model human clothing based on mesh representation to enhance the required optimization-based registration steps, but they are prone to failure. Moreover,
they have limited resolution and cannot explain all the policies. Implicit-based representation for
human clothing has been explored, but most of them only model static shape and are not controllable like the NASA model [68], which poses dependent occupancy, but it cannot explain highly
non-rigid behavior and has part-based artifacts. NEURAL-GIF [69], depicts an implicit function for
people’s clothes. By generating a detailed 3D shape from an input posture, NEURAL-GIF can be
trained from raw scans without registration and used to explain a variety of topologies and geometrical patterns. It has also been proposed to learn an implicit representation of the human body
surface using SCANIMATE [70] and LEAP [71]. In NEURAL-GIF, they learned a post added implicit
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

A Study of Human–AI Symbiosis for Creative Work

47:15

Fig. 11. Description of the implementation of generalized implicit function in modeling NEURAL-GIF [69].

surface with generalized implicit function [72]. It is easy to determine whether a set of points lies
inside or outside of a surface given the surface’s implicit function. There will be no implicit function between the original shape and the newly converted space if a transformation or deformation
is applied to it. This may be done easily by inverse transformation and then querying the original
function regarding whether it is in or out of bounds. Only in this section were rotation and translation taken into account by the authors. So long as we have a point to work with, we can recover
the surface using a stroke and use it to explain the shape as deformation of itself in the new space.
A continuous displacement field is also included in this transformation by the authors to widen
the range of deformations that can be divided. On the mesh surface, it acts as a displacement field
in reverse. Face/surface deformation will increase if a displacement field is applied inward.
An implicit function is used to learn post-appended surfaces by adding human articulation and
non-rigid deformation. By using a canonical mapping network and inverse scanning transform,
the work converts the query point P into a pose known as a canonical pose, which is then mapped
to canonical space. According to Figure 11, B is the joint transformation matrix, k is the number
of joints, and w is the predicted blend width.
Additionally, a post-appended displacement field is included to represent the very dynamic and
non-rigid deformation that occurs in canonical space. The signed distance field improves the supply of the margin queue to rebuild the mesh directly in post space during inference. Pose-driven
animation for a clothed human was tested using CAPE [73] and DFAUST [74] datasets with the
model developed by the researchers. Separate clothing items, such as t-shirts or skirts, are said to
be flexible with this concept.
Although NEURAL-GIF works fine for clothing avatars that have more flexibility than templatebased avatars, it still has some limitations and artifacts. For instance, it shows better results for
the clothing of humans in grayscale mode avatars, but it does not perform well with RGB avatars
when in motion. Figure 12 shows the artifacts of the NEURAL-GIF that have been collected based
on the model’s experimental results.
However, creating photorealistic animatable full-body codec avatars is still difficult. To address
these obstacles, an animated clothed body avatar was created using multi-view gathered videos
[75]. They used a two-layer mesh for the body and clothing templates. To improve photometric compatibility across frames, inverse rendering of apparel geometry and texture is used. A
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

47:16

B. Mahmud et al.

Fig. 12. Experimental works with NEURAL-GIF: show the limitations while separate clothing present for
avatar in RGB mode (T-shirt and skirts).

two-layer codec avatar with upper clothes and inside body modeling is then trained. They used
a temporal convolution network to predict clothing latent coding from skeletal input positions.
They used photorealistic animation to highlight the advantage.
7 RESULT ANALYSIS AND KEY FINDINGS
After experimenting throughout this research field, we can say that although the human–AI collaboration is getting special attention among researchers, the amount of research is still very limited.
Most of the research on human–AI symbiosis is still at a primary level in terms of practical implementation and contribution. In addition, we discovered that most of the reviewed papers are
uneven in terms of in-depth insights. Most of the reviewed papers still lack proper evaluation and
performance methodology for their work.
Our review on human–AI collaboration in text generation summarizes the techniques and
methodology to generate text more interactively. All the papers we reviewed that were related
to text generation emphasized the quality of datasets. Fine-tuned datasets are crucial to generating meaningful stories or conversations. Even though all the works used evaluation methods to
validate their systems, the fluency and relevance of generated text remain a major concern. Similarly, human–AI collaborative work in artistic drawing has proven to be doable. However, the big
question is How acceptable is the drawing to the human collaborator? Art is a matter of an artist’s
thoughts and creativity. Understanding the artist’s cognitive capabilities is a big challenge for computer algorithms and vice versa. In the case of generative adversarial networks, there is currently
no core score evaluation for better model training and advanced output production. In addition, it
is still difficult to predict the density of the correctness of the evaluated model to claim that this image is dense enough to proceed. Moreover, the training process of a generative adversarial network
is overly complex and time-consuming. For avatar clothing, an expansion of the current two-layer
approach is needed to handle lower-body clothes, such as short pants with moving leg boundaries,
which provides novel issues for both registration and modeling. A skirt, another frequent item of
apparel, could be much more challenging because of the significant amount of movement and deformation it undergoes. Clothing-body interaction models now in use may not be able to manage
these issues. Adding extra physical limitations to registration and learning for animation could be
an option to resolve these problems.
8

DISCUSSION AND FUTURE DIRECTION

In summary, significant work has been done in developing the teaming of human–AI to do creative
work. As demonstrated in recent literature, the human–AI symbiosis needs collaborative efforts
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

A Study of Human–AI Symbiosis for Creative Work

47:17

from the research of different fields. A successful collaboration could be achieved with the accumulative efforts from researchers from the fields of robotics, artificial intelligence, neuroscience,
interaction, and so on. Moreover, the area of research is still very limited and needs extensive
implementation. In general, researchers should focus on achieving more efficient and effective
collaboration between humans and AI and making their systems adaptable among a larger number of people. Again, more research is needed to understand the human’s cognitive capability and
adaptability to an intelligence system.
Some characteristics are required for an ideal collaborative system. For instance, user-level experience is very crucial for a system to be robust and effective. The goal of a human–AI collaborative
system must be clear and aligned with the human user. Output analysis is also an effective way to
measure the success of the collaboration. For example, calculating the potential advantages, disadvantages, impacts, and consequences is crucial for the system’s robustness. A level of trust and
privacy is also a major future concern for a human–AI collaborative system. Gaining users’ trust
and protecting their privacy would be crucial for the future success of the system.
For collaborative writing systems, continuous contributions from both machines and humans
are important. For instance, to write a successful and meaningful story, the user’s initial inputs are
very important and lead the story to the subsequent stages. However, real-time storytelling systems are not easy tasks considering the quality of datasets and users’ inputs. In artistic drawing
systems, both machines and human users work concurrently. The human users’ inputs are essential in determining what the machine will draw in the next step. To draw realistic artwork, the
user’s artistic knowledge and cognitive capabilities play a crucial role. human–AI collaboration
for creative drawing has great potential in helping kids to learn how to draw from scratch.
Currently, the most common problems of generative adversarial networks are vanishing gradients, mode collapse, failure to converge, and so on. All these problems of GAN technologies are
active research areas. Generator training can fail due to vanishing gradients if your discriminator is too good [76]. As a consequence, an ideal discriminator cannot provide the generator with
enough information to proceed. Some major GAN issues, such as mode collapse, may be mitigated
by a finely tuned learning rate. One solution to avoid this problem is when mode collapse occurs,
lower the learning rate, and restart the training.
Autonomous machines can be performed more effectively if they work in a team with humans.
The main hurdle behind the collaboration is understanding the teammates’ communication and
cognitive capabilities [77]. One of the major roadblocks to the development of human–AI collaborative systems is sequential decision making [78]. To construct a trustworthy and secure system,
parallel development of human–AI collaboration and sequential decision making is critical [79].
Existing research in human–machine collaboration is restricted in terms of its focus on long-term
engagement and system stability. The two most important criteria in facilitating human–AI symbiosis are effective communication and coordination. To design an efficient human–AI collaborative system, trustworthiness, robustness, and adaptation must all be addressed simultaneously
[80].
9

CONCLUSION

In summary, we deduce that some significant work has been done in developing the concept of
human–AI symbiosis. As we discussed above, the human–AI teaming concept involves the complex tasks of understanding human nature, cognitive capacities, behaviors, and so on, which requires multi-disciplinary work in artificial intelligence, robotics, neuroscience, communications,
and so on. Every disciplinary field has its own research regulations. Combining all of these into
one can be a challenging task for researchers. To get more effective results from the teaming concept, challenges and opportunities should be studied first. Furthermore, practical implementation
ACM Trans. Multimedia Comput. Commun. Appl., Vol. 20, No. 2, Article 47. Publication date: September 2023.

Artificial intelligence (AI) technologies have developed rapidly, and generative AI in particular
challenges human creativity. Therefore, people’s perspectives about this transformative change
involving creativity and art must be examined. We investigated attitudes toward using AI in art
from the perspective of self-determination theory. We used data from a two-wave survey of
Finnish respondents aged 18–80 years (n = 828) to analyze within- and between-person effects
using hybrid multilevel regression modelling. We measured positive attitudes toward using AI in
(a) the art and culture field in general, (b) music, (c) visual arts, (d) detecting forged art, and (e)
creating art. The main independent variables were the basic psychological needs (perceived
relatedness, autonomy, and competence) in using new technologies. The results showed that
participants were less positive toward using AI in the art and culture field in general compared to
many other fields, such as medicine and building and real estate technology. Stronger relatedness
had within- and between-person effects on positive attitudes on using AI in the art and culture
field in general, as well as in music, visual arts, and creating art. Stronger autonomy had withinand between-person effects on positive attitudes on using AI in detecting forged art and creating
art. The results indicate that human needs for relatedness and autonomy are important in atti­
tudes toward using AI in art. Hence, positive personal experiences with the use of new technology
are likely to affect how people perceive the introduction of AI to the art field, which has been
considered the last human frontier in the technological world.

Artificial intelligence (AI) is constantly evolving and creating new opportunities across various fields, including art and culture. AI
can be used in creative processes, analyses of artistic works, and productions of art, and to enhance artistic events and performances in
ways that were previously impossible (Allal-Chérif, 2022; Casacuberta, 2004; Cetinic & She, 2022; Duan et al., 2021; Meany & Clark,
2012; Starkey et al., 2020; Zohar & Shimshoni, 2021). Although the art field has long discussed AI, generative AI tools have started to
change human perception of what AI can do. We are currently in the middle of a major AI transformation where it is increasingly more
difficult to distinguish between human-made and AI-made art (Oksanen et al., 2023).
AI-made art is controversial and raises questions about whether AI can be considered equal to a human artist (Browne, 2022; Hong
& Curran, 2019). Creativity and uniqueness are often regarded as fundamental aspects of the art and culture field, with creativity
commonly seen as an exclusively human trait (Shao et al., 2019). Some fear that AI may eventually replace human artists and that the
art products AI produces may be of higher creativity, quality, and productivity (Hong & Curran, 2019; Tubadji et al., 2021). Analyzing

* Corresponding author. MSocSci, Tampere University, Kalevantie 4, 33100 Tampere Finland
E-mail address: rita.latikka@tuni.fi (R. Latikka).
https://doi.org/10.1016/j.poetic.2023.101839
Received 19 June 2023; Received in revised form 3 October 2023; Accepted 9 October 2023
Available online 2 November 2023
0304-422X/© 2023 The Author(s).
Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license
(http://creativecommons.org/licenses/by-nc-nd/4.0/).

Poetics 101 (2023) 101839

R. Latikka et al.

people’s images of AI and attitudes toward using AI in art is important because it helps understand to what extent and how AI is likely
to affect the art and culture field.
This is among the first longitudinal population studies to investigate perceptions of AI in art. In our analysis, we first compared
attitudes toward AI in the art and culture field to other fields. Then, we investigated predictors of positive attitudes toward using AI in
(a) the art and culture field in general, (b) music, (c) visual arts, (d) detecting forged art, and (e) creating art. The final part of the
analysis focused on participants’ perceptions of AI created art through a word cloud made from open-field answers. Our study was
grounded theoretically in self-determination theory (SDT) and its basic psychological needs of autonomy, competence, and relatedness
(Ryan & Deci, 2017). We also consider a wide range of sociodemographic and other individual factors in our longitudinal analyses.
1. Attitudes Toward AI in Art
Attitudes are general assessments of attitude objects that can vary in terms of their strength and valence (Maio et al., 2018, p. 27).
Even in cases where individuals are unfamiliar with the realistic attitude object, they tend to form attitudes, with affective information
(i.e., how people feel about it) playing a crucial role in such instances (van Giesen et al., 2015). Attitudes toward AI are also closely
linked to people’s acceptance and behavioral intentions regarding the use of AI in their daily lives (Kelly et al., 2023). Moreover,
investigating attitudes toward AI in the art field enables analyzing how people feel about this phenomenon in a field that has long
traditions.
Attitudes toward AI tend to vary greatly and likely differ from the traditional acceptance of technologies (Park & Woo, 2022;
Schepman & Rodway, 2020, 2022). Given that governments and large corporations play a pivotal role in deciding on the imple­
mentation of AI, attitudes toward AI are influenced by the reduced power to discard or adopt AI compared to the greater power
involved in deciding to adopt technologies that are more traditional (Schepman & Rodway, 2022). However, attitudes toward AI vary
depending on the context and its specific applications (Schepman & Rodway, 2020). For example, perceptions of AI can be more
positive regarding applications involving big data or other easily automated simple tasks compared to applications involving some
aspect of human judgment and more complex tasks (Ingrams et al., 2022; Schepman & Rodway, 2020).
Research has also demonstrated individual differences in attitudes toward AI. Extroverts, older individuals, and women reported
less positive attitudes toward AI, whereas those with greater computer experience and higher use of computers reported more positive
attitudes toward AI (Kaya et al., 2022; Neudert et al., 2020; Schepman & Rodway, 2022). Openness to experiences, higher education,
higher income, and daily use of smart technologies have also been associated with more positive attitudes toward AI (Bergdahl et al.,
2023). Higher income has been linked with greater access to and use of AI devices that likely influence perceptual understandings of AI
(Park et al., 2022). Constantly evolving representations of and information about AI have also been suggested as influences on attitudes
toward AI (Park & Woo, 2022), making it intriguing to study AI attitudes over time with data collected from the same participants at
more than one timepoint.
Evidence has been gathered specifically regarding perceptions of AI in the art realm. Studies have focused on the extent to which
participants have identified AI-generated art and distinguished it from human-made art (e.g., Gangadharbatla, 2021; Schubert et al.,
2017), whereas other studies have delved deeper into perceptions of AI-generated art and the factors that influence the perceptions of
the AI system or the art it generates (e.g., Bellaiche et al., 2023; Hong & Curran, 2019; Hong et al., 2021, 2022; Jansen & Sklar, 2021;
Lima et al., 2021; Tubadji et al., 2021; Wu et al., 2020). In general, evidence from these studies points toward people not always being
able to recognize AI-generated art or to differentiate it from human-generated art and toward people tending to value human-made art
over AI alternatives, although not in call cases. For instance, the perception of AI-generated content varies across societies (Wu et al.,
2020). One study found that negative perceptions of AI creating art were linked with less favorable evaluations of the artwork when
participants believed the images were AI generated (Hong & Curran, 2019). Bellaiche et al. (2023) highlighted the importance of
labeling (AI- vs. human-created art) and found that when people learned about human engagement in the artistic process, they had
more positive appraisals of the art.
2. Self-Determination Theory and Attitudes Toward Technology Use
SDT provides a valuable yet underutilized theoretical framework for analyzing attitudes toward using AI in art from the basic
human psychological needs perspective. SDT is a theory of human development, wellness, and motivation that is grounded in decades
of empirical research, and it was initially introduced by Deci and Ryan (1985). According to SDT, the driving force within an individual
is an innate motivation that emerges from fulfilling three psychological needs: autonomy, competence, and relatedness (Ryan & Deci,
2017). Autonomy pertains to an individual’s need to experience volition and willingness in their actions and behaviors. Competence
represents the need to experience capability and effectiveness in relation to one’s choices and actions. Relatedness reflects the need to
experience care and connection with others. These psychological needs are argued to be innate and universal, and thus, they apply
across groups of people and their satisfaction and frustration to explain a broad variety of phenomena (Vansteenkiste et al., 2020). SDT
postulates that when these three basic psychological needs are met, individuals experience satisfaction and their intrinsic motivation
and well-being are enhanced (Ryan & Deci, 2017). The SDT framework has been applied in various fields, including technology.
Other theoretical models that have previously been used to explain human acceptance and adoption of technologies generally
support SDT principles. For instance, the theory of reasoned action (Ajzen & Fishbein, 1980) and the theory of planned behavior
(Ajzen, 1991) assume that certain psychological factors influence an individual’s behavioral intentions and actual behavior. These
theories have been the background for the commonly used technology acceptance model (Davis, 1989) and its extensions (e.g.,
Venkatesh & Davis, 2000; Venkatesh et al., 2003). The model and its extensions include constructs that are similar to yet distinct from
2

Poetics 101 (2023) 101839

R. Latikka et al.

SDT’s basic psychological needs, such as the perceived ease of use, perceived usefulness, and perceived behavioral control.
Researchers have also begun to integrate the basic psychological needs with the traditional technology acceptance models (e.g.,
Alowayr & Al-Azawei, 2021; Fathali & Okada, 2018; Moradbakhti et al., 2022; Nikou & Economides, 2017; Lee et al., 2015). For
instance, Nikou and Economides (2017) found that perceived autonomy, relatedness, and competence in technology use were asso­
ciated with the perceived ease of using technology. Perceived autonomy and relatedness were also related to perceived usefulness of
technology and willingness to use it. Other studies have reported similar results (e.g., Fathali & Okada, 2018; Şahin & Şahin, 2022).
Studies within the past few years on the relationship between the basic psychological needs and attitudes toward technology can be
found in experimental research related to AI chatbots. For example, in Moradbakhti et al. (2022) research on AI-based personal
banking assistants, the fulfillment of autonomy, competence, and relatedness was associated with the intention to use these tech­
nologies. Similar results were also obtained by Jiménez-Barreto et al. (2021), who observed that experienced high self-determination
positively influenced user satisfaction, customer experience, and attitudes toward a chatbot. Furthermore, satisfaction of autonomy,
competence, and relatedness in the use of AI has related to both directions of emotional attitudes toward AI on a correlational level
(Park & Woo, 2022). SDT and its basic psychological needs are an appropriate framework for understanding people’s perceptions on
using new technologies such as AI (Gagné et al., 2022; Peters et al., 2018). In a paper reporting cross-national and longitudinal studies
investigating the attitudes toward AI and SDT dimensions, the basic psychological needs emerged as explanatory factors for positive
and negative attitudes toward AI when considering control variables (Bergdahl et al., 2023).
3. This Study
Currently, there is limited longitudinal research on attitudes toward AI in art and the social psychological factors that predict the
attitudes. Our study aims to address this research gap by examining perceptions of AI in art using a two-wave survey and applying SDT
as a theoretical framework (Ryan & Deci, 2017) to explain positive attitudes toward using AI in art over time. We focused on the basic
psychological needs of autonomy, competence, and relatedness via new technologies because fulfilling the needs is central for intrinsic
motivation and well-being (Ryan & Deci, 2017). Furthermore, previous empirical studies have demonstrated a link between fulfilling
the basic psychological needs in technology use and more positive attitudes toward AI (Bergdahl et al., 2023; Jiménez-Barreto et al.,
2021; Park & Woo, 2022). Following these lines of theory and empirical evidence, we hypothesize that fulfilling these three basic
psychological needs, in relation to beliefs about technology, is linked to attitudes toward using AI that are more positive, also within
the art realm.
Hypothesis 1: Greater perceived relatedness in the use of new technologies is connected to more positive attitudes toward using AI
in the context of art.
Hypothesis 2. Greater perceived autonomy in the use of new technologies is connected to more positive attitudes toward using AI in
the context of art.
Hypothesis 3. Greater perceived competence in the use of new technologies is connected to more positive attitudes toward using AI
in the context of art.
4. Materials and Methods
4.1. Participants and Procedure
We used data from a two-wave online AI in society survey, focusing on the topic of AI in art in the present study. The survey is part
of a larger research project on AI in art and society. The survey asked participants about their attitudes toward AI, use of technology in
general, cultural activities, sociodemographic factors, and several individual and psychological measures. The first measurement point
was from May to June 2021 (Time 1 [T1]: N = 1,226) and the second wave was collected from May to June 2022 (T2: n = 828). The
response rate at T1 was 30.81%, and 67.55% of those respondents answered the survey at T2. The mean response time for the survey
was 16.1 min at T1 and 17.1 min at T2.
The surveys targeted Finnish adults aged 18–80 years and Norstat Finland recruited the study participants from its online panel.
The first sample was balanced to represent the target population regarding age and gender (Mage = 48.43, SD = 17.33; 50.08% female),
and these distributions remained similar at T2 (Mage = 51.30, SD = 16.66; 50.36% female). The data used in this study include
measures and observations relevant for investigating attitudes toward AI in art from participants who answered both surveys (n =
828).
We informed the respondents about the research aims and their right to quit the survey at any point as well as provided them with a
link to the privacy notice and contact information for the project. In the final data set, we only included answers from respondents who
filled out the entire survey. Before the data collection, the Academic Ethics Committee of Tampere region in Finland confirmed the
research protocol was ethically sound. We conducted quality-check analyses (e.g., patterned responses and attention checks) for the
data set using the protocol of the research lab before conducting the analyses.
4.2. Measures
We used five dependent variables in this study to measure positive attitudes toward using AI in (a) the art and culture field in
general, (b) music, (c) visual arts, (d) detecting forged art, and (e) creating art. The study’s main independent variables were perceived
autonomy, competence, and relatedness in the use of new technologies; weekly use of smart technologies; monthly gross income; and
3

Poetics 101 (2023) 101839

R. Latikka et al.

employment status. Control variables were age, gender, education, openness to experiences, extraversion, art hobbies, and owning a
museum card.
Positive attitudes toward using AI in the art and culture field in general were measured with a question: “How positively do you
perceive use of AI in the following fields?” The respondents indicated their answers to the culture and art item on a scale from 1 (not at
all positively) to 7 (very positively). For descriptive analysis, we also gathered descriptive information of other fields measured in the
survey with the same question: medicine, care work, teaching and education, traffic, urban planning, building and real estate tech­
nology, defense forces, information security, job recruitment, dating services, and political decision-making to compare them with the
art and culture field first with a sum variable combining all other fields (T1 ω = .90, T2 ω = .89), and then each field separately.
Positive attitudes toward using AI in music was measured with four questions modified from the Threats of Artificial Intelligence
Scale, which considers four AI functionalities: recognition, prediction, recommendation, and decision-making (Kieslich et al., 2021).
Respondents were asked: “When you think about the use of AI in music, how positively do you feel about whether AI (a) detects your
favorite music, (b) forecasts the evolution of your preferred music, (c) recommends listening to songs and artists, and (d) selects the
songs and artists to listen to.” The participants gave their answers on a scale from 1 (not at all positively) to 7 (very positively). We created
sum variables with values from 1 to 7 showing ω coefficients .92 (T1) and .91 (T2).
Positive attitudes toward using AI in visual arts was measured with four questions modified from the Threats of Artificial Intel­
ligence Scale (Kieslich et al., 2021). The respondents were asked: “When you think about the use of AI in visual arts, how positively do
you feel about whether AI (a) detects your favorite visual art, (b) forecasts the evolution of your preferred visual art, (c) recommends
visual art according to your taste, and (d) selects visual art according to your taste.” The participants marked their answers on a scale
from 1 (not at all positively) to 7 (very positively). We created sum variables with values from 1 to 7 showing ω coefficients .94 (T1) and
.95 (T2).
Positive attitudes toward using AI in detecting forged art was measured with statements with the following introduction: “AI can
become part of the art field in different ways in the future. Rate how positively you perceive the following future scenarios.” The
statements were, “AI detects copied art” and “AI detects forged art.” The participants indicated their answers on a scale from 1 (not at
all positively) to 7 (very positively). We created two-item sum variables with values from 1 to 7 showing correlations between the items r
= .88 (T1) and r = .86 (T2).
Positive attitudes toward using AI in creating art was measured with statements with the following introduction: “AI can become
part of the art field in different ways in the future. Rate how positively you perceive the following future scenarios.” The statements
were, “AI creates art independently” and “AI creates art together with a human.” The participants indicated their answers on a scale
from 1 (not at all positively) to 7 (very positively). We created two-item sum variables with values from 1 to 7 showing correlation
between the items r = .69 (T1) and r = .71 (T2).
Autonomy, competence, and relatedness in the use of new technologies were measured with three-item scales used in previous
research (Bergdahl et al., 2023). Participants reflected their agreement with statements on a scale from 1 (totally disagree) to 7 (totally
agree). In total, three statements measured autonomy (e.g., “I feel I have the ability to influence how I use new technologies”), three
statements measured competence (e.g., “Other people tell me I am good at using new technologies”), and three statements measured
relatedness (e.g., “New technologies give me more opportunities to interact with others”). We created a sum variable for each
dimension (autonomy, competence, and relatedness) with possible values from 3 to 21. Omega coefficients were .81 (T1) and .81 (T2)
for autonomy, .83 (T1) and .83 (T2) for competence, and .87 (T1) and .88 (T2) for relatedness.
Weekly smart technology use was measured with a question: “How often do you use the following technologies?” The listed options
were, “a smart home system (e.g., smart lighting); immobile smart home appliance or other appliance (e.g., smart TV); mobile robot or
another smart device (e.g., robot vacuum cleaner, robot lawn mower, assistance robot); virtual assistant via smart speaker, computer,
or a phone app (e.g., Siri, Alexa); and wearable smart technology (e.g., smart watch, smart ring).” Participants gave their responses on
a scale from 0 to 4 (0 = never, 1 = less than weekly, 2 = weekly, 3 = daily, 4 = many times a day). We created dummy variables to indicate
respondents who used at least one of the technologies weekly (0 = less than weekly or no use, 1 = at least weekly).
Openness to experiences and extraversion personality traits were measured using items from the Big Five Inventory (Hahn et al.,
2012). Both personality traits have been associated with positive attitudes toward AI in previous research (Bergdahl et al., 2023; Kaya
et al., 2022; Schepman & Rodway, 2022). Participants gave their answers to the three statements for both dimensions on a scale from 1
(does not describe me at all) to 7 (describes me completely). For the analysis, we created a sum variable for both personality traits with
possible values from 3 to 21. Omega coefficients were .88 for extraversion and .75 for openness. Extraversion was measured at T1, and
openness was measured at T2.
Art hobbies were measured with four statements: “I listen to a lot of music,” “I often go to music events,” “I am interested in visual
arts,” and “I often go to art exhibitions.” The participants indicated their agreement with statements on a scale from 1 (does not describe
me at all) to 7 (describes me completely). We coded a sum variable with possible values from 4 to 28 showing ω coefficient .71 at T2.
Sociodemographic variables included age in years, gender, education (0 = no college or university degree, 1 = college or university
degree), monthly gross income on a scale from 1 to 8 (1 = below 1,000€ , 8 = at least 7,000€ ), employment status (0 = not working, 1 =
working), and ownership of a museum card (0 = does not own museum card, 1 = owns museum card). Sociodemographic information was
measured at T1 and owning a museum card was measured at T2.
All five dependent variables measuring positive attitudes toward using AI in art; autonomy, competence, and relatedness in the use
of technologies; monthly gross income; and employment status were time-variant variables, whereas the rest were time-invariant
variables.
A word cloud related to art AI makes was created using survey participants’ answers to the question, “Which three words would you
use to describe art AI makes?” Participants were given three open-answer fields. We used Google Translator to translate answers to
4

Poetics 101 (2023) 101839

R. Latikka et al.

English. Two authors went through the list manually to guarantee the accuracy of the translations.
4.3. Statistical Techniques
We conducted a pairwise comparison t test to analyze descriptively the differences between the art and culture field and other
fields. We conducted the main analyses using linear multilevel hybrid models that used the xthybrid command in Stata (Schunck &
Perales, 2017). Hybrid models allow simultaneous estimations of within-person effects and between-person effects. Within-person
effects reflect changes over time within individuals, and between-person effects reflect differences between individuals. We report
regression coefficients (B), their robust standard errors (SE), and p values for statistical significance. We conducted the statistical
analyses using Stata 17 software, and we created the word cloud with LIWC-22 software. We used the LIWC-22 software’s internal stop
list for English language to exclude words and symbols irrelevant to meaningful interpretation. Finally, we set the emphasis on fre­
quency differences to 4 (from options of 1–5) and included 100 words that appeared more than three times in the visualization.
5. Results
Table 1 reports a descriptive overview of study variables. Appendix Table A1 presents a correlation matrix of all study variables
used in the models. According to the results of the t test, participants had significantly more positive attitudes toward using AI in other
fields (T1: M = 4.08, SD = 1.20; T2: M = 4.15, SD = 1.14) compared to the art and culture field at T1, t(827) = − 12.80, p < .001, and at
T2, t(827) = − 11.68, p < .001. Comparisons between the means of positive attitudes toward using AI in art and culture and other fields
separately in both time points showed that positive attitudes toward using AI in medicine, building and real estate technology, in­
formation security, traffic, urban planning, defense forces, teaching and education, care work, dating services, and political decisionmaking were significantly different from positive attitudes toward using AI in art and culture (p < .05), whereas no significant dif­
ference was found between job recruitment and the art and culture field (p > .05). Political decision-making was the only one with less
positive attitudes toward using AI compared to art and culture field.
Table 1
Descriptive Overview of All Study Variables.
T1

T2

Continuous variables

Range

M

SD

M

SD

Within-person
differences, SD

Positive attitudes toward using AI in…
culture and art field
medicine
building and real estate technology
information security
traffic
urban planning
defense forces
teaching and education
care work
dating services
job recruitment
political decision-making
music
visual arts
detecting forged art
creating art
Autonomy via new technologies
Competence via new technologies
Relatedness via new technologies
Age
Income level
Extraversion
Openness
Art hobbies

1–7
1–7
1–7
1–7
1–7
1–7
1–7
1–7
1–7
1–7
1–7
1–7
1–7
1–7
1–7
1–7
3–21
3–21
3–21
19–80
1–8
3–21
3–21
4–28

3.41
5.06
4.93
4.61
4.53
4.35
4.03
3.98
3.75
3.55
3.31
2.75
3.86
3.43
5.55
3.55
12.74
11.82
9.97
50.30
3.11
13.60

1.68
1.67
1.51
1.78
1.67
1.63
1.84
1.74
1.81
1.72
1.66
1.66
1.63
1.58
1.47
1.52
3.95
4.24
4.07
16.66
1.52
4.58

3.53
4.90
4.96
4.64
4.64
4.49
4.25
4.03
3.84
3.79
3.43
2.72
3.98
3.58
5.71
3.79
13.06
11.85
10.16

1.63
1.65
1.46
1.72
1.59
1.55
1.82
1.65
1.77
1.68
1.61
1.56
1.55
1.61
1.36
1.53
3.90
4.24
4.06

0.90
0.78
0.75
0.88
0.73
0.82
0.88
0.81
0.84
0.88
0.84
0.85
0.62
0.69
0.67
0.75
1.93
1.37
1.89

3.24

1.56

0.43

14.06
14.35

3.75
4.92

Categorical variables

n

%

n

%

Weekly use of smart technologies
Works
Female
College/university degree
Owns a museum card

533
400
423
328

64.37
48.31
51.09
39.61

594
411

71.74
49.64

139

16.79

Note. n = 828, except for income n = 827

5

Poetics 101 (2023) 101839

R. Latikka et al.

Table 2
The Hybrid Model Predicting Positive Attitudes Toward Using AI in the Art and Culture Field in General.
Within-person effects
Autonomy
Competence
Relatedness
Weekly use of smart technologies
Income
Works
Between-person effects
Autonomy
Competence
Relatedness
Weekly use of smart technologies
Income level
Works
Controls
Female gender
Age
College/univ. degree
Owns museum card
Art hobbies
Extroversion
Openness

B

Robust SE

p

0.03
0.01
0.04
0.11
− 0.15
0.09

0.02
0.03
0.02
0.12
0.08
0.19

.142
.633
.020
.366
.056
.650

0.00
0.02
0.13
0.07
0.01
0.03

0.02
0.02
0.02
0.11
0.04
0.12

.965
.217
< .001
.525
.727
.794

0.00
0.00
− 0.15
− 0.20
0.01
− 0.01
− 0.02

0.10
0.00
0.10
0.13
0.01
0.01
0.02

.995
.867
.135
.112
.536
.382
.126

Note. n = 827

Table 2 presents results of the model predicting positive attitudes toward using AI in the art and culture field in general. We found
positive within-person effects and between-person effects of relatedness in the use of new technologies on positive attitudes toward
using AI in art and culture in general. Other variables in the model did not reach the significance at the p < .05 level.
Table 3 presents results of the models predicting positive attitudes toward using AI in music, visual arts, detecting forged art, and
creating art. Regarding music, we found positive within-person and between-person effects of relatedness in the use of new tech­
nologies on positive attitudes toward using AI in music. Weekly use of smart technologies had a positive between-person effect on
positive attitudes toward using AI in music. Older age was negatively associated with positive attitudes toward using AI in music. Other
variables in the model did not reach significance at the p < .05 level.
Regarding visual arts, we found positive within-person and between-person effects of relatedness in the use of new technologies on
positive attitudes toward using AI in visual arts. Female gender was positively associated, and older age and extraversion were
Table 3
The Hybrid Model Predicting Positive Attitudes Toward Using AI in Music, Visual Arts, Detecting Forged Art, and Creating Art.
Music
Within-person effects
Autonomy
Competence
Relatedness
Weekly use of smart tech.
Income level
Works
Between-person effects
Autonomy
Competence
Relatedness
Weekly use of smart tech.
Income level
Works
Controls
Female gender
Age
College/univ. degree
Owns museum card
Art hobbies
Extroversion
Openness

Visual arts

Detecting forged art

Creating art

B

Robust SE

p

B

Robust SE

p

B

Robust SE

p

B

Robust SE

p

0.01
− 0.01
0.07
0.12
− 0.05
0.07

0.01
0.02
0.01
0.10
0.05
0.14

.366
.626
< .001
.219
.337
.624

0.03
0.01
0.08
0.09
0.01
− 0.11

0.01
0.02
0.01
0.10
0.05
0.16

.057
.565
< .001
.363
.903
.501

0.05
0.00
0.01
0.19
0.00
0.19

0.01
0.02
0.01
0.10
0.06
0.16

< .001
.833
.420
.055
.959
.226

0.05
0.02
0.04
0.21
0.02
− 0.27

0.02
0.02
0.02
0.11
0.06
0.16

.001
.210
.004
.061
.752
.097

0.02
0.03
0.16
0.42
0.02
− 0.01

0.02
0.02
0.02
0.11
0.04
0.11

.304
.066
< .001
< .001
.608
.946

0.03
0.02
0.17
0.19
0.01
0.00

0.02
0.02
0.02
0.10
0.04
0.11

.072
.227
< .001
.062
.760
.994

0.10
0.00
0.02
0.21
0.01
0.06

0.02
0.02
0.02
0.11
0.04
0.11

< .001
.767
.238
.049
.819
.566

0.06
0.01
0.12
0.23
− 0.04
− 0.02

0.02
0.02
0.02
0.11
0.04
0.11

< .001
.407
< .001
.037
.342
.862

0.13
− 0.01
0.00
− 0.07
0.01
− 0.01
− 0.01

0.09
0.00
0.09
0.13
0.01
0.01
0.01

.172
< .001
.981
.571
.291
.608
.576

0.23
− 0.01
0.05
0.03
0.02
− 0.03
0.00

0.09
0.00
0.09
0.13
0.01
0.01
0.01

.012
< .001
.543
.792
.123
.013
.870

0.09
0.01
0.22
0.33
− 0.01
0.01
0.04

0.08
0.00
0.08
0.11
0.01
0.01
0.01

.244
.080
.006
.003
.226
.135
.009

− 0.01
0.00
0.05
− 0.01
0.01
− 0.02
0.00

0.09
0.00
0.09
0.12
0.01
0.01
0.01

.950
.597
.578
.955
.282
.053
.804

Note. n = 827

6

Poetics 101 (2023) 101839

R. Latikka et al.

Fig. 1. The Word Cloud From Participants’ Answers to the Question “Which Three Words Would You Use to Describe Art Made by AI?” Note. n
= 828.

negatively associated with positive attitudes toward using AI in visual arts. Other variables in the model did not reach significance at
the p < .05 level.
Regarding detecting forged art, we found positive within-person and between-person effects of autonomy in the use of new
technologies on positive attitudes toward using AI in detecting forged art. Weekly use of smart technologies had a positive betweenperson effect on positive attitudes toward using AI in detecting forged art. Having a college or university degree, owning a museum
card, and openness to experiences were positively associated with positive attitudes toward using AI in detecting forged art. Other
variables in the model did not reach significance at the p < .05 level.
Regarding creating art, we found positive within-person and between-person effects of autonomy and relatedness in the use of new
technologies predicting positive attitudes toward using AI in creating art. Weekly use of smart technologies had a positive betweenperson effect on positive attitudes toward using AI in creating art. Other variables in the model did not reach significance at the p < .05
level.
The word cloud in Fig. 1 shows that participants mostly perceived the idea of AI-made art with curiosity, but apprehensive per­
ceptions were also present. The most common positive or neutral descriptions included answers such as interesting, modern, special,
abstract, surprising, technical, exciting, and colorful. Common negative descriptions were strange, artificial, boring, useless, cold, scary,
unknown, false, and insensitive.
6. Discussion
In this study, we investigated attitudes toward using AI in art. This is among the first longitudinal population studies on a topic that
is currently evolving and highly pressing due to the transformative development of AI and generative AI tools. Our findings provided
important evidence on how people perceive this change within two timepoints. More specifically, we analyzed positive attitudes
toward using AI in (a) the art and culture field in general, (b) music, (c) visual arts, (d) detecting forged art, and (e) creating art. The
results indicate individual differences in positivity toward using AI in art and they highlight the importance of experiences of relat­
edness and autonomy in the use of new technologies as antecedents of positive attitudes toward using AI in art.
The results supported our first hypothesis concerning relatedness. Stronger relatedness in the use of new technologies was con­
nected to more positive attitudes toward using AI in art in general and in three of the specific art contexts (music, visual arts, and
creating art). This was in line with previous research suggesting that perceived relatedness in the use of new technologies relates to
more positive attitudes toward AI (Bergdahl et al., 2023; Jiménez-Barreto et al., 2021; Park & Woo, 2022). One interpretation is that
when the need for relatedness is satisfied in technology use, individuals perceive the technology useful (Nikou & Economides, 2017;
7

Poetics 101 (2023) 101839

R. Latikka et al.

Fathali & Okada, 2018) and therefore, have positive attitudes toward it. Although similar prior evidence is limited in the art realm
specifically, one may think that feeling socially connected when using new technologies may generate positive user experiences that
enhance the perception of AI as new technology more favorably in general as well as in the more specific context of art. Having social
contacts that can be reached through technologies may also give individuals the impression that other people are positive about using
technologies, forming grounds for a social environment that promotes positive attitudes toward technology.
The results partly support our second hypothesis concerning autonomy in specific contexts. Higher perceived autonomy in the use
of new technologies was not connected to more positive attitudes toward using AI in art in general, in music, or in visual arts, but in the
specific contexts of detecting forged art and creating art, we found a positive connection. These are important findings because no prior
research has demonstrated these relationships regarding detecting and creating art specifically. Having autonomy that supports user
experiences of new technologies may enhance one’s curiosity to see what AI can do in such specific contexts. Highlighting AI as a tool
rather than a replacement, the detection of forged art may also be something that individuals who feel autonomous consider useful,
and therefore, they might support the idea of using it. Although AI cannot yet make art without any people’s input, some have voiced
fears that AI may eventually replace human artists (Epstein et al., 2020; Hong & Curran, 2019; Tubadji et al., 2021). The sense that
individuals still have control over new technology such as AI could explain the more positive attitudes toward AI as well as its role in
creating art.
Our results did not support our third hypothesis because perceived competence in the use of new technologies was not connected to
more positive attitudes toward using AI in general or the examined art contexts. The result is somewhat surprising because in the
psychological literature, competence (or self-efficacy) beliefs are well-established antecedents of human thinking and behavior
(Bandura, 1997; Ryan & Deci, 2017) and they are an important motivator in adopting new technologies (Peters et al., 2018). One
interpretation is that individuals’ need to feel capable and affective is not fulfilled or positively challenged when thinking of using AI in
the context of art, which may be an abstract or unfamiliar topic to many, as the results from the word cloud suggest.
In addition to our main findings, the additional and descriptive analyses revealed that the use of AI in art is perceived less positively
compared to many other fields such as medicine or building and real estate technology. The descriptive visual analysis showed that
although people viewed AI in the art field with curiosity, they also had concerns about AI in art being strange, false, cold, or even scary.
Thus, despite finding AI in art interesting from the perspective of something new and exciting, the responses also indicated a lack of
familiarity, authenticity, warmness, and safety. The results align with previous findings suggesting that people are more positive
toward using AI in applications and tasks involving big data and easily automated tasks relative to tasks involving more complexity and
human judgement (Ingrams et al., 2022; Schepman & Rodway, 2020) such as art. The word cloud shows many words describing
participants’ feelings toward AI-made art, which generally aligns with the idea that feelings associated with the attitude object play an
important role in forming attitudes when the attitude object is less familiar (van Giesen et al., 2015).
6.1. Theoretical and Practical Implications
Focusing on the case of AI in art, our study contributes to the theoretical discussions about the basic psychological needs and how
they predict our thinking and behavior intention in technology adoption. Based on our results, social factors such as relatedness to
others through the use of new technology have a major role in attitudes toward AI in art. Although autonomy seems to be critical in
some specific art contexts, competence to use new technology is the least influential psychological need behind attitudes toward AI in
art. The nonsignificant connection of competence to use new technologies with attitudes toward AI in art differs to some prior crosssectional studies suggesting an association between competence satisfaction and attitudes toward AI (Bergdahl et al., 2023; Park &
Woo, 2022). Hence, our results provide new insight that building people’s competence to use new technologies such as AI might not
affect their attitudes toward AI in art, but improving the sense of autonomy and especially relatedness within new technology might.
Generally, our results contribute to social psychological research on the relationships between the basic psychological needs
outlined in SDT (Ryan & Deci, 2017) and attitudes (e.g., Maio et al., 2018). Specifically, our results add knowledge of the relationships
between the basic psychological needs outlined in SDT and attitudes toward AI in the art context. As our results showed, AI attitudes
and their antecedents can be context specific, such as within a field of art, which stresses the importance of considering the context and
individual differences when trying to understand attitudes toward AI. Although previous studies have found SDT and its basic psy­
chological needs as an appropriate framework for understanding people’s perceptions on using new technologies such as AI (Bergdahl
et al., 2023; Gagné et al., 2022; Jiménez-Barreto et al., 2021; Park & Woo, 2022; Peters et al., 2018), our study demonstrates that SDT
offers a useful theoretical tool for analyzing attitudes also toward using AI in art, which is a new field in SDT research.
Our results also have practical implications. Based on our findings, people view using AI in the art field less positively than many
other fields where AI has already been adopted and established. Our visual analyses imply that the potential reasons for negativity
relate to a lack of familiarity, authenticity, warmness, and safety. This is understandable because human creativity has been considered
highly important in the art and culture field, and currently, the rapid development of generative AI challenges these prior conceptions
of art. Our findings on social aspects of AI adoption are important when considering the use of AI in the art field. The use of AI in art has
many aspects that do not necessarily challenge human creativity as such, but rather support it, one example being detecting forged art.
Our results help to understand social psychological aspects of accepting the use of these tools in art. The findings reveal that negativity
stems from, for example, unfamiliarity, unsafety, and unrelatedness. Supporting individuals’ positive user experiences with new
technologies, particularly the senses of relatedness and autonomy, could help enhance peoples’ positive attitudes toward AI in art.
Thus, the findings help to understand the reasons behind perceptions of AI in art that will eventually influence the societal discussions
and decision-making regarding the topic.
8

Poetics 101 (2023) 101839

R. Latikka et al.

6.2. Limitations and Future Directions
Our study has certain limitations concerning traditional self-reporting survey methods. To provide more reliability to our findings,
our study extended from solely cross-sectional to two-wave longitudinal data examination, thus enabling us to study within- and
between- person effects over time. Despite the initial longitudinal evidence, interpretations of causal relationships should be made
cautiously when using data from two timepoints only. Our analyses were based only on data from Finland, a country with its own
cultural characteristics (Purhonen et al., 2010), and therefore, the results cannot be directly generalized to other contexts. AI and robot
acceptance can be influenced by country-level factors comprising the sociotechnological environment that likely influences in­
dividuals’ opportunities to gain direct experience of AI devices (Turja & Oksanen, 2019; Vu & Lim, 2022). Because generative AI is
developing rapidly, it is important that future studies continue to investigate attitudes toward AI in different contexts, including art
and culture. This transformative change calls for new national and cross-national studies.
7. Conclusion
We used SDT and its three basic psychological needs to investigate attitudes toward using AI in art employing two-wave longi­
tudinal survey data from Finnish adults. The results showed that participants were less positive toward using AI in the art and culture
field in general compared to fields such as medicine and building and real estate technology. We detected within- and between-person
effects of both relatedness and autonomy on positive attitudes toward using AI in art. Participants who considered that new tech­
nologies helped them to feel related to others were generally more positive about AI in art. Based on our descriptive visual analysis,
many participants considered AI to be interesting and modern, but also strange and even scary. The use of AI in the art field currently
divides people. Our results highlight the importance of the human basic psychological needs and positive prior user experiences for
understanding attitudes toward AI in art and beyond.
CRediT authorship contribution statement
Rita Latikka: Conceptualization, Data curation, Formal analysis, Funding acquisition, Investigation, Methodology, Writing –
original draft, Writing – review & editing. Jenna Bergdahl: Conceptualization, Investigation, Writing – original draft, Writing – re­
view & editing. Nina Savela: Conceptualization, Data curation, Formal analysis, Funding acquisition, Investigation, Methodology,
Visualization, Writing – original draft, Writing – review & editing. Atte Oksanen: Conceptualization, Data curation, Funding
acquisition, Investigation, Methodology, Project administration, Supervision, Validation, Writing – original draft, Writing – review &
editing.
Declaration of Competing Interest
None.
Funding
This research received funding from the Kone Foundation (Urban utopias and dystopias: artificial intelligence in art and society
[UrbanAI] project 2021–2024, Grant 202011325, PI: Atte Oksanen). The data that support the findings of this study will be made
available in the Finnish Social Science Data Archive after the UrbanAI-project.
Supplementary materials
Supplementary material associated with this article can be found, in the online version, at doi:10.1016/j.poetic.2023.101839.


Abstract. Artificial intelligence (AI) is bringing new possibilities to numerous
fields. There have been a lot of discussions about the development of AI technologies and the challenges caused by AI such as job replacement and ethical issues.
However, it’s far from enough to systematically discuss how to use AI creatively
and how AI can enhance human creativity. After studying over 1,600 application
cases across more than 45 areas, and analyzing related academic publications, we
believe that focusing on the collaboration with AI will benefit us far more than
dwelling on the competing against AI. “AI Creativity” is the concept we want to
introduce here: the ability for human and AI to co-live and co-create by playing to
each other’s strengths to achieve more. AI is a complement to human intelligence,
and it consolidates wisdom from all achievements of mankind, making collaboration across time and space possible. AI empowers us throughout the entire creative
process, and makes creativity more accessible and more inclusive than ever. The
corresponding Human-AI Co-Creation Model we proposed explains the creative
process in the era of AI, with new possibilities brought by AI in each phase. In
addition, this model allows any “meaning-making” action to be enhanced by AI
and delivered in a more efficient way. The emphasis on collaboration is not only
an echo to the importance of teamwork, but is also a push for co-creation between
human and AI. The study of application cases shows that AI Creativity has been
making significant impact in various fields, bringing new possibilities to human
society and individuals, as well as new opportunities and challenges in technology,
society and education.
Keywords: Creativity · Artificial intelligence · Design methods and techniques ·
Design process management · HCI theories and methods · Education

1 Introduction
In recent years, Artificial intelligence (AI) is bringing new possibilities to numerous
fields from everyday life, industry application to scientific research. There have been a
© Springer Nature Switzerland AG 2021
M. Kurosu (Ed.): HCII 2021, LNCS 12762, pp. 171–190, 2021.
https://doi.org/10.1007/978-3-030-78462-1_13

172

Z. Wu et al.

lot of discussions about the development of AI technologies and the challenges caused
by AI such as job replacement and ethical issues. However, it’s far from enough to systematically discuss how to use AI creatively and how AI can enhance human creativity.
After studying over 1,600 application cases across more than 45 areas, and analyzing
related academic publications, we believe that focusing on the collaboration with AI will
benefit us far more than dwelling on the competing against AI [1, 2]. Among the human
dominant abilities, creativity is one of the most im-portant yet the least understood of
all intellectual abilities until today. It is a popular topic yet remains underdiscussing. It
is being refocused in the era of AI as the debate arose whether AI has creativity.
The purpose of this paper is to introduce the preliminary definition of “AI Creativity”
and the corresponding Human-AI Co-Creation Model. AI Creativity refers to the ability
for human and AI to co-live and co-create by playing to each other’s strengths to achieve
more. AI is a complement to human intelligence, and it consolidates wisdom from
all achievements of mankind, making collaboration across time and space possible. AI
empowers us throughout the entire creative process, and makes creativity more accessible
and more inclusive than ever. The corresponding Human-AI Co-Creation Model we
proposed explains the creative process in the era of AI, with new possibilities brought
by AI in each phase. In addition, this model allows any “meaning-making” action to be
enhanced by AI and delivered in a more efficient way. The emphasis on collaboration
is not only an echo to the importance of teamwork, but is also a push for co-creation
between human and AI.
By illustrating the application cases in various areas, this paper explains that AI
Creativity is a new philosophy to collaborate with all achievements of mankind across
time and space, a new strategy to boost productivity and to inspire innovation, and a new
force to empower human to access creativity inclusively more than ever.

2 Related Work
2.1 The Rise of AI and Potential Impacts
The application of AI has already made significant impacts in businesses around the
world. Between 34% and 44% of global companies surveyed are using AI in their IT
departments mainly in information technology, marketing, finance and accounting, and
customer service, monitoring huge volumes of machine-to-machine activities [3].
AI Industries is becoming the new engine of economic development. According to
recent reports, the potential contribution of AI to the global economy will reach $15.7
trillion, bringing a GDP boost of up to 26% to local economies [4]. 29–62% of annual
growth rate of GVA (gross value added) comes from AI by 2035 across 16 industries in
12 economies, which could lead to an economic boost of US$14 trillion [5].
In these circumstances, people are concerned that AI is on the verge of reaching and
challenging “human-level intelligence,” with recent evidences suggesting that workforce
transitions from human to AI has been triggered. A report by McKinsey [6] says, “50% of
the time spent on work activities in the global economy could theoretically be automated
by adapting currently demonstrated technologies”. The most quoted study of occupations
likely to be automated in the next decade by Oxford University [7] also predicted up to
47% replacement of the workforce in US. A following study by Asian Development Bank

AI Creativity and the Human-AI Co-creation Model

173

[8] concluded that routine, cognitive and manual work would be the most vulnerable,
and the time spent on different activities which can be replaced ranges from 9% to 78%.
2.2 Collaboration Between Humans and AI
AI is relatively strong when it comes to repetitive and predictable workflow, and super
good at dealing with complexity and multi-tasking; while humans are flexible and creative, and adept at knowledge understanding and strategic thinking, as is summarized in
the figure below. Collaboration between humans and AI varies across domains [9, 10].
Human leads where tasks are more about creative or strategy and compassion is needed,
while AI leads where tasks are more about routine or optimization and compassion is
not needed (Fig. 1).

Fig. 1. (a) Human-AI complement each other, (b) Blueprint of Human-AI collaboration [10]

2.3 AI and Creativity
Creativity Research is Mainly About People, Methods and Tools Before the Era of AI.
Creativity is often considered as an “intuition” and can’t be easily interpreted in a rational way. The creative industries often refer to graphic design, film, music, video game,
fashion, advertising, media, or entertainment industries [11], related to the extraordinary
thinking by supreme creative individuals [12]. However, creativity actually lies in all
creating activities, from art to science, from everyday life to industry production. And
the thinking behind creativity and all those great creations can be acquired by ordinary
people with deliberate practice [12]. Some recent studies summarized creativity as a
“multifaceted phenomenon to form value and produce innovation entailing the generation of new intangible or physical item” [13, 14]. In discussing how to define, measure,
and enhance the impact of creativity, scholars have proposed three dichotomies: firstly,
whether creativity orginates within individual or comes from social; secondly, whether
creative artifacts should be of novelty or value; and thirdly, whether creative activity is
a thought or an action [15].
In recent decades, great progress has been made by an increasing number of scholars
and researcher with different backgrounds, including cognitive science, psychology,

174

Z. Wu et al.

philosophy, computer science, logic, mathematics, sociology, architecture, design and
etc. The emerging concepts such as digital creativity [16] and computational creativity1
[17] also shed some light on the concept of AI Creativity. With the new possibilities AI
bringing in, the research on AI Creativity will help us use AI creatively and enhance
human creativity efficiently and effectively.
The Creativity of AI is Inseparable from Human’s. From AlphaGo to AlphaFold
[18, 19], AI created something which have never existed before, although researchers
still hold different viewpoints on whether AI has creativity [20–23]. Theories and algorithms were invented to imitate and go beyond human’s ways of thinking, using the past
achievements of mankind, such as internet data, as training data for AI. Furthermore, as
lack of understanding causality of the real world, AI has to be designed for interactive
use by humans and enhance human creativity [20, 24]. No matter how far AI can go
on creativity in the future, human judgment should always be kept essential through the
creative process, so to make sure AI Creativity serves humanity. The creativity of AI
can be considered as a new tool but also beyond a tool.
Human Creativity is to be Enhanced by AI. More and more scholars are studying the
AI-powered, AI-enhanced or AI-assisted human creativity [24, 25], reporting the application of AI in the creativity industry [26] and Art industries [27]. Designers and design
researchers also discussed and practiced design with data [28, 29]. Most of the existing
reports categorize application cases by disciplines or technologies [1, 30], while the
report we made, CREO AI Creativity Report 2021, presents the typical cases in the creative process of our Human-AI Co-Creation Model. Our study shows that AI can work
far more than a black box, but can assists humans throughout the entire creative process.
Human input serves as the framework of this process.

2.4 The Study of Creativity
The Theories of Creativity. One major opinion in early creativity research argued
whether creativity is “unconscious thinking” or “unconscious processing” [31, 32], a
sudden appearance of an idea [33] or leaps of insight [34, 35]. These theories undoubtedly demonstrated the mysterious nature of creativity or the extraordinary thinking of
some creative individuals, which makes ordinary people think that creativity is far away
from them.
Measurement psychology suggested that every individual has creativity, with “divergent thinking” and “convergent thinking” involved [36]. Their study identified the main
components in creative thinking, but lacked the analyzing of the functional mechanisms
of creative process. Guilford [37] further construed creativity as a form of problemsolving and argues that the creator’s sensitivity to the problem is the key to initiating
creation. In the era of AI, various sensors and big data gives humans expanded views in
both perceptual and rational perspectives.
1 Computational creativity also known as artificial creativity, mechanical creativity, creative

computing or creative computation.

AI Creativity and the Human-AI Co-creation Model

175

Evolutionary theories of creativity [38] suggested that the creative process is similar
to Darwinian evolution: Innovative ideas are generated based on early ones and tested
with the latest conditions [35]. The Human-AI Co-Creation Model is consistent with this
theory: Upon input, AI can generate a myriad of explorations and present the preliminary
selections for humans to choose for further “evolving”.
Cognitive theories of creativity believed that the processes of creative thinking and
thinking involved in solving ordinary problems are basically the same [39], and creative
products come through the process of ordinary thinking [12]. This view brings creativity
and ordinary people closer together. With AI empowering in all phases of the creative
process, people can access creativity inclusively more than ever.
In recent years, new theoretical frameworks proposed from the perspective of brain
science have systematically elaborated the interaction between knowledge and creative
thinking [40]. The studies of creative cognition through medical imaging have opened
up new possibilities for the measurement of creativity [41]. It also provides valuable
references for the development of AI.
The Methods of Creativity. These methods encourage creative actions and have
demonstrated their usefulness in both arts and sciences [42], usually covering information acquisition, idea generation, problem reframing, prototyping, testing, iterating
and etc. [43].
Some of them are for guiding the creative process, such as TRIZ [44] (and its modifications and derivatives such as SIT and USIT), CPS (Creative Problem Solving) [45],
Design Thinking [46], Double Diamond Model [47], First Principles [48]. Others provide different thinking principles and toolkits, such as Six Thinking Hats [49], Herrmann Brain Dominance Instrument [50], Lateral Thinking, Brainstorming, Brainwriting, Think Outside the Box, SWOT Analysis, Thought Experience, and Five Ws. As
internet technology advanced, new methods came in such as Data-Driven Design [28],
HEART & GSM [51], Agile Development [52], Design Sprint [53].
Most of the methods listed above are in the context of problem solving. However,
meaning making including painting and music composing, is not necessarily only about
problem solving.
The Abilities of Creativity. Creativity tests summarized the abilities of creativity.
Structure of Intellect theory (SOI) [54] by Guilford organizes intellectual abilities in
three categories: operations, content and products. Operations dimension included six
general intellectual processes. Built on SOI, Torrance Tests of Creative Thinking (TTCT)
[55] involves simple tests of divergent thinking and other problem-solving skills. Several controversial creativity tests, such as Getzels and Jackson’s exploration [56] and
Wallach and Kogan’s study [57] had significant impact in the research area (Table 1).
Future-oriented creativity requires people to learn and create in a constantly evolving technological landscape. ISTE (International Society for Technology in Education)
provided a well-recognized standard for student to become a transformative learner [58].
AIK12 [59] provided a list of criteria of competencies for young people to have in the
era of AI.
From the current study of creativity, some characteristics were found: The classical
creativity theories have less discussion on the discovery strategies before the problem

176

Z. Wu et al.

emerges. The existing creativity methods are mainly for problem solving or product
innovation, but not for other meaning-making activities; Besides, these methods lay
no emphasis on collaboration. The Human-AI Co-Creation Model we proposed introduces new possibilities brought by AI throughout the creative process, allows any
“meaning-making” action to be enhanced by AI and delivered in a more efficient way,
and emphasizes on collaboration no mater it’s interpersonally or between hu-man and AI.
This model also well supports the creativity abilities reflected in the ex-isting creativity
assessment standards such as ISTE and aik12.

Table 1. Main process/components in current study of creativity
Theories/methods/abilities

Main process/components

Psychometrics

Divergent thinking, Convergent thinking

Evolutionary Theories

Randomness, Conditions, Selection

Cognitive Perspective

Remembering, Imagining, Planning, Deciding

Brain Research

Knowledge Domain: Emotional, Cognitive
Processing Model: Deliberate, Spontaneous

TRIZ (ARIZ)

Abstraction, Solution, Concretization

CPS (Creative Problem Solving)

Clarify, Ideate, Develop, Implement

Design Thinking

Empathize, Define, Ideate, Prototype, Test

Double Diamond

Challenge, Discover, Define, Develop, Deliver, Outcome

First Principles Thinking

Identify problems and define assumptions, Breakdown the problem into its fundamental
principles, Create new solutions based on the deductions of those principles

Six Thinking Hats

White Hat – Facts and Information. Red Hat – Feeling and Intuition. Black Hat – Caution and
Problems. Yellow Hat – Benefits and Advantages. Blue Hat – Managing Thinking. Green Hat
– Creativity and Solution.

The Whole Brain Thinking Model

Analytical Thinking, Structural Thinking, Relational Thinking, Experimental Thinking

Data-Driven Design

Goal, Problem/Opportunity Area, Hypothesis, Test, Result

HEART & GSM

Happiness, Engagement, Adoption, Retention, Task Success; Goals, Signals and Metrics

Agile Development

Requirements, Design, Development, Testing, Deployment, Review

Design Sprint

Map, Sketch, Decide, Prototype, Test

SOI’s (Structure of Intelligence)
Operations Dimension

Cognition, Memory recording, Memory retention, Divergent production, Convergent
production, Evaluation

TTCT (Torrance Tests of Creative Thinking)

Fluency, Flexibility, Originality, Elaboration

5C Core Competences

Cultural Competence, Creativity, Collaboration, Critical Thinking, Communication

ISTE

Empowered learner, Digital citizen, Knowledge constructor, Innovative Designer,
Computational Thinker, Creative communicator, Global Collaborator

Human-AI Co-Creation Model

Perceive, Think, Express, Collaborate, Build, Test

3 The “AI Creativity”
3.1 Preliminary Definition of AI Creativity
Combining the above points of view, we make our own preliminary definition: AI creativity is the ability for human and AI to live and create together by playing to each
other’s strengths. It is a new philosophy, a new strategy, and a new force.
AI Creativity can be perceived as a new philosophy. Through AI, people can collaborate with all achievements of mankind across time and space. It’s well demonstrated

AI Creativity and the Human-AI Co-creation Model

177

in the making of Portrait of Edmond Belamy: the original algorithm by Americans, the
implementation by Frenchmen, and the AI trained with 15,000 human paintings from
between the 14th and 20th centuries.
AI Creativity can be conceived as a new strategy. Human and AI can play to each
other’s strengths and embrace more possibilities efficiently. Thus human and AI can
complement each other throughout the entire creative process, boosting productivity
and inspiring innovation.
AI Creativity can be regared as a new force. Empowered by AI, human can access
creativity inclusively more than ever. AI creativity can lower the bar to enter an area and
enable human to focus on the most creative part, leaving the complex or time-consuming
tasks to AI.
3.2 AI Creativity Reshapes Creative Process
The “Human-AI Co-Creation Model” is a circular process model including 6 major
phases: perceiving, thinking, expressing, collaborating, building and testing (Fig. 2).

Fig. 2. The Human-AI co-creation model

The first phase is to persive, where human perception can be enhanced by big data
and sensors with AI. Beyond the Senses that humans normally perceive the world with,
AI can turn big data into meaningful information and knowledge using all kinds of
sensors and networks, giving human expanded views in both perceptual and rational
perspectives. The second phase is to think, where humans can think deeper and wider with
AI. Inspiration and exploration that AI brings can go far more than human considerations.
This will break the limits of resource and help human think deeper, wider, in a more
thorough but also efficient way, potentially leading to unexpected accomplishments.
The third phase is to express, where humans can explore more and rapidly with AI.
Various ideas and diverse people need their optimal ways to present, such as painting,
designing, composing, writing, performing, coding, prototyping… Empowered by AI
tools, people won’t be stopped for lack of talent or training. Creativity matters more
than skills. The fourth phase is to collaborate, where human and AI play to each other’s

178

Z. Wu et al.

strengths. Whether working alone or with others, people can always team up with AI.
Just fully understand the strengths and limitations of both human and AI, and give each
side the best assignment. The fifth phase and the sixth are to build and test, where
production can achieve higher quality and lower cost by simulating and analyzing with
AI. Rehearsing gives people a chance to predict how things will go and to prepare
ourselves for real-world events. With detailed simulation and calculation offered by AI,
the process and result of building and testing can be handled effectively and efficiently.
During this creative process, human and AI can complement each other and unleash the
great potential of both sides.

4 The Application of “AI Creativity”
4.1 AI Creativity Prospering Across Industries
We analyzed over 1,600 AI Creativity cases across more than 45 areas from 2017 to
2020. An AI application is only qualified as an AI Creativity case when AI is used
creatively or AI enhances human creativity. Culture and entertainment contributes the
most cases until now, mainly in the format of digital media, which is easier to go with
AI; Cases in industry and lifestyle are trying to bridge the virtual world and the physical
world, which has a great potential to grow; The big percentage in science suggests that
it’s still the early phase of exploration overall; A lot more subcategories will rise from
the misc. as AI moves forward (Fig. 3).
4.2 Examples Throughout the Human-AI Co-creation Model
Perceive. The sound of cellphone-recorded coughs can be used to detect asymptomatic
Covid-19 infections (Fig. 4a). Only AI could achieve high accuracy and efficiency for
this purpose because neither doctor can be effectively trained on this, nor can enough
doctors be trained around the globe for this. It demonstrates the huge potential of AI
assisted diagnosis [60, 61].
Sensors such as cameras, LiDAR and millimeter-wave radar on autonomous driving
cars (Fig. 4b), do not only help humans get an all-direction and all-weather view, but
also give humans smart advice based on object detection and analysis [62].
IoT connects machines, objects, animals and people in increasingly numerous ways
(Fig. 4c). As each pig is recognized and traced, customized plans can be applied. Such
a detailed overview enables humans to have a better understanding and greater control
over their work and life [63].
Ambient Intelligence makes physical spaces sensitive and responsive to the presence
of humans (Fig. 4d). It enables more efficient clinical workflows and improved patient
safety in hospital spaces. It could also help the elderly with chronic diseases in daily
living spaces [64].
Think. Predicting the protein structure, AlphaFold unlocked a greater understanding
of what it does and how it works (Fig. 5a). From AlphaGo, AlphaStar to AlphaFold,
AI demonstrated new methods and great potential to learn and solve complex problems
effectively and efficiently through massive exploration [19].

AI Creativity and the Human-AI Co-creation Model

179

Fig. 3. AI creativity cases across industries: (a) By name of subcategories, (b) By number

Multi-Channel human-machine interaction allows humans to communicate with AI
in a natural way [68], such as searching by color and shape (Fig. 5b). Making AI adapt
to the human way, it brings not only comfort, but also efficiency [65].
Inspired by the knowledge graph based on the search queries on internet, people can
get a better overview of the object studied and can trigger more relevant ideas around
it (Fig. 5c). With the help of AI, the world’s knowledge can be organized and accessed
more than ever, and then further developed into new concepts [66].
Simulating a simple game of hide-and-seek, agents built a series of distinct strategies
and counterstrategies, some of which were unexpected (Fig. 5d). This further suggests
extremely complex and intelligent behaviors could be synthesized [67].

180

Z. Wu et al.

Fig. 4. (a) Cough test for Covid-19 by MIT [60]. (b) Lidar and camera view at night by Waymo
[62]. (c) Pig recognition and smart farming by JD.com [63]. (d) Illuminating the dark spaces of
healthcare with ambient intelligence by Li Fei-Fei et al. [64]

Express. It’s not a dream anymore to have a “Magic brush” that turns a doodle into a
photo. As if done by an experienced artist or designer, AI turns people’s rough ideas into
reality (Fig. 6a). AI helps humans focus more on generating and testing ideas without
worrying about the presenting skills [69]. And DALL·E released in Jan 2021 is pushing
this to the next level.
AI can work as a friend sharing ideas with humans, responding and inspiring each
other to make a story gradually (Fig. 6b). From such a game today, we can foresee that
the future of collaborative writing between human and AI is coming [70].
With the help of AI, humans can play any role in any context by controlling characters through body and face movements (Fig. 6c). The making of animations and
demonstrations becomes easier [71].
Coding has a history of becoming easier to use, and AI will speed up this process
(Fig. 6d). Although the making of high-quality software still requires experienced engineers, it will be world-changing to enable everyone to create their own software by
talking, writing, drawing, playing with building blocks, not only by coding [72].

AI Creativity and the Human-AI Co-creation Model

181

Fig. 5. (a) AlphaFold on protein folding problem by DeepMind [19]. (b) Street art by color
by Google Arts & Culture [65]. (c) Knowledge graph of google searches by Anvaka [66]. (d)
Simulation of multi-agent hide and seek by OpenAI [67]

Build and Test. In the context of product manufacturing, AI allows designers and engineers to input their design goals, along with parameters such as materials, manufacturing
methods, and cost constraints (Fig. 7a). Then AI explores all the possible solutions by
testing and iterating [73].
Qualitative changes can happen when quantitative changes are big enough. Personalization comes after. Alibaba Luban’s design engine has demonstrated how powerful
the true personalization is, as so does TikTok’s recommendation engine (Fig. 7b). AI is
the key to enable massive design and implementation efficiently at low cost [74].
A process that takes generations of evolution in the physical world can be simulated
in the virtual world at much higher speeds. Through the design and making of Xenobots,
biology and computer scientists worked together and significantly speeded up the process
of trial and error (Fig. 7c) [75].
Digital Twin brings parallel universe to reality. Building and testing happens in the
virtual world and the best solution can be chosen to implement in the physical world
(Fig. 7d). Meanwhile, anything manifesting in the physical world can be reflected in the
virtual world for further analysis and exploration [76].

182

Z. Wu et al.

Fig. 6. (a) GauGAN by NVIDIA [69]. (b) AI Dungeon by Latitude [70]. (c) Animation production
with Kuaishou & PuppetMaster [71]. (d) Build apps by describing in words with debuild, powered
by GPT-3 [72]

Collaborate. We placed collaborating at the end instead of as its sequence in the model,
because it’s a great example demonstrating the creative process enhanced by AI. Art
styles are among the great achievements of civilizations. It’s almost impossible for a
human to master every style of art, but it’s not hard for AI (Fig. 8a). Trained with
examples of various artistic styles, AI can imitate any one of them. Based on the variations
developed upon the input, the best parts can be picked for further development2 .
Expressing in an ancient language is much harder than understanding it. However,
given enough training materials, it’s no different for AI to learn a modern language or
an ancient one (Fig. 8b). Such a poetry AI can give human many inspirations, although
it’s not perfect, nor does it have a soul3 .

2 The painting by Mr. HOW with Deep Dream Generator: https://deepdreamgenerator.com/.
3 The poem Mr. HOW with Tsinghua JiuGe: http://118.190.162.99:8080/, Microsoft JueJu: http://

couplet.msra.cn/jueju/ and SouYun: https://sou-yun.cn/MAnalyzePoem.aspx.

AI Creativity and the Human-AI Co-creation Model

183

Fig. 7. (a) “The first chair created with AI” by Philippe Starck, Autodesk & Kartell [73]. (b)
Alibaba Luban’s AI banner design [74]. (c) Xenobots: first living robots by University of Vermont
[75]. (d) Collaborative robots in assembly by University of Southern Denmark [76]

Breaking language barriers, AI helps regular people to enjoy different cultures and
create things more easily (Fig. 8c) [77]. In this case, the poem in ancient Chinese was
firstly translated into modern Chinese by human, then into English by AI, and then
fine-tuned by human in the end4 .
Not everyone can make music although it’s a universal language (Fig. 8d). Music AI
allows people to bring out the rhythm and rhyme from their heart and mind. Based on
the initial input, variations will be generated for picking for further developing5 .
As the ending of a traditional Chinese painting, a stamp was used, which is actually
a QR code linked to the video of the making of this artwork6 .

4 The poem translated by Mr. HOW with Google, Apple and Microsoft Translation.
5 The music by Mr. HOW with LingDongYin: https://demo.lazycomposer.com/compose/v2/.
6 The making of the artwork, The Mind of AI Creativity: http://qr09.cn/Ew06EW.

184

Z. Wu et al.

Fig. 8. The mind of AI creativity (a) Painting, (b) Poem in Chinese, (c) Poem in English, (d)
Music composing

5 The Future of AI Creativity
5.1 Developing AI Creativity
The adoption of AI is expected to run high across industries, company sizes and geography [78]. Skills of using AI as a demand in all online job vacancies have been
rapidly increasing especially since 2015 [79]. AI talents include technology developers,
technology-product transformers [80], and product utilizers. All of them need AI Creativity, mastering AI thinking and skills. Regardless of interests or specialties, people
can always find effective ways to develop their AI Creativity.
Collaborative creation between human and AI will be seen everywhere. Processes are
enhanced or even evolved in every step where AI enters. STEM-DAL [81] is a new way
to inspire and leverage AI Creativity in cross-disciplinary learning and creation. Science
and Art stand at the two ends. Technology brings Science into application, while Design
brings Art into application. Meanwhile, Engineering merges Technology and Design,
while Mathematics and Literature serve as foundations (Fig. 9).
In recent years, some educational initiatives have proposed some new concepts and
practices for AI education in addition to coding, such as AI4ALL [82], aik12-MIT [59]
and Mr. HOW AI Creativity Academy [81]. These initiatives are trying to make AI
education inclusively accessible for all people with different interests and specialties,
beyond technology perspectives only. Great potential remains yet to be unleashed.

AI Creativity and the Human-AI Co-creation Model

185

Fig. 9. The STEM-DAL model

5.2 Challenges and Opportunities
Technology Perspective. Pre-Mature AI technologies are still the norm, although there
has been a huge leap since the modern era of deep learning began at the 2012 ImageNet
competition. Scientists are working hard on the next generation of AI to break today’s
constrains. New initiatives such as GPT-3 aren’t perfect, but it did unleash new potentials.
Incomplete solutions built on separate technologies according to proprietary standards are very common. Doing anything with AI often relies heavily on experts and wellfunded organizations. This stands in the way of more people adopting AI technologies
and unleash the great potential of AI Creativity.
Limited Resources invested in the industry today are mainly driven by capital for to
maximize financial returns. As more scientists, engineers and other resources are added
to transform AI technologies into more products, more areas will be covered and driven
by AI Creativity.
Attacks on AI raises the alert of AI security. A simple attack can cause AI to see
something different than what an image really looks like, so a T-shirt with a special
pattern can render someone “invisible” to cameras, or an autonomous car misread an
altered traffic sign. Addressing the security issue also needs AI Creativity.
Society Perspective. Privacy could become very vulnerable in the era of AI. Individuals could become transparent to all kinds of ubiquitous sensors and AI applications
with recognition and analysis abilities. It’s not always easy to balance privacy with
convenience. AI Creativity may help to make smart decisions.
Abuse of AI has been documented, such as unwanted facial recognition, spam calls,
deepfake videos, etc. Anyone of those could set you in trouble. As more people access
more AI applications, potential for abuse will increase. AI Creativity can contribute in
preventing this.
Discrimination follows from human behaviors, as AI is trained with materials that
humans generated. As a technical issue, things like accuracy of facial recognition across
different human races can be easily improved. However, things like the bias in resume
screening may need a lot of AI Creativity to address.
Job Replacement is a hot topic, especially for parents. However, many parents
wouldn’t necessarily want their children to do the jobs AI is going to replace. Rather
than worrying about potential job replacement, it’s more important to think about how

186

Z. Wu et al.

to inspire and develop AI Creativity for both yourself and future generations, and how
to live and create with AI.

I don't agree
with this
paragraph.

Education Perspective. Exploration in the AI education system is key for developing
talents. What to learn, how to train, whether AI should be an independent discipline or
intertwined with other ones… The answers to these questions will only emerge through
deep thinking and practice. AI Creativity itself shall be used in these explorations.
Liberal Arts + AI education is almost an untouched area, when compared with
STEM, robotics and coding. As part of AI Creativity, the fusion of liberal arts and AI
will be critical. It’s not only to give all kids a balanced education in addition to STEM
learning, but also to provide a method of development for kids who do not have an
aptitude for STEM.
Thinking vs Skills are both important things to learn for AI Creativity. AI thinking
is for choosing the right strategy, while skills are for choosing the right tactics. They
support each other and can’t live without each other.
Democratizing AI and Creativity will be a key outcome of AI Creativity education.
People will be empowered to go beyond their current level, to live and create with AI
by playing to each other’s strengths.

6 Conclusion
AI Creativity has been making significant impact in various fields, bringing new possibilities and challenges to human society and individuals. The topic of cultivating AI
Creativity has a great value and potential to be explored. For professionals, the evolved
thinkings and methods need to be built up, such as the Human-AI Co-Creation Model
we proposed; For educators, the inclusive AI education system needs to be built up, such
as the STEM-DAL system we proposed, which will be discussed in another paper; For
scholars, the framework of measuring AI Creativity needs to be built up. For everyone,
how to unleash the great potential of AI Creativity and how to prevent the unexpected
consequences need to be discussed. We initiated CREO (Creativity Renaissance in Education and Organizations) with experts around the world, and will keep pushing the
boundary of AI Creativity.
Acknowledgements. The authors like to thank Qinwen Chen, Guojie Qi, Peiqi Su, Qing Sheng,
Jieqiong Li, Qianqiu Qiu, Linda Li and all the volunteers for their contribution in this paper.

This study explores university students’ engagement with Generative Artificial Intelligence
(GenAI) tools for creative writing and graphic storytelling, drawing on Jacques Rancière’s phi­
losophy of intellectual equality and emancipation. Qualitative data analysis from a co-curricular
creative writing programme, including reflections, surveys, and focus-group interviews, reveals
emerging artificial intelligence literacies and students’ improvisational aptitudes for interpreting,
subverting, and transforming notions of authorship. Students decentred authorial attribution
through the pragmatic adoption of the technology as a creative catalyst, negotiated creative
conventions by adopting non-conventional communication strategies, and reconceptualised
creativity as distributed across human and non-human agents. Our approach of student-driven
learning for autonomous exploration, sense-making, and criticality with GenAI indicates the
potential for promoting conditions for students to exercise intellectual equality and emancipation.
The findings contribute to the understanding of authorship and creativity; begin to contour
emerging GenAI literacies and competencies; and suggest that creative collaborations with GenAI
may be a promising way to foster emancipatory practices in the classroom, while nurturing
creative and critical skills.

1. Introduction
Recent mainstream popularisation and development of new Artificial Intelligence (AI) tools for generative, creative work open
radical new possibilities for disrupting traditional notions of creativity, authorship and the creative process. Generative Artificial
Intelligence (GenAI), including Large Language Models (LLMs), encompasses a proliferating family of AI systems typically built on
foundation models rooted in advanced neural networks to generate diverse modalities (including text, images, audio, and videos)
based on human instructional prompts. These systems leverage advanced machine learning methodologies, such as deep learning and
reinforcement learning, to discern patterns and structures from extensive unstructured and publicly accessible datasets, producing
original and coherent outputs and performing multiple tasks. The remarkable adaptability and natural language proficiency of LLMs,
exemplified by OpenAI’s cutting-edge language model, GPT-X, along with innovative digital art creation tools like DALL-E, Mid­
journey, and the open-sourced Stable Diffusion, have vastly enhanced AI’s utility for the general public and fostered experimentation
and active online communities among non-experts. In this context, "non-experts" refers to enthusiasts, hobbyists, or casual users,
including artists, writers, educators, students, who, despite not having formal training or extensive experience in AI, engage with AI
* Corresponding author.
E-mail address: jtsao@hku.hk (J. Tsao).
https://doi.org/10.1016/j.poetic.2024.101865
Received 28 August 2023; Received in revised form 20 December 2023; Accepted 10 January 2024
Available online 17 January 2024
0304-422X/© 2024 Elsevier B.V. All rights reserved.

Poetics 102 (2024) 101865

J. Tsao and C. Nogues

tools for creative work or other purposes. For instance, the online Discord community of the image generation app Midjourney,
established in July 2022, has exponentially acquired over 16 million users within one year, becoming the largest collaborative and
knowledge-sharing community for GenAI image generation. Crucially, GenAI systems transcend mere data repositories or discrimi­
native machine learning models, instead functioning as reasoning apparatuses and possessing significant potential to transform,
automate, and augment knowledge-related tasks across numerous sectors. McKinsey and Company (2023) estimates GenAI can
perform more than 2100 detailed work activities, impacting 850 occupations and stimulating new frontiers in creativity and inno­
vation. This development has precipitated robust educational debates and reflections regarding reforming curriculum, pedagogy, and
assessment and structural constraints of schools and universities.
Our empirical investigation examines the engagement of undergraduate and postgraduate students from two Hong Kong univer­
sities in a co-curricular creative writing programme, focusing on the student’s negotiation and mediation of GenAI in the creative
production process. Utilising Rancière’s (1991) concepts of intellectual equality and emancipation, we explore the entanglement of
technology with educational, aesthetic, and political value and the implications for educators’ roles within the creative production and
learning process. In its emphasis on the views of university students themselves throughout the human-GenAI co-creative writing,
image generation, and workshopping process, this investigation embodies what Davis (2010) sees as a practice of Rancière’s political
and aesthetic philosophy and radical egalitarianism. However, beyond a praxis of intellectual emancipation through creative writing,
our study also encourages educators to re-think how knowledge is produced and how to radicalise traditional teaching and learning of
creative practices through cultivating the competencies and orientations required to co-create with AI. It contributes to the nascent
corpus of research at the intersection between GenAI and creativity in education, pointing to how creative collaborative practices with
GenAI could serve to nurture creativity, critical thinking skills, and ethical awareness. By “ethical awareness,” we mean a student’s
capacity to understand the moral and societal implications of their actions, considering issues such as fairness, justice, responsibility,
data privacy, algorithmic bias, the digital divide, and the societal impacts of AI-generated content in their engagement with GenAI.
While creativity has been shown to be a contested concept from a sociological lens, here our sense of the term aligns with Godart
et al.’s (2020) understanding of creativity as an “intentional configuration of cultural and material elements that is unexpected for a
given audience” (p. 489) and with Novak-Leonard’s (2022) emphasis on creativity as what a person does through problem-solving to
actualise ideas into reality both individually and in groups. The use of image is grounded in Sgourev’s (2021) conception that
perception and optics are indissolubly connected to creativity and imagination.
2. Intellectual equality and emancipation
Our study draws on Rancière’s (1991) notions of intellectual equality and emancipation to provide a critical theoretical framework
for examining students’ co-creative production with GenAI. Rancière conceives his philosophy based on the concept of “universal
teaching” discovered by Joseph Jacotot, a nineteenth-century French professor, whereby his Flemish students learnt French through a
bilingual edition of Fenelon’s Les Aventures de Telemaque, despite Jacotot’s ignorance of Flemish. The core of Rancière’s (1991)
philosophy is that all social actors are “thinking beings” and have equal intellectual abilities for understanding, comparing, and
forming knowledge (pp. 9, 34). He argues that differences in performance stem from variations in students’ attention or willingness to
learn affected by their social contexts. Rancière criticises the “structuring fiction” (p. 80) of knowledge transmission that falsely
presupposes a dependency on learned teachers in guiding ignorant students from simple to complex concepts. He blames this expli­
catory order as complicit in stultification and perpetuating a culture of inattention. Instead, Rancière refers to Jacotot’s idea of learning
and creative processes as movements in a circular, rather than a linear or progressive, motion (p. 55). Rancière views intelligence and
equality as interconnected and involving the ability to communicate and verify knowledge with others. Clarifying Rancière (1991, pp.
84 - 85), Ewalt (2016) distinguishes between poetics and rhetoric as fluid conceptual poles on a spectrum of communicative forces.
Poetics operates under the presumption of human equality and invites a reciprocal dialogue between equals, envisioning a commu­
nicative space where every individual can be both listener and speaker, thereby challenging traditional dichotomies. On the other
hand, rhetoric assumes a pre-existing inequality and can contribute to stultification. Rather than dismissing the value or relevance of
rhetoric, it highlights its potential to perpetuate a hierarchy between the speaker and the listener, the positions of “knowing” and “not
knowing”. Hence, intellectual equality comes into view when poetics, rather than rhetoric, is primary, and the distinction between
speakers and listeners diminishes (Hjulström & Rytzler, 2022). This interpretation provides a lens through which to view the
entanglement of technology with educational, aesthetic, and political value in GenAI’s creative processes.
Following intellectual equality, intellectual emancipation challenges hierarchical knowledge structures as arbitrary and “liberates”
thought by questioning norms within a knowledge domain. Hence, this emancipation is connected to Rancière’s philosophy around
dissensus, as clarified by Corcoran (2010):
“…the disruption that [genuine political or artistic activities] effect is not simply a reordering of the relations of power between
existing groups; dissensus is not an institutional overturning. It is an activity that cuts across forms of cultural and identity
belonging and hierarchies between discourses and genres, working to introduce new subjects and heterogeneous objects into
the field of perception.” (p. 2)
In theorising what he calls “the distribution of the sensible”, Rancière (2004) describes how social communities develop specific
language usage guidelines delineating what can be seen, heard, and thought (the “sensible”). His-theories suggest expertise is not
essential for new ideas, as it often perpetuates norms and the status quo, mirroring Williams’ (1977) earlier analysis of modes of
domination and the social context of authorship. Instead, Rancière (1991) values the approach of an “ignorant schoolmaster” like
Jacotot, who “doesn’t have to worry about what the emancipated person learns. He will learn what he wants, nothing maybe” (p. 18).
2

Poetics 102 (2024) 101865

J. Tsao and C. Nogues

Biesta (2016) clarifies that Rancière’s focus is not on forbidding explication but on asserting that it is not the route to emancipation.
Biesta highlights education’s role in cultivating individuality, creativity, responsibility, and ethical judgment for emancipation. Hence,
emancipation emphasises students’ intellectual efforts and necessitates verifications through acts of imagination instead of assessment,
a counterforce to the neoliberalisation of universities generally focused on (re)producing an efficient, employable, yet uncritical
workforce (Karlsson, 2022).
In pursuit of intellectual equality and emancipation, educators should establish conditions encouraging self-confidence, enabling
students to engage their thinking and overcome their own and others’ contempt. For Rancière (1991), “contempt” denotes discourse or
conduct that seeks to “put people in their place” by asserting distinctions in intellectual capacity, and leads to students relinquishing
responsibility for independent learning (pp. 12, 15). Intellectual emancipation counters the tendency in academic settings to compare,
categorise, and respond based on students’ perceived intellectual differences, instead recognising students’ shared capabilities as
speaking beings to mitigate potential contempt within the classroom. Kogut et al. (2021) reminds us of Rancière’s recognition of the
difficult pedagogical paradox that all communication contains an inherent ambiguity between intentions to categorise and compare
versus intentions to acknowledge equality. Every classroom interaction can enact inequality through hierarchies but can also pre­
suppose equality between thinking beings. For educators, the core challenge is becoming aware of inequality as an ever-present
possibility in order to intentionally counter it. Rancière underscores that vigilance, creativity and committing students to investiga­
tion are required to prioritise equality within situations that also allow contempt.
To facilitate this, Rancière endorses a thing-centred approach over student-centred or teacher-centred methods. The process in­
volves students using their intelligence to translate ideas and emotions into a text, and then in turn, as readers, relying on their own
intelligence to decipher and interpret the meaning of this text (Vlieghe, 2018). Emancipation hinges on a “third thing” or “common
thing”— a shared, accessible text or site unfamiliar to both teacher and student yet embraced as a focal point and open to multiple
interpretations (Rancière, 2009, pp. 14 - 15) - enabling students to conduct their own intellectual exploration and thinking. By
emphasising such a common object, Rancière seeks to disrupt and shift the links, associations, borders, and constraints between
knowledge and emancipation (Simons & Masschelein, 2011), transforming education into an inclusive, experimental, and
non-teleological pursuit (Bingham et al., 2010).
3. Creative education and intellectual emancipation
Various studies have explored creative pedagogical approaches through the emancipatory lens, including: the transformation of
visual journal assignments into a “third space” for knowledge production (Sinner, 2015); video self-portraits by young Latinx children
in the USA as a “third thing” that stimulates a “heterogenesis of the sensible”, emphasising teachers’ roles in facilitating students’ will
and agency to contribute creatively to the urban imaginary (Trafí-Prats, 2012); theatre education as a shared subject for creative
collaboration, comparison, and individuality between teachers/facilitators and students/participants (Lev-Aladgem, 2015); and
drama and experimental theatre performances as the “third thing”, enabling new relations to emerge outside social hierarchy and
facilitating a subjective process of mutual discovery for teachers/performers and students/spectators (Fryer, 2015). Building on the
role of teachers, Simpson (2021) challenges the notion that effective creative writing instruction requires teachers to be writers
themselves, advocating for an “ignorant schoolmaster” approach that emphasises teachers as storytellers (Biesta, 2016).
Studies have also focused on digital creative writing tools as a means to facilitate emancipatory, circular learning and to redis­
tribute power in the classroom by operating as a “third thing.” Abdel-Hack and Helwa (2014) explore how interactive classroom
learning with digital storytelling can boost critical thinking and student agency by fostering engagement instead of passivity with the
software, while Bumgarner (2012) investigates student-centred learning, where expertise comes from students as much as teachers.
Klerfelt (2007) focuses on how student agency is influenced by students’ access to digital resources as active participants, where
Dahlström (2019) suggests that active engagement with the affordances of digital writing tools can shift classroom power dynamics.
Research specifically about classroom digital writing using GenAI tools presents mixed findings regarding students’ perceptions of
being creatively inspired and supported beyond grammar and vocabulary assistance (Kangasharju et al., 2022; Plate & Hutson, 2022).
In non-educational settings, “machine-in-the-loop” processes have demonstrated the ability to enhance creative writers’ perception of
their creativity being “amplified” (Clark et al., 2018), while for less experienced writers, GenAI tools can provide a less intimidating
environment for brainstorming compared to collaborating with a human (Clark et al., 2018; Roemmele & Gordon, 2018). From an
emancipatory and classroom setting, “less experienced” writers can engage with GenAI on terms of equality, alleviating concerns about
teachers’ potential and contempt.
Ouyang and Jiao (2021) proposed three broad paradigms of AI in education: AI-directed, AI-supported, and AI-empowered
learning. Collaborative creative writing is a promising arena in which to consider how educators can facilitate the AI-empowered
“learner-as-leader” model, emphasising and furthering research around increased student agency and redistribution of power in the
classroom. The present study offers a model for how co-creating with AI collaborators can operate as a “third thing” and a trans­
formative force, moving classrooms toward emancipation and equality in Rancière’s sense.
4. Our participants and the data
In our 8-week pilot study, 16 undergraduate degree and PhD postgraduate students from two public Hong Kong universities
participated in a co-curricular creative writing programme, employing GenAI tools such as Rytr, GPT, Midjourney, Stable Diffusion,
and Craiyon. Participation was framed as a research project to explore how GenAI text and image generation could complement the
creative writing process. Students came from different year levels and disciplinary programmes, with an overrepresentation of English
3

Poetics 102 (2024) 101865

J. Tsao and C. Nogues

Literature majors. Participants were a mix of primarily local Hong Kong and mainland and international students. Our study primarily
consisted of students with higher educational backgrounds and potential socioeconomic advantages, who may hold views on art and
creativity that do not fully reflect the wider population. This limitation underscores the need for caution in generalising the results.
Following institutional ethical approval guidelines, all participant data were anonymised, and students could voluntarily opt out
without explanation. The programme occurred between February and April 2023, when Hong Kong universities implemented tem­
porary policies limiting GenAI use. Our study therefore aimed to explore more imaginative applications of LLMs for student learning
beyond the immediate concerns over academic honesty.
Students had access to Rytr, Midjourney, and later ChatGPT (via the Poe app) to experiment with various AI tools for generating
graphic short stories or poems. Alternative GenAI apps were permitted and employed. GenAI-produced images can act as productive
catalysts for student writing and inspire juxtaposed multimedia compositions. Moreover, the ambiguous character of AI art also has
potential to resist intuitive expectations, compelling students to fill interpretive "gaps" and forge tangential associations through its
unpredictability that is distinct from other visual sources. Students actively participated in peer reviews and received some input from
teachers while creating their graphic short stories and poetry. Our data included drafts, final submissions, reflective writings, peer
feedback, end-of-programme surveys (N = 15), and two focus group interviews (N = 8) facilitated by the second author. Both oral and
written classroom interactions were recorded to observe teacher-student and student-student relationships that emphasised intel­
lectual equality and emancipation.
5. Methodology of equality in practice
In alignment with the approach by advocated by Bingham et al. (2010) on fostering self-directed learning environments, we aimed
to engage students collaboratively, learning alongside them without traditional evaluation. Students were encouraged to pursue their
own learning and creative endeavours in the project, which was designed as a voluntary co-curricular program driven by their own will
to learn. Our focus was on the process over the end product. We aimed to verify students’ intellectual efforts and emancipation through
their acts of imagination in creating graphic short fiction and poetry. GenAI served as an unfamiliar site to affirm their equality in this
experimental endeavour, fostering the exploration of a creative product without predefined answers. The approach echoes Rancière’s
(1991) assertion that “To teach what one doesn’t know is simply to ask questions about what one doesn’t know” (p. 30). We considered
creative writing via GenAI applications as Rancière’s “third thing” – a shared object promoting discovery-based learning because it
required effort to navigate and served as a locus for intellectual accountability. The emancipatory potential of GenAI’s content gen­
eration tool distinctly sets it apart from discriminative AI algorithms based on ranking systems and implicit inequality. Hence, our
research undertakes preliminary strides to elucidate how the accessibility of GenAI democratises algorithmic technology, offering hope
of subverting the prospective dystopian futures forewarned by Burrell and Fourcade (2021), particularly pertaining to inequitable
power relations predicated on discriminatory AI systems.
As Rancière (1991) asserts, teachers, despite their asymmetrical position of authority, play an essential role in asking questions,
improvising, and supporting students’ commitment to self-expression and investigation through “the relationship of will to will” (p.
13). While we minimised explicative or instructional materials to prevent any predetermined influence on the students’ work, we did
observe that some explication would be required as a starting point to initiate learning and initial progress. Therefore, we conducted
two 2-hour interactive and open-ended workshops over two weeks to introduce students to GenAI applications, share our own recent
experiments with prompting, and highlight the ongoing debates around biases and the opacity in LLM pre-training. As instructors, we
explicitly communicated that we did not have much more expertise than the students and therefore were not there to correct or provide
answers. The workshops sparked discussions around GenAI’s implications for creative writers in terms of avoiding cliches and ste­
reotypes, and promoting ethical representation of characters and worlds. No guidance was offered on resolving these challenges;
students were responsible for arriving at a solution, mainly through trial and error.
While conscious that our workshops could not model a full embodiment of Rancièrian pedagogical practice, we observe that, as
mentioned before, Rancière’s emancipation does not forbid explication, but rather, asserts that explication is not the route to
emancipation (Biesta, 2016). Our subsequent feedback on draft submissions, alongside peer feedback, was intentionally open-ended
and non-prescriptive. This approach aimed to suspend comparative judgment and affirm students’ shared capacity as speaking beings
through creative expression. We fostered a learning environment where, as much as possible, students turned to each other, rather than
to us as instructors, for validation of their acts of imagination. For example, when Student A created something imaginative, Student B
had to recognise and respond to it without assessing based on instructor-provided standards which introduced hierarchies of power.
We remained attentive to actions by the students, such as imitation, translation, deconstruction, and reconstruction, that signalled the
circular motions of emancipation and potential enactments of equality (Galloway, 2012; Rancière, 1991). Rancière sees
student-originated, trial-and-error repetition as emancipatory because it showcases the will and belief in equal intelligence among
individuals. In the classroom, we propose that teachers play a role in maintaining and strengthening this motion.
6. Findings and discussion
Employing our methodology informed by Rancière’s notion of intellectual emancipation, our analysis of multiple qualitative data
points uncovered the participants’ aptitudes for interpretation, meaning-making, self-directed and collaborative learning, contouring
some emerging GenAI literacies or competencies. Our discussion revolves around themes of decentring authorship, the negotiation
over creative conventions, and the notion of creativity as a specialised skill as we seek to understand the influence of GenAI on student
subjectivities in creative production.
4

Poetics 102 (2024) 101865

J. Tsao and C. Nogues

7. Decentring authorship
Decentring authorship in creative writing involves shifting from the idea of an individual author as the sole creator to recognising
the collaborative and sociohistorical contextual contributions within the creative process. The idea situates well within Rancière’s
philosophy of reducing dependence on external authorities and fostering more active and critical interactions with knowledge and
texts. The theme of decentring authorship emerged as we explored students’ co-creation with GenAI applications and their views on
allocating authorship between themselves and the technology. We found that co-creating with GenAI helped students develop a
nuanced view of authorship, recognising their own responsibilities in the creative process.
One of the ethical concerns was the potential of students to excessively rely on this technology, with implications for academic
dishonesty, unethical authorship, and stultification. However, our findings posit that a substantial proportion of students chiefly
employed GenAI as an initiating catalyst or an inception point for their creative thoughts, particularly when confronted with moments
of creative stagnation. Initially, a few students prompted GenAI to accomplish the entirety of their literary works, but this impulse was
quickly abandoned after discerning the system’s inability to apprehend their intentions fully. For most students confronting this novel
technology for the first time, their early struggles in formulating effective prompts improved as they became more adept at feeling out
GenAI’s limits.
Student 7 adopted a fragmented approach of feeding piecemeal inputs to the GenAI when she failed to obtain a complete poem with
the twist she expected because the outputs were too clichéd. Student 14 encountered challenges generating cohesive works that would
lend fluidity to his narrative and resigned himself to manually writing certain scenes of the story. In both cases, students expressed a
sentiment common across student participants in their early experiments: the quality of first-draft AI creative writing, without further
human intervention, was unsatisfying. This assessment related to issues around (mis)interpretation of their prompts; unreliable
relevance, coherence and consistency of the outputs; poor use of language such as tone, style, word choices (for images, this related to
colours, style, composition), and lack of emotional resonance. When results did not align with students’ desired outcomes, they were
forced to rely on their own intellect to advance or complete their stories and poems. For example, we observed that, while GenAI’s
knowledge encompasses genre conventions due to pre-training on extensive datasets that reflect hegemonic sociocultural and political
history, it is students themselves who must recognise and refuse outputs which are not only conventional for their genre but clichéd or
boring. Arguably, the technology’s passive agency and authorially ignorant characteristics (i.e., the fact that its knowledge is over­
whelmingly encompassing, but it is contextually ignorant to respond unless activated and made aware through prompts) enabled
students to take responsibility for the creative writing process and claim greater authorship. Even and especially when it did not meet
their expectations, the AI played a part in shaping the creative process by providing a starting point, a challenge, or even an unexpected
direction that the students had to navigate.
As they learned to problem-solve their results, numerous students actively engaged in proactive experimentation with crafting the
prompts to support and refine their ideas, independently discovering ways for Rytr to contribute to richer character and narrative
development, recommend alternative wording and phrasing, and offer feedback on pacing:
The writing tools surprised me the most. I never thought they can write something so sophisticated. For example, they can help
generate ideas for stories, by suggesting topics or characters based on user input. AI can also help with the actual writing
process, by suggesting words or phrases to use in a sentence, or by suggesting plot points and providing feedback on pacing.
(Student 7)
Notably, the dialectical potential of GenAI to guide and review the students’ creative writing is directed by the students, without the
intervention of, or being unintentionally subject to “contempt” from, teachers. As the common “thing”, GenAI acted not simply as a
substitution for the teachers’ explication but demanded students’ efforts in inducing satisfactory solutions and negotiating its outputs.
Our results suggest that students, on the whole, felt themselves to be agents in the co-creative process, claiming the lion’s share of
authorship of the resulting creative writing. Sometimes they even claimed sole authorship, addressing the GenAI tool as a purely
mechanical aid more like a word processing programme than a creative collaborator. As will become clear in subsequent discussions,
students’ comments in the end-of-programme survey show that there was a range of cognisance of the role of the AI in the collaborative
process. Even as merely a “tool”, GenAI’s suggestions directed or shaped the creative process in subtle ways, thus blurring the lines of
authorship.
Students tended to attribute greater authorship to GenAI image applications, though, as they perceived the creative (re)production
of these images to surpass their own abilities to enact or explain. Many students expressed being caught off-guard by the remarkable
quality of the digital images generated by Midjourney and the technology’s intuitive interpretation of their prompts compared to the
GenAI writing tools. Nonetheless, paralleling the challenges of consistency experienced in the generative writing process, students
encountered difficulties engineering suitable text prompts to ensure consistency or accurately portray their mental visual represen­
tations. This struggle is a tension between what they perceive and what they can express - a division between the visual (images) and
the linguistic (words) - a division of the sensible at play. Hence, visual artists might negotiate AI’s linguistic prompts differently
because of their capacity to vividly conjure mental images, their sensitivity to emotional, sensorial, or conceptual aspects, and their
ability to translate colours, patterns, and compositions encapsulating the quintessence of visual forms. The disparity in our students’
attribution of authorship between GenAI writing versus image generation tools highlights the continuum of relative confidence and
sense of proficiency students experience in using current AI tools across different creative domains. The unique, algorithmically
randomised creation process of GenAI art and its capacity to manufacture pastiche was found by students to be more innovative and a
more compelling source of inspiration than the generated writing. The diffusion model of image generators iteratively refines random
noise image into a final generated image, allowing artists a higher degree of control to influence and (re)compose new images,
5

Poetics 102 (2024) 101865

J. Tsao and C. Nogues

showcasing the dynamic, interactive potential of AI in enhancing creative outputs. Hence, rather than just an imitative art, the bur­
geoning user community around GenAI art indicates its social trajectory as a new art form, akin to photography’s evolution from
mechanical reproduction to accepted art.
While the students’ attribution of greater authorship to the GenAI might ostensibly undermine the parity of intelligence, they
utilised these tools as springboards to assert their creativity and intellectual equality, rather than accepting the AI’s contributions
unjudiciously. Student 7, for example, regarded his use of Midjourney much like a collaboration with a human illustrator or assistant
and judged the degree of authorship contingent on the specificity of human instructions and where the source of inspiration originated:
And for the illustration, actually, I would think that me and the AI are both authors… the meaning of “author” is the one who
actually has the idea, or like, who does the creative stuff, so I would say that Midjourney is rather my helper to draw those
pictures rather than the sole author or main author. (Student 7)
Here, we see a binarisation of authorship into creative/ abstract thinking versus the mechanical labour involved in the production
process. Therefore, for Student 7, greater authorship could be credited to the GenAI if the human prompts were vague, compelling
GenAI to engage in more “creative” cognition relative to its mechanical labour:
[A]fter using these AI [tools], I think that originality or authorship actually means those who actually have the idea or who
generate inspiration....But then that can still be the AI tool—like, if we don’t have anything in our mind, and then we just use the
AI tools for, like, inspiration, or they just gave us some very great new ideas. Then the AI is still the author or there’s still
originality in AI, but … [if I use] AI as an illustrator of my creative thoughts, then I think the sole author would still be me and
the originality still comes from me. (Student 7)
Hence, students cultivated a nuanced perspective of authorship by engaging with varying affordances of the technology and
directing their attention towards the complexities involved. This process stimulated their recognition of their own will and re­
sponsibility in creating content, as well as the importance of verification within the creative process. The students’ experiences indicate
that the technology may not necessarily deskill or stultify young authors if used appropriately.
8. Negotiating creative conventions
Beyond authorship, we observed acts of dissensus and critical judgement as an exercise of intellectual emancipation through the
students’ experimentation with GenAI. Improvisational efforts to negotiate creative conventions included engineering prompts to
generate non-clichéd outputs, deconstructing the outputs, and playing with varied genres and stylistic structures. Moreover, they
receptively incorporated unconventional ideas offered by the GenAI, which shaped their sense of originality and creativity. Because of
our initial workshops, students were cognisant of GenAI’s tendency to compose biased, clichéd and stereotypical materials due to its
pre-trained origins. The GenAI writing tool’s predisposition towards the clichéd forced students to reflect and adapt the precision of
their language and grammatical structures in text prompts for the AI to understand their intentions. The tendency towards repetition
and clichés rooted in the pre-training process does not necessarily negate GenAI’s emancipatory potential but underscores areas for
refinement, such as diversity of datasets, enhancing algorithms, and improved prompting to mitigate these patterns. In fact, this
reiterative trial-and-error process made most students aware of the importance of highly descriptive text prompts.
On the other hand, students discovered that not only highly precise text prompts but also “unconventional” linguistic and nonlinguistic strategies, including the use of misspellings, peculiar combinations of vocabulary, non-English languages, and symbols/
emojis, helped to generate what they wanted and to push beyond clichéd outputs:
…when we input conventional stuff in the writing tools, that usually generates cliched outputs for them. And you try to input
seemingly irrelevant words or face symbols, it would give you something entirely different. So I feel like it’s possible to use these
tools in rather unconventional ways to assist us in our creative writing processes. So instead of telling it to write, for example, a
sonnet in iambic pentameter, you can ask it to do something else. Something unexpected to give you also a unique [output].
(Student 12)
Here, Student 12 describes their realisation of how non-linguistic inputs introduces “something else” into the conventional norms of
the AI’s knowledge domain, yielding a process of collaboration that is oriented less toward the sort of expected result represented by
the familiar form of the “sonnet in iambic pentameter” and more toward open-ended discovery. Similarly, student 2 prompted the AI to
translate the text back and forth between English and Chinese, exploiting semantic gaps or lacunae from its contextual ignorance to
generate novel responses. These examples direct to how, throughout the course of the project, both students and instructors experi­
entially discovered that GenAI tools often make stochastic or tangential associations, or even what is popularly referred to as
“hallucinating” or making up knowledge, if prompted in particular ways. Notably, the term “hallucinations” is a misnomer as the
technology is not perceiving or seeing things that are not there. Instead, these aberrations are merely probabilistic outliers in the
“learning” of the underlying patterns and structures of the training data and fall outside of what we consider “the sensible” - which can
indicate something “creative”. This in-process, student-originating discovery offered opportunities for students to devise innovative
practices to adapt to these inherent characteristics and develop their attentive capacities. The following dialogue between two students
illustrates how their experimental approaches refined their understanding of creativity, emphasising the importance of striking a
balance between the clichéd and the surreal:

6

Poetics 102 (2024) 101865

J. Tsao and C. Nogues

Student 7: For example, I try and have some problems - like an apple becoming a Superman. But then the results will be too
unreasonable, without being, like, creative, or it’s not, like, [satisfying]…
Student 5: No, it’s like even if you use problems like an apple becoming Superman, it still has some way to make it cliché.
Student 7: Or it would be too unrelatable. So yeah, going to two extremes.
Here, the students describe their discovery that what registers as “creative” threads the needle between the clichéd and the “too
unreasonable” or “too unrelatable,” what we might say is too far outside “the sensible”.
Student 6 speaks further about GenAI’s imaginative potential but how, like humans, it is conditioned by a habitus that acts in a
probabilistic manner and defaults back into reproducing “the sensible” and safe:
AI have abundant “imagination”, or they have enough materials (at least much more than any individuals in the world) to
generate something “creative”, but they will always fall back to the organised and structured way of writing, conforming to the
formality and rules that most people use in their daily lives. (Student 6)
Such recognition of the mix of mundaneness, misdirection and weirdness from the GenAI nudged students towards widening their
understanding beyond their own preconceived notions of the components of creative writing. For example, Student 1 noted that GenAI
text tools often featured abrupt tone shifts and sudden mention of characters without proper introduction. These improprieties
influenced the students towards heterogenesis through actively interpreting and negotiating the outputs to include a hybridisation of
ideas, as in this observation by Student 6:
I typed “letters” in Midjourney hoping for images containing papers with words and envelopes, but turns out, Midjourney
provided me with four images of “letters” as in symbols. It may be disappointing, but it was actually quite funny once you have
realised your “mistakes”, or I should say “subjectivity”. Moreover, those “disappointing results” provided me with more ideas.
For example, what if we are really talking about symbols instead of words? Those disappointments are not only disappointment,
but something with more potential. (Student 6)
Much like Student 12′s discovery that she could use emoji to confound Rytr into producing “something else” than conventional
poetic forms, Student 6 devised a way to pursue “something with more potential” via the “disappointments” of her initial attempts with
Midjourney.
A few students discovered they could employ multiple generative models through modality transfer. For example, vivid images
could be input through “reverse” image-to-text GenAI applications to produce highly descriptive text. Alternatively, students requested
GPT to formulate the text prompts by describing the desired images and then pasting them into the image generators. For instance,
Student 3 inserted text from her co-created poem into Midjourney and discovered she needed to mitigate its deep associational biases.
The generated images persistently included red hues due to the word “red” in her poem and depicted a woman because of references to
flowers despite the absence of any explicit reference to a woman in the poem itself. Ultimately, she was influenced to incorporate the
red palette more predominantly into her imagery than initially intended. AI’s tendency for visual cliché reflects its training data and
human feedback biases but understanding these patterns can enable users to ingeniously navigate the clichés. Nonetheless, Student 3′s
acquiescence to Midjourney’s colour suggestion underscores concerns of outsourcing our creative cognition to AI, which may result in
skills erosion and risks of AI-led homogenisation of creativity. It underscores the salience of critical judgement in situations where
human intervention could significantly advance the quality of creative outputs.
As we noted in the previous section, students discovered that co-creation carried a responsibility to critically evaluate which
outputs constrained or expanded creativity in their works. But they also recognised that GenAI could help them reflect on the paro­
chialism of their writing process:
The writing AI applications showed me that I can quite easily get tunnel vision when focusing on my own ideas…Because it’s not
really about the output… It’s more like the ideas, I would say, it’s like helping you refresh your mind… I’ll ask it to generate
maybe 10 to 20 again, and then sometimes I might find some ideas that I haven’t thought of… (Student 14)
Though some of them can be illogical or repetitive, just by viewing such many different responses generated using the big data,
you can be inspired to think outside the box. (Student 16)
Here, students were exercising confidence in actively negotiating with the inputs and outputs instead of deferring or accepting this
generative authority:
The writing AI applications were able to provide me a more comprehensive view than what I can conceptualise by myself, but
the ideas provided were not unique. Fully following those ideas actually made my creative process less creative in a sense, and
lacks that individualistic flair. (Student 14)
While these students found the sheer scale of GenAI’s “comprehensive view” to be an exhilarating expansion of their own “tunnel
vision”, they perceived GenAI’s ideas to lack the “individualistic flair” to offer a way “out of the box” or to be a good choice to “fully
follow.” Thus, students articulated the experience of sensing the value of their own critical judgment and relying on their own in­
telligence. The co-creative process also developed students’ empathetic perspectives, as they used the GenAI to contemplate how
others comprehend their works and how they might enhance their communications. In this case, we argue creative writing through
GenAI develops capacities to not only communicate more effectively with others but also to become more resilient to the contempt of
others:
7

Poetics 102 (2024) 101865

J. Tsao and C. Nogues

Student 12: Oh, well, I think regarding communication skills, it’s required for the peer review part because we can see how our
peers…our human peers, respond to our, you know, creative writing. Since a lot of it, I guess, is like emotional response that is
unique to humans. I guess this process is also important in, you know, in the process of creative writing.
That [GenAI text tools] could mime different literary styles! It’s like they serve as mirrors of the other’s perspective—giving me
a glimpse of what my craziest feelings may “look” like in others’ eyes. (Student 1)
The produced image outputs left a notable affective impression on the students. As another example, when Midjourney produced
“dark and ominous” images based on Student 3′s text, this startled both the student and her peers. When she included some of those
images in her draft for peer review, one reader, Student 5, interpreted the resulting visual poem as describing a female serial killer,
which was not the effect Student 3 had wanted. Similarly, Student 10 found the weirdness and unnaturalness of some of the generated
images unsettling when Midjourney produced images where body parts were separated or humans had more than two hands. Through
the gaze (Sartre, 2022) of the GenAI’s interface, a mirroring process transpired: the students’ communications were interpreted and
(re)presented to them, either aligned with or skewing their intentions. At the same time, the process was disassociating them from their
typical understandings of certain terms and widening these associations. Mismatches between poiesis (creation) and aesthesis
(perception) hint at the preconditions for the materialisation of dissensus. This gaze was also described in Student 10′s reading of
Student 7′s creative work. In exercising her will to understand the eclectic arrangement of text and images by her peer, who underwent
the frustration of trying to combine heterogeneous outputs into a coherent composition to convey themes of fragility and friendship,
Student 10 wrote:
I actually like the way you organise where to locate the words. Frankly, it took me a bit of time to read the words but I don’t
think that it posed any difficulty in understanding. They forced me to read left and right, I don’t know if you did this delib­
erately, but it reminded me of the gaze when you feel uncomfortable with someone – you look left and right cos you feel
awkward. (Student 10)
For Student 15, this gaze was reassurance:
The images generated by AI gave me more concepts to write my feelings out. I feel less alone each time I watched the images
slowly generate out as I got to see someone, or something, understand my thoughts. And seeing my memories become art is a
surprisingly soothing feeling. (Student 15)
Beyond the affective influences is the self-transformation of the students’ subjectivities towards emancipation. Specifically, stu­
dents were constantly pushing forward in search of ways to “speak” with the AI:
I know that I’m talking to AI, right? It’s not a person. So, then the kind of approach you have to take to talk has to be very
different.... But then there are certain things you have to keep in mind and there’s also a lot of times when you have to change, for
example, your prompt because you think it was going to work and then it doesn’t. (Student 3) [emphasis added]
Even though the repetitive labour in prompting seemed occasionally unproductive or “frustrating”, and the outputs were some­
times underwhelming or mediocre, the refrain reinforced the consciousness, emotional intensity, and a drive for action in the creation
process that was evidence of intellectual emancipation. For example, we perceive an evident sense of urgency and necessity in Student
3′s reflections on her methodology, cognitive shift, and how she “had to” modify her interaction with the algorithm. Similarly, Student
6 spoke about how the AI gave “a lot of negative feedback” that kept her “changing and changing all the prompts”. These iterative acts
of translating abstract human thought into concrete instructions and converting the outputs of AI’s generative logic suggest that
students were developing a type of logical adaptability we can think of as an emerging essential literacy. In other words, they were finetuning their comprehension of AI’s functionality and potential biases, the critical analysis of its outputs, and the conversion of abstract
creative concepts into concrete AI-instructions, ultimately outlining what proficiency in AI’s language and logic might look like.
9. Creativity as a specialised skill
Our analysis of the students’ discourses painted a nuanced conception of creativity and imagination that shifts the focus away from
a specialised skill exclusive to specific individuals, given the intermediation of an external agent in their creative production. For
example, Student 14 debated the difference between compelling works and creative ones, questioning if genuinely creative or original
works needed to exhibit resonant characteristics to readers or viewers. He pointed out that high-quality creations from Midjourney
could be captivating with minimal human intervention but not be considered to meet the criteria for being creative. The student
deemed his work creative and original because of his active intervention in infusing his “direction and flair” into the creation,
transforming AI-generated content he considered not creative into something creative. Similarly, Student 5 discovered the need to
constrain the “creative space” of the GenAI through specification and qualifiers in her prompting to manage the direction of its
creativity, for example, prompting “happiness of marriage…or the time of childhood” instead of just “happiness”. Likewise, Student 11
underscored the significance of human intervention in preserving the “unity” or coherence of the creative endeavour via well-crafted
prompts and working through how disparate outputs relate to each other and come together. This negotiation over the generated
output reinforces the combination of contextual awareness and judgement in the creative synthesis process.
Student 12 reflected on conceptions of creativity, drawing connections between intertextuality, originality of AI-generated content
and its embeddedness within the broader milieu:

8

Poetics 102 (2024) 101865

J. Tsao and C. Nogues

Personally, I think [this project] kind of challenged my preconception regarding what creativity actually means. Because if you
think of the concept of intertextuality, like each text you create is somehow influenced by other texts, no matter if it’s inten­
tionally or it’s unconsciously, if you have that view to AI writing or AI image tools, you will see that, hey, we consider it as nonoriginal because it kind of absorbed its content from other sources, from the Internet. Then you can also see how at least
something “new” or something original is, you know, is generated by its collection and absorption of different sources and
styles. (Student 12)
This extract squares with Horner’s (1997) contention that instead of teachers treating students as original creators of unique
meaning in creative writing, students can learn to work within and transform existing discourse, considering how meaning is produced
socially and collectively, not individually. The students’ reflections are a reminder of the critiques of traditional and institutionalised
perspectives of creativity as an expert skill and highlight the parallels between human and AI-driven creative processes in assimilating
and reconfiguring existing elements. The “death” of the single author doesn’t signify a loss, but rather a transformative reimagination
towards a collective and inclusive approach to creativity, one that even acknowledges non-human contributions. This directs to the
possibility of a social imaginary that includes both human and non-human “imaginations”, opening up new potentials for emanci­
pation and empowerment in the creative process. This echoes Barthes’ (1977) assertion that a “text is a [fabric] of quotations”, drawing
from “innumerable centres of culture” (p. 146) rather than from the experience of a single individual; hence a text’s meaning is
constructed by the reader’s interpretation, and liberated from the author’s original intent.
The students’ reflections also spoke to the creative opportunities, obstacles, and capacities constituting creative works and sug­
gested that creativity can come from anywhere:
One of the most important takeaways is to never assume what can and cannot add to your creativity. Ideas can come from
anywhere, even from AI, and it depends on you how you can use them to add to your creative output rather than take something
away from it. (Student 3)
The students’ exchanges and feedback served to elucidate the homeotic transformations of their personal creativity. They embraced
the fluidity and hybridity of their creative capacities as something flexible and combinatory, made possible through this milieu of
human-technology augmentation. For instance, students metaphorically described their approach as “borrowing” GenAI’s field of
vision or using it as a “mid-space” to synthesise their creative expressions:
AI can basically use everything happening in the world as their inspiration, while for we humans, our own field of vision is very
much limited by our own experience. Making use of the AI field of vision will help me think of something that I may not usually
notice, and thus supports my creativity. (Student 16)
This collaborative hybridisation is further evident in the case of Student 5, who learned through peer feedback to blend existing
excerpts from informative genres, such as news articles, with her “human writing” into Rytr. This approach proved effective for
controlling the generated outputs she desired. Rancière’s cyclical motion of emancipation describes Student 12′s experience of
repetitively composing, revising, and evaluating her own and her peers’ collaborative works, which she considered a practice of
creative thinking. The iterations accentuated the constraints of GenAI in resonating with unique human experiences, simultaneously
bestowing an appreciation towards the nuances and commonalities of collective creativity:
This reminds me of [Student 15′s] work. I think she addresses topics like depression and traumatic experiences which we feel
like AI currently cannot, you know, fully understand and interpret that. It seems like it’s trying its best to gather information
regarding these experiences unique to humans. But it just can’t, you know. Again, it doesn’t express them in a compelling way
that we can find resonance with. (Student 12)
We can evaluate the potential and constraints of co-creativity when the algorithms of machines are designed around a consensus
logic drawn from human cultural artefacts. Consider Student 1′s reflection: “Like humans, [the GenAI] carry their own inertia.” The
student questions how these AI can transcend their programmed algorithms. For example, students deliberated creative works’
emotional aspects and meanings, debating their preference for outputs produced by humans or AI. They recognised that interpretations
can often diverge from an artist’s original intention, a phenomenon that remains true even for AI-generated art, which inherently lacks
original intent. These discussions underscore the need for a comprehensive and inclusive examination of creative processes and
highlight the evolving roles of both human and AI “agents” in these processes.
10. Emancipated “Teaching”
What are the implications for educators in expanding creativity and imagination with the rise of GenAI? Firstly, our earlier point
concerning the authorial ignorance of GenAI in its hybrid role as the “third thing” has implications for how teachers should position
themselves in pedagogical emancipatory practice. Our context reinforces Klerfelt’s (2007) assertion that student agencies depend on
instructors’ willingness to provide access to new digital tools and empower them to explore its affordances in their own ways.
Secondly, we must acknowledge that despite GenAI’s passive aspects, this technology is not neutral as a common “thing”. The
"black box" problem of AI’s decision-making, combined with its training primarily on Western and English-language texts and human
feedback, not only hides cultural and societal biases with implications for representation, inclusivity, and marginalisation, but can also
lead to a tendency towards simplistic literalism. While careful and precise prompting can counter such issues, recent efforts to train on
more globally diverse datasets promise to foster more diverse and hybridised outputs. Teachers are responsible for asking questions to
9

Poetics 102 (2024) 101865

J. Tsao and C. Nogues

provoke students to critically negotiate with the tool to counteract the complicity of students in subordinating their intellect to digital
hegemony and domination. For instance, a student cited the workshop discussions about pre-trained biases as influential in shaping her
approach to crafting text prompts and analysing the generated outputs.
Students valued how teachers and peers also drew attention to critical values, such as originality and creativity, in written works
and emphasised the importance of developing one’s unique and hybridised style instead of relying on AI-generated content that may
lack individuality or simply rehashing existing positions. The students’ dedication and thoughtful engagement in the project serve as a
counterpoint to institutional apprehensions over plagiarism through GenAI. Instead, these efforts manifest students’ intent to preserve
their voices while leveraging technology to animate and deepen their ideas. The dynamic and circular process of acceptance, rejection,
and refinement that unfolded shows students’ critical engagement with the technology and conscious creative decisions. This inter­
action of catalysing creativity and learning rather than a replacement for originality suggests AI’s capacity to foster a dynamic learning
ecosystem that encourages experimentation, critical thinking, and understanding of authorship intricacies in the digital era, including
plagiarism. Yet, as AI progressively evolves to better infer our decision-making and preferences, we need to guard against it inad­
vertently becoming a proxy “sage on the stage”, thereby limiting our personal agency and emancipatory potential. This revelation
amplifies the importance of the assigned tasks and the pedagogical methodologies employed when assimilating GenAI into educational
environments.
Thirdly, emancipation requires cultivating environments that stimulate students’ intellectual endeavours and imaginative acts.
Teachers can facilitate both tangible and intangible conditions for interdisciplinary and transdisciplinary experiments that may be
difficult for students to initiate independently. For instance, Student 7 asserted that without this involvement, she believes her un­
derstanding of the potential of GenAI in creative writing would have remained unexplored. The iterative and circular dynamics of
learning we champion here underscore the imperative of unfettered access to GenAI tools for students. Policies that impose restrictions
are not only counterproductive but also risk marginalising socioeconomically disadvantaged students.
The experimentation affirmed students’ adaptive and learning capacities, illustrating the need for human agency and intervention
in creative production. For a few students, the project interrupted their complacencies and presuppositions about the capabilities of AI.
For Student 10, the experiments had an affective influence by growing her confidence in her capacities and her optimism about the
future with GenAI technology - a sentiment shared by many participants. For Student 3, the takeaway was about authorship. She
walked away valuing the power of generative art in creative storytelling but reifying that she “wanted the words to be my own.”
Conclusion
In exploring GenAI in creative production through the lens of Rancière’s philosophical concepts, our investigation revealed stu­
dents’ struggles with both the predictable and unconventional generative outputs, which paradoxically spurred them to recognise their
agency to subvert genre conventions and aesthetic norms against the passivity and authorial ignorance of the technology. Student
improvisation and spontaneity in experimenting with different techniques to communicate with the GenAI showcased their logical
adaptability (ability to flexibly respond to GenAI’s outputs), contextual awareness (discerning the influence of context in the creative
process), and capacity for recombinant synthesis (combining various creative techniques and outputs to generate unique creative
conventions). Implementing Rancière’s methodology in creative education with GenAI through an object-focused pedagogy demon­
strated the possibilities of this co-creative process in cultivating intellectual emancipation. The study reinforces the need for educators
to operate as “ignorant schoolmasters” by designing minimally guided experiential activities and research projects to develop students’
autonomy, sense-making, and criticality. Our findings contest the view of creativity as a specialised skill and present the possibility of
GenAI in promoting a more distributed and diverse conception of creativity accessible to all. Students viewed creativity as configu­
rations of cultural and social elements, emphasising the combination of unexpectedness and intentionality in human efforts. They
rejected the notion of creativity as a random or chance-based process, aligning more with sociological definitions in which creativity is
realised in the result rather than the actor and is intrinsically collective, and in which not all novelty is deemed creative, but rather
hinges on audience reception (Godart et al., 2020). Moreover, our observations indicate that GenAI tools “fold into” and obscure the
distinctions between common characteristics of creativity such as agency, support, scaffolding, and artefacts (Bardzell, 2007). As
GenAI takes on fundamental learning tasks and advances in complex areas like data analysis and synthesis, educators must re-think the
environment for capacities like meaning creation and ethical judgment to flourish.
With the global integration and advancement of AI, the task of resisting and guarding against forms of technological somnam­
bulism, corporate regulatory capture, and technocracy becomes more urgent. These phenomena bear profound implications, including
the potential displacement of human creativity, the reconfiguration of our agentic capacities, and the threat to democratic processes.
Moreover, they can contribute to alienation through insidious expressions of neocolonialism and domination. Ethical debates around
AI as anti-art, unauthorised use and storage of intellectual property, limitations of moderation and filters, AI-related labour exploi­
tations, and the unfolding regulatory dynamics require attention amidst the proliferation of social and economic activities coalescing
around GenAI. The risk is compounded by the growing indistinguishability between human and AI-generated content (with the rise of
synthography, AI-generated photography), that can potentially dilute the emotional resonance that often comes from humangenerated content, leading to a sense of disconnection, breeding mistrust due to the AI-generated misinformation, and inducing
apathy towards reality as we continuously question the authenticity of content. In the context of Rancière’s “distribution of the
sensible”, AI might be construed as embodying “anaesthetic” creativity - a dual-edged phenomenon that both numbs traditional artistic
sensibilities through mechanisation and antagonises them by posing as a credible author or artist. No doubt our growing reliance on its
capabilities could profoundly reshape aesthetic norms and judgments, impacting on what is valued, questioned, or discarded.
While our small-scale implementation of Rancière’s philosophy reveals the potential for intellectual emancipation within the
10

Poetics 102 (2024) 101865

J. Tsao and C. Nogues

classroom, achieving durable social change requires acting with the assumption of intellectual equality while simultaneously ques­
tioning the broader conditions that inscribe and reproduce the material inequalities beyond it and addressing wider economic and
opportunity disparities. Educators in higher education must acknowledge our current coexistence with AI. They bear the responsibility
for creating conditions that enhance students’ critical awareness, aiming to reduce structural inequalities and inspire imaginative
thinking for a better future. Human participation is crucial in directing a technology that generates “new” content by drawing upon our
digitised past. Future research should investigate how AI can co-create with students and teachers to transform, augment, and
empower creative pedagogy in higher education for deeper engagement and civic participation.
Funding details
This study was funded by the Hong Kong University Grant Committee Teaching Development and Language Enhancement Grant
and allocated by the University of Hong Kong Vice-President and Pro-Vice-Chancellor (Teaching and Learning), ID 012530415.
CRediT authorship contribution statement
Jack Tsao: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Project administration, Resources,
Supervision, Writing – original draft, Writing – review & editing, Funding acquisition. Collier Nogues: Conceptualization, Data
curation, Formal analysis, Investigation, Project administration, Supervision, Validation, Writing – original draft, Writing – review &
editing.
Declaration of competing interest
None.
References
Abdel-Hack, E. M., & Helwa, H. (2014). Using digital storytelling and weblogs instruction to enhance EFL narrative writing and critical thinking skills among EFL
majors at Faculty of Education. Educational Research, 5(1), 8–41.
Bardzell, J. (2007). Creativity in amateur multimedia: Popular culture, critical theory, and HCI. Human Technology: An Interdisciplinary Journal on Humans in ICT
Environments.
Barthes, R. (1977). Image, music, text (S. heath, trans.). Fontana.
Biesta, G. (2016). The beautiful risk of education. Routledge. https://doi.org/10.4324/9781315635866
Bingham, C., Biesta, G. J. J., & Rancière, J. (2010). Jacques Rancière: Education, Truth, Emancipation. Continuum International Publishing Group. 10.5040/
9781472546975.
Bumgarner, B. L. (2012). Digital storytelling in writing: A case study of student teacher attitudes toward teaching with technology. University of Missouri-Columbia [Doctoral
Thesis].
Burrell, J., & Fourcade, M. (2021). The society of algorithms. Annual Review of Sociology, 47(1), 213–237. https://doi.org/10.1146/annurev-soc-090820-020800
Clark, E., Ross, A. S., Tan, C., Ji, Y., & Smith, N. A. (2018). Creative writing with a machine in the loop: Case studies on slogans and stories. In 23rd International
Conference on Intelligent User Interfaces.
Corcoran, S. (2010). Editor’s Introduction. In S. Corcoran (Ed.), Dissensus: On politics and aesthetics (pp. 1–24). Continuum.
Dahlström, H. (2019). Digital writing tools from the student perspective: Access, affordances, and agency. Education and Information Technologies, 24, 1563–1581.
Davis, O. (2010). The radical pedagogies of François Bon and Jacques Rancière. French Studies, 64(2), 178–191. https://doi.org/10.1093/fs/knq001
Ewalt, J. P. (2016). Rhetoric, poetics, and Jacques Rancière’s The ignorant schoolmaster: Five lessons in intellectual emancipation. Philosophy & Rhetoric, 49(1),
26–48. https://doi.org/10.5325/philrhet.49.1.0026
Fryer, N. (2015). The ‘third thing’: Rancière, process drama and experimental performance. Research in Drama Education: The Journal of Applied Theatre and
Performance, 20(3), 331–336.
Galloway, S. (2012). Reconsidering emancipatory education: Staging a conversation between Paulo Freire and Jacques Rancière. Educational Theory, 62(2), 163–184.
Godart, F., Seong, S., & Phillips, D. J. (2020). The sociology of creativity: Elements, structures, and audiences. Annual Review of Sociology, 46, 489–510.
Hjulström, E., & Rytzler, J. (2022). Herbart with Rancière on the educational significance of the ’third thing’ in teaching. Ethics and Education, 17(4), 421–436.
https://doi.org/10.1080/17449642.2022.2153470
Horner, B. (1997). Students, authorship, and the work of composition. College English, 59(5), 505–529.
Kangasharju, A., Ilomäki, L., Lakkala, M., & Toom, A. (2022). Lower secondary students’ poetry writing with the AI-based poetry machine. Computers and Education:
Artificial Intelligence, 3, Article 100048.
Karlsson, M. (2022). In pursuit of ignorant university teachers and intellectually emancipated students. Culture and Organization, 28(3–4), 194–215. https://doi.org/
10.1080/14759551.2022.2026947
Klerfelt, A. (2007). Barns multimediala berättande. En länk mellan mediakultur och pedagogisk praktik. Göteborg: Acta Universitatis Gothoburgensis.
Kogut, M., Sørensen Thaning, M., & Birksted, N. (2021). Intellectual emancipation as minimal humanism – The relevance of Jacques Rancière in business school
teaching. Management Learning, 52(2), 165–187. https://doi.org/10.1177/1350507620969549
Lev-Aladgem, S. (2015). The ignorant facilitator: Education, politics and theatre in co-communities. Research in Drama Education: The Journal of Applied Theatre and
Performance, 20(4), 511–523.
McKinsey & Company. (2023). The economic potenial of generative AI: The next productivity frontier.
Novak-Leonard, J. L., Skaggs, R., & Robinson, M. (2022). Innovative and artistic: Conceptions of creativity among the American public. Poetics (Amsterdam), 90,
Article 101599. https://doi.org/10.1016/j.poetic.2021.101599
Ouyang, F., & Jiao, P. (2021). Artificial intelligence in education: The three paradigms. Computers and Education: Artificial Intelligence, 2, Article 100020.
Plate, D., & Hutson, J. (2022). Augmented creativity: Leveraging natural language processing for creative writing. Art and Design Review, 10(3), 376–388. https://doi.
org/10.4236/adr.2022.103029
Rancière, J. (1991). The ignorant schoolmaster: Five lessons in intellectual emancipation. Stanford University Press.
Rancière, J. (2004). The politics of aesthetics: The distribution of the sensible. Continuum.
Rancière, J. (2009). The emancipated spectator. Verso.
Roemmele, M., & Gordon, A. (2018). Linguistic features of helpfulness in automated support for creative writing. In Proceedings of the first workshop on storytelling.
Sartre, J.-P. (2022). Being and nothingness: An essay in phenomenological ontology (S. richmond, trans.). Taylor & Francis.

11

Poetics 102 (2024) 101865

J. Tsao and C. Nogues

Sgourev, S. V. (2021). Changing perspective: An “optical” approach to creativity. Poetics (Amsterdam), 89, Article 101581. https://doi.org/10.1016/j.
poetic.2021.101581
Simons, M., & Masschelein, J. (2011). Introduction: Hatred of democracy . . . and of the public role of education? (pp. 1–14) Wiley. https://doi.org/10.1002/
9781444393866.ch1. In.
Simpson, P. W. (2021). The art of making up things: Jacques Rancière and intellectual emancipation in the primary creative writing classroom. Auckland, New Zealand:
Auckland University of Technology [Doctoral Thesis].
Sinner, A. (2015). Against the grain: An intervention of mastery learning and intellectual emancipation in art education. Educational Philosophy and Theory, 47(5),
502–514. https://doi.org/10.1080/00131857.2014.883962
Trafí-Prats, L. (2012). Urban children and intellectual emancipation: Video narratives of self and place in the city of Milwaukee. Studies in Art Education, 53(2),
125–138. https://doi.org/10.1080/00393541.2012.11518857
Vlieghe, J. (2018). Rethinking emancipation with Freire and Rancière: A plea for a thing-centred pedagogy. Educational Philosophy and Theory, 50(10), 917–927.
https://doi.org/10.1080/00131857.2016.1200002
Williams, R. (1977). Marxism and literature. Oxford University Press.
Dr. Jack Tsao is the Associate Director and Senior Lecturer of the Common Core, the undergraduate transdisciplinarity curriculum at the University of Hong Kong. As a
Senior Fellow of Higher Education Advance, he is interested in exploring projects around gaming, storytelling, and digital and artificial intelligence technologies. Jack
earned his PhD in Education from the University of Queensland and specialises in comparative and international education, youth studies, and the sociology of education
through an interdisciplinary perspective.
Dr. Collier Nogues is Assistant Professor of Creative Writing at the Chinese University of Hong Kong. Her poetry collections include the hybrid print/interactive volume
The Ground I Stand On Is Not My Ground (Drunken Boat, 2015) and On the Other Side, Blue (Four Way, 2011). Her creative and scholarly work has been supported by
fellowships from the MacDowell Colony, the Ucross Foundation, Vermont Studio Center, and the Hong Kong Research Grants Council, and her writing has appeared in
Jacket2, The Volta, At Length, Pleiades, jubilat, Tupelo Quarterly, the Academy of American Poets’ Poem-A-Day Project, and elsewhere.
With artificial intelligence (AI) replacing humans at work, creative work is becoming increasingly important for
humans. Although AI may improve employees’ innovation behavior, some evidence suggests a negative effect
through employees’ psychological well-being. To address these contradictory arguments, this study investigated
the double-edged sword effect of AI-assistant intelligence on employees’ innovation behavior based on the
transactional model of stress. Two scenario-based experiments reveal that an AI assistant characterized as high
intelligence has a positive indirect effect on employees’ AI-enabled innovation behavior via creative self-efficacy,
while the indirect effect is stronger when organizational AI readiness is higher than when it is lower. However,
the same AI assistance has a negative indirect effect on employees’ AI-enabled innovation behavior via STARA
awareness when organizational AI readiness is low. These findings have pivotal implications for both manage­
ment theory and practice.

Keywords:
Artificial intelligence
Creative self-efficacy
STARA awareness
Organizational AI readiness
Innovation behavior

1. Introduction
Artificial intelligence (AI) refers to highly capable and complex
machines that perform cognitive functions usually associated with
human intelligence, such as learning, interacting, and problem solving
(Nilsson, 1971). AI transforms human–technology relations by shifting
agency from humans to technology, and is considered the core of In­
dustry 4.0 (Raisch & Krakowski, 2020). Given that AI can significantly
increase labor productivity (Brynjolfsson et al., 2021), 80% of large
companies have integrated AI into their core businesses in the last few
years (Ghosh et al., 2019). Many companies provide employees with AI
assistants to help them perform various tasks. An AI assistant is a soft­
ware driven by artificial intelligence functions such as machine learning,
and can help individual users complete work and non-work tasks (Yang
& Lee, 2019). The most common AI assistants currently in the market are
intelligent agents with an identifiable entity and embodiment via
anthropomorphism (Moussawi et al., 2020), such as Amazon’s Alexa,
Apple’s Siri, and Microsoft’s Cortana. There are also embedded
AI-driven software systems that do not have an intelligent agent, but can
help employees with a variety of tasks (Glikson & Woolley, 2020). For

example, customer service intelligent assistants can instantly identify
customer problems, recommend sales talks, generate customer portraits,
and predict transaction probabilities (Vlacic et al., 2021).
AI intelligence is the extent to which AI can learn, reason, and solve
problems (Bartneck et al., 2009). With the advancement of intelligence,
AI assistants can perform various complex tasks, react to environmental
changes, and perform tasks in line with user preferences by learning
information from users and the environment (Hu et al., 2021). However,
AI is only capable within defined limits; out-of-the-box thinking and
creative problem solutions seem unattainable for now, where humans
will still dominate (Wirtz et al., 2018). In the future division of labor,
cognitive-analytical tasks are more likely to be performed by AI (Huang
& Rust, 2018). Employees may only be required to ensure the operation
of the AI system (Wilson & Daugherty, 2018), while being engaged in
tasks related to emotions and creativity (Huang & Rust, 2020). The
advantages of humans and AI are complementary only when the former
are motivated to innovate, and human–AI collaboration can lead to a
source of competitive advantage for an organization (Makarius et al.,
2020). Therefore, promoting employees’ innovative behavior is impor­
tant for the development of employees and organizations in the digital

This study is supported by the Innovative Research Fund of Higher Education of Gansu Province (Grant number: 2022A-082), Postgraduate Innovative Research
Fund of University of International Business and Economics (Grant number: 202221).
* Corresponding author.
E-mail addresses: yinmeng1231@qq.com (M. Yin), jsy_nku@sina.com (S. Jiang), niuxy@uibe.edu.cn (X. Niu).
☆

https://doi.org/10.1016/j.chb.2023.107987
Received 11 March 2023; Received in revised form 11 September 2023; Accepted 29 September 2023
Available online 11 October 2023
0747-5632/© 2023 Elsevier Ltd. All rights reserved.

M. Yin et al.

Computers in Human Behavior 150 (2024) 107987

and intelligent era.
Can AI promote employee innovation if it cannot completely replace
employees in innovation-related tasks? According to the Society for
Industrial and Organizational Psychology’s top ten workplace trends
list, AI continues to be the top workplace trend and is relevant to almost
every organizational function (SIOP Administrative Office, 2020). This
has brought to prominence the influence of AI on employees’ innovation
behavior, with most researchers arguing that AI can improve employees’
creativity and innovation behavior in general (e.g., Arias-Perez &
Velez-Jaramillo, 2022; Jia et al., 2023; Verma & Singh, 2022). However,
competent AI may also have a negative impact on employees’ psycho­
logical well-being (Stein et al., 2020) and motivate employees’ avoid­
ance behavior (Brougham & Haar, 2017), thus suppressing employee
innovation behavior. Considering these contradictory arguments, unlike
previous studies that focused on the positive effect of AI on employees’
innovation behavior, we suppose the coexistence of positive and nega­
tive effects of AI on employee innovation behavior. In short, we aim to
reveal the double-edged sword effect of AI assistants on employees’
innovation behavior.
First, we aim to investigate the mediating mechanisms through
which AI assistants have a double-edged sword effect on employee
innovation behavior. We introduce the transactional model of stress
(TMS)—an important theoretical perspective for revealing the doubleedged sword effect—to investigate the mediating mechanism thereof.
TMS describes the cognitive processes and subsequent responses when
confronted with a particular stressor (Lazarus & Folkman, 1987). Digital
technologies, including AI, can be a source of job stress because the
implementation of new technology allows employees to adapt to novel
task situations and learn new roles and skills (Park et al., 2020; Shin,
2022; Wang, Liao, Chen, Zhang, & Qian, 2023; Yu et al., 2018). Thus, AI
assistants can increase employees’ perceptions of stress, which subse­
quently induce cognitive processes and responses. According to the
TMS, AI assistants can be evaluated positively by employees, induce
positive responses (Gelbrich et al., 2021; Guha et al., 2023), or be
evaluated negatively, induce negative responses (Spatola & Normand,
2020; Stein et al., 2020). Therefore, we propose that AI assistants with
high intelligence not only lead to a creative self-efficacy, which in turn
promotes innovation behaviors, but also lead to a STARA awareness,
which in turn suppresses innovation behavior.
STARA awareness refers to the extent to which employees feel that
their jobs can be replaced by smart technology, AI, robotics, and algo­
rithms (Lingmont & Alexiou, 2020). STARA awareness has served as a
predictor of employees’ emotions, cognition, and behaviors toward AI
(Brougham & Haar, 2017; Kong et al., 2021; Li et al., 2019). For
example, Liang et al. (2022) found that STARA awareness increased
employees’ emotional exhaustion, intrinsic motivation, and innovative
service behaviors. These studies assumed that STARA awareness arises
spontaneously in individuals, focusing only on the central role of
humans, while ignoring the broader technological context of work
(Anthony et al., 2023). However, employees may not perceive a threat
when the AI is incompetent, malfunctioning, or inefficient. We believe
that STARA awareness does not arise spontaneously in individuals but is
stimulated by AI itself. High-intelligence AI may be a predictor of STARA
awareness, which plays a mediating role between AI-assistant intelli­
gence and employees’ AI-enabled innovative behavior.
Creative self-efficacy refers to individuals’ belief in their ability to
generate creative outcomes when working with an AI assistant (Tierney
& Farmer, 2002). People rely on mastery and vicarious experiences as
sources of information pertaining to their level of self-efficacy (Bandura,
1997). However, the implementation of AI in the workplace means that
employees must adapt to novel task situations in which they lack the
experience of innovating when working with AI. If so, how can AI
contribute to the development of creative self-efficacy among employees
who lack innovation experience when working with AI? To answer this
question, we extended the antecedents of employees’ creative
self-efficacy when working with AI based on a model of the determinants

of self-efficacy (Gist & Mitchell, 1992). We argue that high-intelligence
AI can contribute to the development of employees’ creative
self-efficacy because of providing them with resources for innovation.
Therefore, creative self-efficacy plays a mediating role between
AI-assistant intelligence and AI-enabled innovative behavior.
Second, we aim to investigate the boundary conditions under which
AI has a positive or negative impact on employees’ AI-enabled innova­
tive behavior. Although previous research has implied the important
role of organizational factors in implementing and integrating AI sys­
tems (Parker & Grote, 2022; Prikshat et al., 2022; Seeber et al., 2020), it
is unclear how organizational factors intervene employee-AI collabo­
ration. According to the TMS, individuals may not appraise or respond to
certain stressors in the same way (Lazarus & Folkman, 1987). Organi­
zational factors partly account for variations in employees’ differential
appraisals and responses to a given stressor. For example, Gursoy et al.
(2019) found that social influence and group norms influenced in­
dividuals’ cognitive appraisal of AI devices. Hence, we believe that
employees’ cognitive appraisals of AI assistants are influenced by
organizational factors-organizational AI readiness. Organizational AI
readiness refers to the state of preparedness and availability of the
organizational resources required to adopt AI (Prikshat et al., 2021).
Employees that belong to organizations with different degrees of AI
readiness may be in a different position to assess, prepare, and integrate
AI assistants into their work (Makarius et al., 2020), which may influ­
ence their appraisals and responses to AI. We propose that organiza­
tional AI readiness moderates the relationship between AI assistants and
employees’ creative self-efficacy as well as the relationship between AI
assistants and STARA awareness.
In this study, by proposing an integrative model based on TMS, we
uniquely reveal the double-edged sword effect of AI-assistant intelli­
gence. Our model achieves a consensus on the different theoretical views
on how AI influences employees, and provides a new theoretical lens for
research on the relationship between AI and employees. Further, we
propose an influence mechanism that explains how high-intelligence AI
assistants influence employees’ innovation behaviors. We also highlight
the moderating role of organizational AI readiness, demonstrating how
organizational AI readiness strengthens the positive effect of AI on
employees and weakens the negative effect of AI on employees. These
findings contribute to the literature on AI-related organizational factors.
Finally, we extend the antecedents of STARA awareness and creative
self-efficacy from the perspective of AI characteristics, which has im­
plications for future research on the importance of AI actors in
human–AI collaboration.
2. Theory and hypotheses
2.1. AI assistant and employees’ innovation behavior: mediating role of
creative self-efficacy
TMS suggests that individuals appraise stressors, and then consider
their subsequent coping (Lazarus & Folkman, 1987). The more an in­
dividual perceives a stressor as a benefit or an opportunity, the more
likely they are to adopt problem-focused coping (Lazarus & Folkman,
1984). Problem-focused coping refers to positive psychological states
and approaching behaviors in response to stressors (Lazarus & Folkman,
1987). In the context of workplace technology usage, employees can
perceive positive psychological states and engage in approaching be­
haviors when they appraise technologies as benefits and opportunities
for their work. For example, Beaudry and Pinsonneault (2010) found
that, when employees appraised the information technology as a benefit
to their work, they would perceive playfulness and show adaptive be­
haviors. Gursoy et al. (2019) found that customers feel positive emotions
and accept AI devices when they appraise them as a benefit during
service encounters. Drawing on the TMS (Lazarus & Folkman, 1984), we
propose that employees can perceive creative self-efficacy and perform
AI-enabled innovation behavior when they regard AI assistants as a
2

M. Yin et al.

Computers in Human Behavior 150 (2024) 107987

benefit and opportunity for their work.
We first explain why AI assistants with high intelligence increase
employees’ creative self-efficacy. The construct of creative self-efficacy
is a promising application of self-efficacy to employees’ creative per­
formance (Tierney & Farmer, 2002). Bandura (1997) suggested that four
categories of experience are used to develop self-efficacy: mastery,
vicariousness, social persuasion, and physiological arousal. Previous
experience contributes to a variety of information cues that ultimately
determine self-efficacy (Bandura, 1997). However, when employees are
in a novel task situation, they generally have insufficient experience in
completing the task. Gist and Mitchell (1992) extended the determinants
of self-efficacy by suggesting that it is formed through personal and
situational resources in novel task situations. Extending the theory to the
workplace AI usage context, the implementation of AI in the workplace
means that employees must adapt to a novel task situation in which they
lack the experience to innovate. Therefore, the availability of innovative
resources is key to developing employees’ creative self-efficacy when
working with AI.
On the one hand, AI assistants with high intelligence help conserve
the cognitive, mental, and emotional resources needed by employees for
innovation. Compared with low-intelligence AI assistants, which are
characterized as incompetent, malfunctioning, and inefficient, AI as­
sistants with high intelligence have strong and versatile problem diag­
nosis and resolution capabilities (Guha et al., 2023). They can accurately
perform various tasks with stable and reliable results (Yoon & Lee,
2019). Unlike AI assistants with low intelligence, which require manual
intervention, high-intelligence AI assistants are embedded with complex
artificial autonomy that allows them to perform tasks autonomously (Hu
et al., 2021). Driven by machine learning algorithms, the most advanced
AI assistants can operate proactively and perform tasks in line with
employees’ preferences by learning their working patterns, schedules,
and tastes (Han & Yang, 2018). With the help of a high-intelligence AI
assistant, employees are liberated from repetitive, well-codified, and
structured tasks. They have more autonomy in how to perform their
work (Verma & Singh, 2022) and conserve cognitive, mental, and
emotional resources to solve higher-level problems (Jia et al., 2023).
Employees can then invest the surplus of resources to solving creative
tasks, which increases their creative self-efficacy (Mathisen, 2011; Hu
et al., 2023).
On the other hand, such AI assistants help employees with the
instrumental resources needed for innovation. Compared with lowintelligence AI assistants, which can only perform simple and mechan­
ical tasks, high-intelligence AI assistants can augment employees’
working abilities and extend their cognition by assisting them in pro­
cessing information and analyzing data (Raisch & Krakowski, 2020). For
example, when dealing with uncertainty and complexity in organiza­
tional decision-making, AI can collect information about both internal
and external organizational environments to assist human decision
makers in predictive analytics (Jarrahi, 2018). Therefore, AI assistants
with high intelligence complement employees’ abilities with machines’
unique capabilities and compensate for employees’ limitations (Hunter,
2019; Verma & Singh, 2022). They provide the instrumental resources
needed by employees for innovation, which increases their creative
self-efficacy (Lu et al., 2023).
Aside from the role of high-intelligence AI assistants in providing
employees with the resources needed for innovation, they may provide
another source of self-efficacy: physiological arousal. Bandura (1997)
suggested that aversive physiological arousal hinders the development
of self-efficacy, whereas pleasurable physiological arousal promotes it.
High-intelligence AI assistants have a human-like mental power that
allows them to identify, understand, and influence employees’ emotions
(Huang & Rust, 2018; Lv et al., 2022). Indeed, outperforming AI can
transmit positive emotions to users (Chuah & Yu, 2021; Han, Yin, &
Zhang, 2023), thus reducing the psychological distance between them
and enhancing users’ positive emotions (Lee et al., 2022; Song et al.,
2022). In contrast, incompetent AI does not have human-like mental

power, making it difficult for users to perceive them (Yam et al., 2021).
Malfunctioning AI can also lead to user dissatisfaction and annoyance
(Filieri et al., 2022). Thus, we expect AI assistants with high intelligence
to promote employees’ creative self-efficacy by arousing positive
emotions.
Second, we explain why employees’ creative self-efficacy leads to AIenabled innovation behavior. Tarafdar et al. (2010) used the term
“ICT-enabled innovation” to describe the extent to which individuals use
ICT to enhance their innovation behavior and performance. Based on the
concept of ICT-enabled innovation, we propose AI-enabled innovation
behavior, which describes the extent to which individuals use AI to
improve their innovation behavior. Individuals’ creative self-efficacy is
an important predictor of innovation behavior (Tierney & Farmer,
2011). Creative self-efficacy has been associated with innovation
behavior in a variety of settings, including management (Chris­
tensen-Salem et al., 2020), education (Puozzo & Audrin, 2021), and
human–computer interaction (Chang et al., 2019). Employees with high
creative self-efficacy believe in their ability to generate creative ideas for
new products or processes, and have greater confidence in solving
problems creatively and generating solutions to new problems (Tierney
& Farmer, 2002). Therefore, employees’ creative self-efficacy promotes
AI-enabled innovation behavior.
Based on the above arguments, we argue that, compared with AI
assistants with low intelligence, AI assistants with high intelligence can
indirectly promote employees’ AI-enabled innovation behavior through
creative self-efficacy. Thus, we propose the following hypotheses:
H1a. An AI assistant characterized by high intelligence (versus low
intelligence) has a positive indirect effect on employees’ AI-enabled
innovation behavior through creative self-efficacy.
2.2. AI assistant and employees’ innovation behavior: mediating role of
STARA awareness
TMS suggests that the more an individual perceives the stressor as
harmful or threatening, the more likely they are to adopt emotionfocused coping (Lazarus & Folkman, 1984). Emotion-focused coping
refers to negative psychological states and avoidance behaviors in
response to stressors, such as work withdrawal behavior and managing
negative emotions associated with a stressful situation, rather than
solving the problem at hand (Lazarus & Folkman, 1987). In the context
of workplace technology usage, employees can perceive negative psy­
chological states and perform avoidance behaviors when they appraise
technologies as a threat or harm to their work. For example, Beaudry
and Pinsonneault (2010) found that, when employees appraised the
information technology as a threat to their work, they would feel anxiety
and were less likely to use it. Butts et al. (2015) found that employees’
negative appraisal of electronic communication led to negative emo­
tions and work-to-non-work conflicts. Drawing on TMS, we propose that
employees can perceive STARA awareness and reduce AI-enabled
innovation behavior when they regard AI assistants as a threat or
harm for their work.
First, we explain why AI assistants with high intelligence increase
employees’ STARA awareness. STARA awareness refers to an em­
ployee’s perception of their working state. Employees with high STARA
awareness believe that their jobs can be replaced by smart technology,
AI, robotics, and algorithms, reflecting a unique perception of job un­
certainty and insecurity in the digital era (Brougham & Haar, 2018).
Employees engage in social comparison when they work hand-in-hand
with an outperforming artificial agent. When the AI assistant out­
performs the employees in some tasks, their self-esteem suffers from
threats that would induce psychological discomfort and job insecurity
(Spatola & Normand, 2020; Stein et al., 2020; Wang et al., 2023).
Moreover, with the rapid advancement of AI, employees are required to
ensure that systems function properly and safely (Wilson & Daugherty,
2018). To some extent, advanced AI is gradually leading to a shift from
3

M. Yin et al.

Computers in Human Behavior 150 (2024) 107987

“human assisting machines” rather than the reverse (Huang & Rust,
2018). Machines determines business success, and employees may move
to a more marginal position in the value chain (Nelson & Irwin, 2013).
This shift diminishes employees’ value and worth, resulting in job
insecurity. In contrast, low-intelligence AI assistants do not have
human-like mental power; therefore, the degree of anthropomorphism
among AI assistants is low (Yam et al., 2021). Rather than threatening
employees, they foster a perception of self-identity and reduce intra­
group prejudice and tension (Jackson et al., 2019; Savela, Kaakinen,
Ellonen, & Oksanen, 2021). Thus, we expect AI assistants with high
intelligence to increase employees’ STARA awareness.
Second, we explain why employees’ STARA awareness reduces their
AI-enabled innovation behavior. STARA awareness reflects employees’
job insecurity when working with intelligent technology, which leads to
the avoidance of working motivation and behaviors (Lingmont &
Alexiou, 2020). Previous research has found that STARA awareness di­
minishes employees’ organizational commitment and job satisfaction
and induces job burnout and turnover intentions (Brougham & Haar,
2017; Kong et al., 2021; Li et al., 2019). Employees’ AI-enabled inno­
vation behavior indicates that they generate creative ideals or problem
solutions when working with AI assistants. This approaching behavior is
negatively related to avoidance motivation (Jin et al., 2016). Therefore,
employees’ STARA awareness suppresses AI-enabled innovation
behavior.
Based on the above arguments, we argue that, compared to AI as­
sistants with low intelligence, AI assistants with high intelligence can
indirectly suppress employees’ AI-enabled innovation behavior through
STARA awareness. Thus, we propose the following hypotheses:

and top management support to implement and maintain AI applica­
tions as well as sufficient installed and in-use enterprise systems and
network technologies on which AI applications can be built (Prikshat
et al., 2021).
The benefits of organizational readiness for AI adoption are already
known (Abuzaid et al., 2022; Prikshat et al., 2021; Wong et al., 2019).
Employees who belong to organizations with a higher degree of AI
readiness may be in a better position to rapidly assess, prepare, and
integrate new AI assistants into their work. AI-oriented organizations
are more capable and willing to leverage advances in AI as part of the
development of new products or services (Makarius et al., 2020). Hence,
employees who belong to organizations with a higher degree of AI
readiness are more capable of coping with AI assistants and believe in
their potential to perform tasks with AI assistant. Based on TMS (Lazarus
& Folkman, 1987), employees with a high degree of coping potential can
strengthen their positive appraisal and actively respond to AI assistants
or weaken their negative appraisal and passively respond to AI assis­
tants. Based on the above arguments, we argue that organizational AI
readiness strengthens the positive effect of AI-assistant intelligence on
employees’ creativity self-efficacy, while weakening the negative effect
of AI-assistant intelligence on employees’ STARA awareness. Thus, we
propose the following hypotheses:
H2a. Organizational AI readiness strengthens the relationship be­
tween AI-assistant intelligence and employees’ creative self-efficacy.
Specifically, the effect of AI-assistant intelligence on employees’ crea­
tive self-efficacy is stronger when organizational AI readiness is higher.
H2b. Organizational AI readiness weakens the relationship between
AI-assistant intelligence and employee STARA awareness. Specifically,
the effect of AI-assistant intelligence on employees’ STARA awareness
was weaker when organizational AI readiness was higher.

H1b. An AI assistant characterized as having high intelligence (versus
low intelligence) has a negative indirect effect on employees’ AI-enabled
innovation behavior through STARA awareness.

2.4. An integrative model

2.3. The moderating role of organizational AI readiness

Hypotheses 1a, 1b, 2a, and 2b suggest a moderated mediation model
in which the indirect effect of AI-assistant intelligence on employees’ AIenabled innovation behavior through employees’ creative self-efficacy
and STARA awareness is moderated by organizational AI readiness. In
other words, when organizational AI readiness is high, the effects of AI
on employees’ AI-enabled innovation behavior through creative selfefficacy are stronger. Conversely, when organizational AI readiness is
low, the effects of AI on employees’ AI-enabled innovation behavior via
creative self-efficacy are weaker. Regarding the mediating effect of
STARA awareness, when organizational AI readiness is higher, the ef­
fects of AI-assistant intelligence on employees’ AI-enabled innovation
behavior via STARA awareness are weaker. Conversely, when organi­
zational AI readiness is low, the effects of AI-assistant intelligence on
employees’ AI-enabled innovation behavior through STARA awareness
are stronger. Based on these arguments, we propose the following
hypotheses:

TMS (Lazarus & Folkman, 1987) suggests that when confronted with
a particular stressor, individuals go through several stages of appraisal,
including evaluating the relevance and importance of the stressor,
evaluating what can be done about the stressor, and finally, coping at­
titudes and behaviors. When employees perceive technology as a
benefit, the less they believe in their potential to cope with it, the less
likely they are to respond actively; when employees perceive technology
as a threat, the more they believe in their potential to cope with it, the
less likely they are to respond passively (Beaudry and Pinsonneault,
2010). Organizational factors in TMS answer the following question:
What can an individual do with organizational help when confronted
with a stressor? Organizational factors are related to the resources and
support available to employees, which partly account for the variation in
employees’ coping potential (Lazarus & Folkman, 1984). We introduced
organizational AI readiness as an organizational factor and investigated
its moderating effect on cognitive appraisal processes.
Organizational AI readiness was developed based on the concept of
organizational readiness, which refers to the state of preparedness and
availability of organizational resources required to adopt technology
(Hossain et al., 2016). Organizational readiness can be used to describe
the readiness of organizational resources required to adopt a specific
technology. For example, van de Weerd, Mangula, and Brinkkemper
(2016) defined organizational readiness as the availability of organiza­
tional resources to implement and integrate SaaS applications when
studying the influence of organizational factors on SaaS adoption.
Hence, organizational AI readiness can describe the state of prepared­
ness and availability of organizational resources required to adopt AI
(Prikshat et al., 2021). Moreover, this concept is often specified in terms
of four aspects: financial, expert human resources, infrastructure, and
top management support (Hossain et al., 2016). Organizations with high
AI readiness have sufficient financial resources, technical professionals,

H3a. Organizational AI readiness moderates the indirect relationship
between AI-assistant intelligence and employees’ AI-enabled innovation
behavior through creative self-efficacy such that the relationship is
stronger when organizational AI readiness is higher than when it is
lower.
H3b. Organizational AI readiness moderates the indirect relationship
between AI-assistant intelligence and employees’ AI-enabled innovation
behavior through STARA awareness such that the relationship is weaker
when organizational AI readiness is higher than when it is lower.
Fig. 1 illustrates the theoretical model.
3. Overview of studies
We conducted two scenario-based experiments to test our
4

M. Yin et al.

Computers in Human Behavior 150 (2024) 107987

Fig. 1. Theoretical model.

hypotheses. Participants’ behaviors in scenario-based experiments are
consistent with their actual work (Woods et al., 2006). Given the con­
straints of conducting a randomized field experiment of AI-employee
collaboration, scenario-based experiments are most often employed to
test the behavioral and psychological consequences of AI-employee
collaboration. For example, Tang, Koopman, Yam, et al. (2022) and
Tang, Koopman, McClean et al. (2022) stimulated participants’ role
breadth self-efficacy and self-esteem by video manipulation of AI usage.
Stein et al. (2020) created two written vignettes for the manipulation of
AI and revealed the effect of AI on individuals’ psychological well-being.
In Study 1, we examined the impact of AI-assistant intelligence on
employees’ AI-enabled innovation behavior, as well as the mediating
effects of creative self-efficacy (H1a) and STARA awareness (H1b). We
experimentally manipulated the intelligence of AI assistants and
measured participants’ creative self-efficacy, STARA awareness, and AIenabled innovation behavior. In Study 2, we replicated the scenariobased manipulation and design from Study 1, and further manipulated
organizational AI readiness. In Study 2, we further tested the results of
Study 1 and examined the moderating effect of organizational AI read­
iness on the relationship between AI-assistant intelligence, creative selfefficacy (H2a), and STARA awareness (H2b), as well as the moderated
mediation effect (H3a and H3b).

AI assistants, creative self-efficacy, STARA awareness, AI-enabled
innovation behavior, and the control variables.
4.2. Manipulation
To increase psychological realism, AI assistants conversationally
interacted with participants, which was conducted through a video
embedded in the survey. These videos combine sophisticated-looking
animation and an anthropomorphic-sounding voice created by an AIbased text-to-video service.
Verbal persuasion, in which individuals are verbally convinced that
they possess the capabilities required to act successfully, contributes to
the development of self-efficacy and other self-perceptions (Bandura,
1997). In the scenario-based experiments, by using experimental ma­
terial such as written vignettes (Ni et al., 2022; Mao, Quan, Li, & Xiao,
2021), pictures (Ng et al., 2022), and videos (Ng et al., 2022), partici­
pants were persuaded to believe that they had the ability to complete the
task, which, in turn, stimulated their self-efficacy. Therefore, the
experimental materials with written vignettes and AI-based videos used
in our experiments can make the participants believe that they can
complete innovative tasks when working with AI assistants (see Ap­
pendix A for the manipulation videos). Fig. 2 shows a sample image of
the virtual AI assistant “Amy” in the manipulation videos.
To distinguish between the different levels of AI-assistant intelli­
gence, we created two self-introductions of AI assistants based on the
common functions on the market and previous research (Kim et al.,
2022; Pitardi et al., 2022; Stein et al., 2020). Appendix B provides the
exact script used in the manipulation of AI-assistant intelligence levels
(see Appendix B for the exact script).

4. Study 1
4.1. Participants and procedures
We conducted a single-factor (high AI-assistant intelligence versus
low AI-assistant intelligence) between-subjects experiment. We
recruited 103 MBA students (Mage = 25.99, SD = 6.50, 47.6% male)
from a large university in China between September 2022 and October
2022. We invited students to participate in this experiment during the
break time of MBA classes. The MBA students volunteered for this
experiment and were compensated with course credit. MBA students are
well-educated and have substantial work and managerial experience,
which allows them to understand experimental scenarios quickly and
accurately. This approach potentially offers more realism in its assess­
ment of employee perceptions of AI assistants (Castilla & Benard, 2010).
We randomly assigned participants to one of two conditions. Subse­
quently, participants read a description of the scenario in which they
were instructed to imagine themselves as employees using an AI assis­
tant. The script describing the scenario is as follows:
Imagine you are a pre-sales engineer in charge of customer demand
dig-out, product solution design, bidding document production, and
bidding Q&A. In recent years, many industries and companies have
attempted to implement AI to assist employees in their daily work.
Following an investigation, your company’s managers have also decided
to bring in AI assistants to help you with your work.
The participants then watched the virtual AI assistant introduce
themselves and answer scenario-related questions based on how they
felt in a simulated situation. We measured the perceived intelligence of

4.3. Measures
All scales were presented in Chinese to the respondents. As the
measurement scales used were originally developed in English, we
conducted a commonly used translation and back-translation procedure

Fig. 2. The virtual AI assistant used in the studies.
5

Computers in Human Behavior 150 (2024) 107987

M. Yin et al.

for the items to ensure the equivalency of meaning in the Chinese
version.
We used the five-item semantic differential scale developed by
Bartneck et al. (2009) to assess participants’ perceived intelligence.
STARA awareness was measured using a five-item scale adapted from
Brougham and Haar (2018). Creative self-efficacy was measured using a
three-item scale adapted from Tierney and Farmer (2002). The items
were modified slightly to fit the research context. The measurement
scales used are listed in Table 1. The reliability and validity of the
measurement items were tested. First, the values of Cronbach’s α should
exceed 0.70. Second, three criteria were used to determine convergent
validity: composite reliability (CR) above 0.70, average variance
extracted (AVE) at least 0.50, and all factor loadings greater than 0.50 at
statistical significance. As shown in Table 1, all measures have good
reliability and validity.
Following Yam et al. (2022), we measured AI-enabled innovation
behavior using behavioral measures. At the end of the study, we told
participants that “after using the AI assistant for a while, the leader
assigned you a task. The company has developed a batch of new
equipment that requires you to find potential target customers and
design solutions. What would you do?“. Participants were asked to what
extent they would “use AI assistant to gather market information, find
new potential customers, and use AI assistant to restructure project
processes, design new solutions instead of applying old ones.”
Seven-point Likert scales ranging from 1 (strongly disagree) to 7
(strongly agree) were used to measure STARA awareness, creative
self-efficacy, and AI-enabled innovation behavior.
We controlled for the participants’ gender, age, familiarity with AI,

and prior experience. Familiarity with AI was measured using the scale
developed by Pitardi et al. (2022). Each participant rated their famil­
iarity with the AI in general conditions using a 7-point Likert scale
ranging from 1 (not familiar at all) to 7 (very familiar). Prior experience
was measured using a scale developed by Gelbrich et al. (2021). The
item for prior experience is “I have experience with using AI” (1 =
strongly disagree to 7 = strongly agree).
4.4. Results
4.4.1. Descriptive statistics and correlations
Means, standard deviations, and correlations for variables in Study 1
are presented in Table 2. As shown in Table 2, AI-assistant intelligence
positively correlated with participants’ creative self-efficacy (r = 0.439,
p < 0.001), and participants’ creative self-efficacy positively correlated
with AI-enabled innovation behavior (r = 0.394, p < 0.001). These re­
sults are consistent with and provide initial support for Hypothesis 1a.
4.4.2. Manipulation check
An independent samples t-test showed that, as expected, participants
in the experimental condition experienced higher levels of AI-assistant
intelligence (M = 4.035, SD = 0.753) than in the control condition
(M = 3.519, SD = 1.046), t = 2.896, p < 0.05. Thus, the manipulation of
AI-assistant intelligence was successful.
4.4.3. Confirmatory factor analysis
We conducted confirmatory factor analyses (CFAs) using structural
equation modeling (SEM) with Mplus 8.3 to test the construct validity.
Results indicated that the three-factor hypothesized model (i.e., AIassistant intelligence, creative self-efficacy, STARA awareness) demon­
strated acceptable model fit (χ2 (63) = 112.227, CFI = 0.951, TLI =
0.939, RMSEA = 0.087). Our hypothesized model was superior to two
alternative models: (1) a two-factor model, in which creative selfefficacy and STARA awareness loaded on a single factor (χ2 (65) =
409.915, CFI = 0.656, TLI = 0.587, RMSEA = 0.227) and (2) a onefactor model, in which AI-assistant intelligence, creative self-efficacy
and STARA awareness loaded on a single factor (χ2 (66) = 615.250,
CFI = 0.452, TLI = 0.352, RMSEA = 0.284).

Table 1
Scales used in Study 1 and Study 2.
Construct and item

Factor loading
(Study1)

Factor loading
(Study2)

AI-assistant intelligence (Study1: CR = 0.928, AVE = 0.764, Cronbach’s α = 0.925;
Study2: CR = 0.913, AVE = 0.725, Cronbach’s α = 0.898)
Incompetent/competent
0.899
0.907
Ignorant/knowledgeable
0.887
0.739
Irresponsible/responsible
0.801
0.820
Unintelligent/intelligent
0.905
0.867
Foolish/sensible
0.900
0.884
STARA awareness (Study1: CR = 0.934, AVE = 0.779, Cronbach’s α = 0.905; Study2:
CR = 0.938, AVE = 0.834, Cronbach’s α = 0.933)
I think my job could be replaced by STARA
0.856
0.889
(smart technology, artificial intelligence,
robotics, and algorithms).
I am personally worried that what I do now in
0.879
0.931
my job can be replaced by STARA.
I am personally worried about my future in my
0.887
0.919
organization owing to STARA replacing
employees.
I am personally worried about my future in my
0.907
0.910
industry owing to STARA replacing
employees.
Creative self-efficacy (Study1: CR = 0.961, AVE = 0.892, Cronbach’s α = 0.939;
Study2: CR = 0.953, AVE = 0.870, Cronbach’s α = 0.925)
I have confidence in my ability to solve
0.953
0.942
problems creatively when working with AI
assistance.
I feel that I am good at generating novel ideas
0.954
0.932
when working with AI assistance.
I have a knack for further developing the ideals
0.926
0.924
of others when working with AI assistance.
Organizational readiness (Study2: CR = 0.966, AVE = 0.877, Cronbach’s α = 0.953)
The company has financial resources for AI
0.934
assistance projects.
The company has expert human resources in AI
0.959
assistance.
The company has an excellent AI-based
0.933
infrastructure, including all IT components.
The company’s top managers support by
0.919
providing labor resources, finances, and
materials for AI assistance.

4.4.4. Hypothesis testing
SEM was used to test the hypothesized model. As shown in Fig. 3,
after controlling for participants’ gender, age, familiarity, and prior
experience, AI-assistant intelligence was positively related to creative
self-efficacy (β = 0.660, p <0.001), whereas AI-assistant intelligence
was not significantly related to STARA awareness (β = 0.189, n.s.).
Creative self-efficacy was positively related to AI-enabled innovation
behavior (β = 0.374, p <0.01) and STARA awareness negatively related
to AI-enabled innovation behavior (β = − 0.463, p <0.01). We tested the
mediating effects using the bootstrapped indirect effect analysis (5000
resamples). Results showed that the indirect effect of AI-assistant in­
telligence on AI-enabled innovation behavior via creative self-efficacy
was significant (coefficient = 0.247, 95% CI = [0.047, 0.500]),
whereas the indirect effect of AI-assistant intelligence on AI-enabled
innovation behavior via STARA awareness was not significant (coeffi­
cient = − 0.088, 95% CI [-0.223, 0.041]). These results supported Hy­
pothesis 1a but not 1b.
4.4.5. Discussion
Study 1 revealed that AI assistants with high intelligence can pro­
mote employees’ AI-enabled innovation behavior via creative selfefficacy, providing evidence for Hypothesis 1. However, we found no
support for the mediating role of employees’ STARA awareness. Ac­
cording to the TMS, employees evaluate what can be done by an AI
assistant also based on their coping potential. Employees who believed
in their potential to cope with AI were more likely to adopt problemfocused coping, whereas those who did not believed in their potential
6

M. Yin et al.

Computers in Human Behavior 150 (2024) 107987

Table 2
Descriptive statistics and correlations for study variables (Study 1).
Variable

M

SD

1

2

3

4

5

6

7

1. Gender
2. Age
3. Familiarity
4. Prior experience
5. AI-assistant intelligence
6. STARA awareness
7. Creative self-efficacy
8. AI-enabled innovation behavior

1.524
25.990
4.000
4.408
3.775
4.299
4.990
4.427

0.502
6.501
1.290
1.309
0.945
1.237
1.314
1.506

− 0.194*
− 0.212*
− 0.164
0.181
− 0.314**
− 0.086
0.103

0.105
0.143
− 0.178
0.011
0.004
− 0.121

0.563**
− 0.019
− 0.011
0.069
0.081

− 0.136
− 0.014
0.109
0.199**

0.098
0.439**
0.333*

0.119
− 0.251*

0.394**

Note: N = 102; *p < 0.05, **p < 0.001.

Fig. 3. Results of structural equation modeling (study1)
Note: N = 103. This is a simplified version of the actual model. *p < 0.05, **p < 0.001.

to cope with AI were more likely to adopt emotion-focused coping
(Spekman et al., 2018). Considering organizational characteristics have
been noted to affect employees’ coping potential (Parker & Grote,
2022). We designed Study 2 to reveal that, under what organizational
circumstance, the positive effect of AI assistants with high intelligence
on employees’ creative self-efficacy can be strengthened, and the posi­
tive effect of AI assistants with high intelligence on employees’ STARA
awareness can be significant.

organizational AI readiness. The items were modified slightly to fit the
research context. A sample item for organizational AI readiness is “The
company would have financial resources to adopt AI.” (1 = strongly
disagree to 7 = strongly agree). As shown in Table 1, all measures dis­
played good reliability and validity.
5.4. Results
5.4.1. Descriptive statistics and correlations
The means, standard deviations, and correlations of the variables in
Study 2 are presented in Table 3.

5. Study 2
5.1. Participants and procedures

5.4.2. Manipulation check
An independent sample t-test showed that, as expected, participants
in the experimental condition experienced higher levels of AI-assistant
intelligence (M = 4.021, SD = 0.711) than participants in the control
condition (M = 3.484, SD = 0.844), t = 4.741, p < 0.001. Participants in
the experimental condition perceived higher levels of organizational AI
readiness (M = 5.430, SD = 1.110) compared to participants in the
control condition (M = 3.553, SD = 1.631; t = 9.251, p < 0.001. Thus,
the manipulation of the AI-assistant intelligence and organizational AI
readiness was successful.

We conducted a 2 (high AI-assistant intelligence vs. low AI-assistant
intelligence) × 2 (high organizational AI readiness vs. low organiza­
tional AI readiness) between-subjects experiment. We recruited 191
MBA students (Mage = 26.44 SD = 8.87, 47.4% males) following the
same procedure and schedule as in Study 1. We randomly assigned the
participants to one of the four conditions. Next, participants read a
description of the scenario used in Study 1. The participants then
watched the virtual AI assistant introduce herself and read a description
of the organizational context. Finally, participants answered scenariorelated questions based on how they felt in the simulated situation.
We measured the perceived intelligence of AI assistants, organizational
AI readiness, creative self-efficacy, STARA awareness, AI-enabled
innovation behavior, and the control variables.

5.4.3. CFA
We conducted CFAs to test the construct validity using the same
procedure in Study 1. Table 4 shows that the fit indices for the proposed
four-factor model were satisfactory and superior to three alternative
models.

5.2. Manipulation
We performed the same manipulation of AI-assistant intelligence as
in Study 1. To manipulate organizational AI readiness, we created two
descriptions of the organizational context based on previous research
(Prikshat et al., 2021). Appendix B provides the script used to manipu­
late different levels of organizational AI readiness.

5.4.4. Hypothesis testing
Fig. 4 presents the results of the SEM. First, the hypothesis testing in
Study 1 was replicated. After controlling for gender, age, familiarity
with AI, and prior experience, the indirect effect of AI-assistant intelli­
gence on AI-enabled innovation behavior via creative self-efficacy was
significant (indirect effect = 0.178, 95% CI = [0.039, 0.419]), sup­
porting Hypothesis 1a. The indirect effect of AI-assistant intelligence on
participants’ AI-enabled innovation behavior via STARA awareness is
not significant (indirect effect = − 0.023, 95% CI [-0.138, 0.091]),
rejecting Hypothesis 1b.
To test the moderating role of organizational AI readiness, we con­
ducted the latent moderated structural equation modeling (LMS) using

5.3. Measures
The same scales as in Study 1 were used to measure the AI-assistant
intelligence, STARA awareness, creative self-efficacy, AI-enabled inno­
vation behavior, and control variables in Study 2. In addition, we used
the 4-item scale developed by Hossain et al. (2016) to assess
7

M. Yin et al.

Computers in Human Behavior 150 (2024) 107987

Table 3
Descriptive statistics and correlations for study variables (Study 2).
Variable

M

SD

1

2

3

4

5

6

7

8

1. Gender
2. Age
3. Familiarity
4. Prior experience
5. AI-assistant intelligence
6. Organizational AI readiness
7. STARA awareness
8. Creative self-efficacy
9. AI-enabled innovation behavior

1.526
26.437
4.100
4.290
3.753
4.501
4.251
5.063
4.825

0.501
8.866
1.198
1.510
0.824
1.677
1.442
1.229
1.405

− 0.221**
− 0.176*
− 0.042
− 0.029
0.051
0.087
0.000
− 0.028

− 0.013
− 0.091
0.033
− 0.255**
− 0.327**
0.035
0.127

0.464**
0.002
− 0.022
− 0.025
0.024
0.190**

0.091
− 0.024
0.064
− 0.009
0.214**

0.121
0.067
0.250**
0.226**

0.176*
0.210**
− 0.019

− 0.053
− 0.280**

0.330**

Note: N = 191; *p < 0.05, **p < 0.001.
Table 4
Results of CFAs.
Model

χ2

df

TLI

CFI

RMSEA

Four-factor model (a-b-c-d)
Three-factor model 1 (a-bc-d)
Two-factor model 2 (a-bcd)
One-factor model (abcd)

124.332
575.802
1175.405
1962.330

98
101
103
104

0.987
0.771
0.494
0.131

0.989
0.808
0.565
0.247

0.038
0.158
0.235
0.307

Note: a = AI-assistant intelligence; b = creative self-efficacy; c = STARA
awareness; d = organizational AI readiness.

Mplus 8.3. As shown in Fig. 4, after controlling for participants’ gender,
age, familiarity, and prior experience, the interaction between AIassistant intelligence and organizational AI readiness was significantly
and positively related to creative self-efficacy (β = 0.286, p <0.001).
The simple slope tests and interaction plot in Fig. 5 show that, when
organizational AI readiness was higher (SD + M), the relationship be­
tween AI-assistant intelligence and creative self-efficacy was positive
(simple slope = 0.622, p <0.001). In contrast, when organizational AI
readiness was low (SD-M), the relationship became non-significant
(simple slope = 0.077, p = 0.567). Therefore, Hypothesis 2a was
supported.
The interaction between AI-assistant intelligence and organizational
AI readiness was significantly and negatively related to STARA aware­
ness (β = − 0.267, p <0.05). The simple slope tests and interaction plot
in Fig. 6 show that, when organizational AI readiness was lower (SD-M),
the relationship between AI-assistant intelligence and creative selfefficacy was positive (simple slope = 0.319, p <0.05). In contrast,
when organizational AI readiness was higher (SD + M), the relationship
became non-significant (simple slope = − 0.175, p = 0.212). Therefore,
Hypothesis 2b was supported.
To test the moderated mediating effects, we conducted the LMS using
Mplus 8.3. Following the procedure introduced by Edwards and Lambert
(2007), we tested the indirect effects of AI-assistant intelligence on
AI-enabled innovation behavior via creative self-efficacy/STARA
awareness at higher (+1 SD) and lower (− 1 SD) levels of organiza­
tional AI readiness and the difference between these two effects (index
of moderated mediation). The mediating effect was moderated if the

Fig. 5. The moderating effect of organizational AI readiness on the relationship
between AI-assistant intelligence and creative self-efficacy.

index of moderated mediation was significant (Edwards and Lambert,
2007). To assess the significance of the index of moderated mediation,
we calculated bootstrapped bias-corrected CIs for 500 resamples with a
95% confidence interval.
As shown in Table 5, the difference between the indirect effects of AIassistant intelligence on AI-enabled innovation behavior via creative
self-efficacy at higher and lower levels of organizational AI readiness
was significant (moderated mediation index = 0.226, 95%CI [0.064,
0.531]). Therefore, Hypothesis 3a was supported. The difference be­
tween the indirect effects of AI-assistant intelligence on AI-enabled
innovation behavior via STARA awareness at higher and lower levels
of organizational AI readiness was significant (moderated mediation
index = 0.139, 95%CI [0.019, 0.429]). Therefore, Hypothesis 3b was
supported.

Fig. 4. Results of structural equation modeling (study2)
Note: N = 191. This is a simplified version of the actual model. *p < 0.05, **p < 0.001.
8

M. Yin et al.

Computers in Human Behavior 150 (2024) 107987

assistant characterized as high-intelligence (vs. low-intelligence) has a
positive indirect effect on employees’ AI-enabled innovation behavior
via creative self-efficacy, and the indirect effect is stronger when orga­
nizational AI readiness is higher than it is lower; and (2) an AI assistant,
characterized by high-intelligence (vs low-intelligence), has a negative
indirect effect on employees’ AI-enabled innovation behavior via STARA
awareness when organizational AI readiness is lower.
6.2. Theoretical contributions
This study has important implications for theory and research. First,
contradictions exist regarding the consequences of AI in workplace. On
the one hand, AI is beneficial to employees because it can augment their
working abilities. On the other hand, AI can create job insecurity and
other negative psychological consequences. We propose an integrative
model that shows the coexistence of two pathways through which AI
assistants influence employees’ innovation behavior. It helps resolve
previous contradictory arguments about the consequences of AI in the
workplace and advances our understanding of the consequences of AI
from the “bright” and “dark” sides simultaneously.
Second, based on TMS, we introduced creative self-efficacy and
STARA awareness as mediators. Our findings indicate that AI assistants
promote employees’ AI-enabled innovation behavior through creative
self-efficacy and suppress employees’ AI-enabled innovation behavior
through STARA awareness when organizational AI readiness is low. By
proposing and testing the mediating effects of creativity self-efficacy and
STARA awareness, our study reveals the mechanism through which AI
influences employee innovation. These findings also provide a new
theoretical lens for future research on revealing how AI influence em­
ployees’ behaviors.
Third, although previous research has implied the important role of
organizational factors in implementing and integrating AI systems
(Parker & Grote, 2022; Prikshat et al., 2022; Seeber et al., 2020), it is
unclear how organizational factors intervene employee-AI collabora­
tion. Based on TMS, we identified and tested the moderating effect of
organizational AI readiness. This study reveals the boundary conditions
under which the positive influence of AI on employees can be
strengthened and the negative influence of AI on employees can be
weakened. Thus, these findings contribute to the literature on organi­
zational readiness and broaden our knowledge of the role of organiza­
tional factors in coordinating employee-AI collaboration.
Fourth, STARA awareness serves as a predictor of employees’ emo­
tions, cognition, and behavior toward AI (Brougham & Haar, 2017; Kong
et al., 2021; Li et al., 2019). These studies assumed that STARA
awareness arises spontaneously in individuals, focusing only on the
central role of humans, while ignoring the broader technological context
of work (Anthony et al., 2023). We propose that STARA awareness does
not arise spontaneously in individuals, but is stimulated by AI itself. Our
study provides experimental evidence that AI positively correlates with
STARA awareness. These findings contribute to the literature on the
antecedents of STARA awareness and highlight the important role of AI
in human–AI collaboration.
Fifth, employees rely on work experience as a source of self-efficacy
(Bandura, 1997). However, the implementation of AI in the workplace
means that employees must adapt to novel task situations in which they
lack the experience of innovating. Drawing on a model of the de­
terminants of self-efficacy (Gist & Mitchell, 1992), we argue that AI with
high intelligence can promote employees’ creative self-efficacy because
of providing innovation resources and arousing positive emotions. Our
study provides experimental evidence that AI positively correlates with
creative self-efficacy. These findings contribute to the literature on an­
tecedents of creative self-efficacy in novel AI-related task situations.

Fig. 6. The moderating effect of organizational AI readiness on the relationship
between AI-assistant intelligence and STARA awareness.
Table 5
Results of moderated mediation tests.
Path

Slopes

Standard
Error

95% CI
Upper

Lower

AI-assistant intelligence→Creative self-efficacy→AI-enabled innovation behavior
High organizational AI readiness
0.303
0.156
0.115
0.743
(M + SD)
Low organizational AI readiness
0.077
0.107
− 0.068
0.410
(M-SD)
Slope difference
0.226
0.112
0.064
0.531
AI-assistant intelligence→STARA awareness→AI-enabled innovation behavior
High organizational AI readiness
0.048
0.072
− 0.050
0.262
(M + SD)
Low organizational AI readiness
− 0.091
0.072
− 0.295
0.010
(M-SD)
Slope difference
0.139
0.093
0.019
0.429

Note: N = 191; *p < 0.05, **p < 0.001.

5.5. Discussion
Study 2 not only confirms the findings of Study 1, but also reveals
that organizational AI readiness strengthens the indirect relationship
between AI-assistant intelligence and employees’ AI-enabled innovation
behavior through creative self-efficacy. In Study 1, we failed to find
evidence for the mediating role of employees’ STARA awareness.
However, Study 2 reveals that the indirect relationship between AIassistant intelligence and employees’ AI-enabled innovation behavior
through STARA awareness is significant when organizational AI readi­
ness is lower. In general, Study 2 revealed the boundary condition under
which the positive influence of AI assistants with high intelligence on
employees can be strengthened and the negative influence of AI assis­
tants with high intelligence on employees can be weakened. These
findings are consistent with the literature on the important role of
organizational readiness in the effective integration of AI (Seeber et al.,
2019; Prikshat et al., 2021; Makarius et al., 2020).
6. Conclusions and general discussion
6.1. Conclusions
Based on TMS, we investigated the double-edged sword effect of AI
assistants with high intelligence on employees’ innovation behavior.
Using two experimental scenarios, the results indicate that (1) an AI

6.3. Practical implications
This study has several practical implications. First, despite the
9

M. Yin et al.

Computers in Human Behavior 150 (2024) 107987

potential for AI to drive organizationally valued outcomes, there is ev­
idence that many companies do not experience the anticipated benefits
(Canhoto & Clear, 2020). Many companies invest time, effort, and re­
sources in AI yet find it difficult to integrate AI with existing people,
processes, and systems, ultimately deeming AI initiatives failures
(Fountaine et al., 2019). Companies need to realize that AI is a
double-edged sword that may either promote or inhibit employee
innovation behavior, depending on whether it works through the crea­
tive self-efficacy pathway or the STARA awareness pathway. We suggest
that managers try their best to take measures to reduce employees’
STARA awareness and enhance creative self-efficacy. On the one hand,
managers can design a variety of interventions to identify, manage, and
prevent STARA awareness. Managers should provide employees with
learning and career development opportunities, resources, and organi­
zational support. This support can help them adapt their skills and ca­
pacities to the technology-driven changing work environment and find
opportunities to perform subjective work that would not be easily
replaced by AI. On the other hand, managers should also realize that AI
is used not only to automate a variety of tasks that used to be performed
by humans but also to augment employees’ working abilities and pro­
mote their performance. Managers should evaluate the best AI appli­
cations and design effective organizational structures or management
systems to exploit its advantages.
Second, our findings reveal the boundary conditions under which
AI’s positive and negative influences on employees can be strengthened.
Hence, although AI is a double-edged sword, companies can benefit
from it while avoiding its negative impacts by promoting their organi­
zations’ AI readiness. Specifically, we suggest that companies provide
sufficient investment and technical professionals to implement and
maintain AI applications to ensure that employees receive timely help
when they have difficulty using AI. Companies should invest in AI-based
infrastructures and equip their employees with high-performance com­
puters and high-speed networks. Top management should motivate
employees to integrate AI into their working processes, resolve conflict,
rebalance power at different phases of the technology assimilation
lifecycle, reward the desirable behaviors of employees in using AI, and
create an organizational climate of learning and active use of AI.

behaviors was not investigated. We suggest that future research could
broaden our understanding by investigating the relationship between
these characteristics and employees’ innovation behavior.
Fourth, the AI assistant played the role of coworkers in our research,
performing tasks for employees either independently or collaboratively.
AI can not only affect employees serving as coworkers, but also as su­
pervisors (Yam et al., 2022; Tong, Jia, Luo, & Fang, 2021). Therefore,
the findings of our research may not apply to AI, which performs
managerial tasks. We suggest that future research explore the impact of
AI serving as a supervisor on employees’ innovation behavior.
Fifth, in addition to the TMS, the job demands-resources model (JDR), conservation of resources theory, social information processing
theory, and other theories provide important theoretical perspectives to
reveal the double-edged sword effect. For example, the JD-R model
suggests that job demands and resources jointly determine an in­
dividual’s working status (Hobfoll, 2002). Job demands cause in­
dividuals to experience strain. Job demands can also be considered
challenging and motivate employees to implement positive behaviors
when they have sufficient job resources (Liang et al., 2022). Because
techno-overload, techno-complexity, and techno-uncertainty of AI itself,
which can lead to technostress and consume individuals’ physical and
psychological resources, the implementation of AI was considered to be
job demands (Wang et al., 2023). We suggest that future research
investigate the double-edged sword effect of AI-assistant intelligence on
employees’ innovation behavior based on the JD-R model, which could
help reveal different mediating mechanisms and boundary conditions.
CRediT authorship contribution statement
Meng Yin: Writing – original draft, Software, Methodology, Formal
analysis, Conceptualization. Shiyao Jiang: Writing – review & editing,
Data curation, Conceptualization. Xiongying Niu: Writing – review &
editing, Funding acquisition.
Declaration of competing interest
The authors declare that they have no known competing financial
interests or personal relationships that could have appeared to influence
the work reported in this paper.

6.4. Limitations and future research
This study has several limitations that set the stage for promising
future studies. First, we conduct two scenario-based experiments to test
our hypotheses. Although experimental materials were provided to
simulate reality, there is still a bias between the experimental scenario
and the actual working situation, which may limit the external validity
of the results. A field design should be applied to test the relationships
documented in the future and strengthen the external validity of our
findings.
Second, our results are based on a convenience sample, and the
majority of participants were MBA students, which helps establish the
internal validity of the results but simultaneously weakens the external
validity at the same time. Although professional and educational back­
grounds did not directly affect our dependent variables, previous
research argued that employees with a technology/engineering degree
or higher knowledge, skills, and abilities could develop greater advan­
tages in collaboration with AI (Kim et al., 2022; Oksanen et al., 2020)
that might, in turn, have affected our outcome (Jia et al., 2023). Future
research should replicate and extend these results with a more balanced
sample in terms of professional and educational background.
Third, we experimentally manipulated AI-assistant intelligence to
examine its effect on employees’ innovation behaviors. Anthropomor­
phism (Yam et al., 2021), emotional support (Gelbrich et al., 2021),
transparency (Glikson & Woolley, 2020), and other characteristics of AI
assistants may also influence employees’ innovation behavior via psy­
chological outcomes. Although we controlled for these characteristics in
our experimental design, their impact on employees’ innovative

Data availability
Data will be made available on request.
Appendix A. Supplementary data
Supplementary data to this article can be found online at https://doi.
org/10.1016/j.chb.2023.107987.
References
Abuzaid, M. M., Elshami, W., Tekin, H., & Issa, B. (2022). Assessment of the willingness
of radiologists and radiographers to accept the integration of artificial intelligence
into radiology practice. Academic Radiology, 29(1), 87–94.
Anthony, C., Bechky, B. A., & Fayard, A. L. (2023). Collaborating” with AI: Taking a system
view to explore the future of work. online: Organization Science.
Arias-Perez, J., & Velez-Jaramillo, J. (2022). Ignoring the three-way interaction of digital
orientation, not-invented-here syndrome and employee’s artificial intelligence
awareness in digital innovation performance: A recipe for failure. Technological
Forecasting and Social Change, 174, Article 121350.
Bandura, A. (1997). Self-efficacy: The exercise of control. New York: Freeman.
Bartneck, C., Kulić, D., Croft, E., & Zoghbi, S. (2009). Measurement instruments for the
anthropomorphism, animacy, likeability, perceived intelligence, and perceived
safety of robots. International Journal of Social Robotics, 1(1), 71–81.
Beaudry, A., & Pinsonneault, A. (2010). The other side of acceptance: Studying the direct
and indirect effects of emotions on information technology use. MIS Quarterly, 34(4),
689–710.
Brougham, D., & Haar, J. (2017). Smart technology, artificial intelligence, robotics, and
algorithms (STARA): Employees’ perceptions of our future workplace. Journal of
Management and Organization, 24(2), 239–257.

10

M. Yin et al.

Computers in Human Behavior 150 (2024) 107987

Brougham, D., & Haar, J. (2018). Smart technology, artificial intelligence, robotics, and
algorithms (STARA): Employees’ perceptions of our future workplace. Journal of
Management & Organization, 24(2), 239–257.
Brynjolfsson, E., Rock, D., & Syverson, C. (2021). The productivity J-Curve: How
intangibles complement general purpose technologies. American Economic Journal:
Macroeconomics, 13(1), 333–372.
Butts, M. M., Becker, W. J., & Boswell, W. R. (2015). Hot buttons and time sinks: The
effects of electronic communication during nonwork time on emotions and worknonwork conflict. Academy of Management Journal, 58(3), 763–788.
Canhoto, A. I., & Clear, F. (2020). Artificial intelligence and machine learning as business
tools: A framework for diagnosing value destruction potential. Business Horizons, 63
(2), 183–193.
Castilla, E. J., & Benard, S. (2010). The paradox of meritocracy in organizations.
Administrative Science Quarterly, 55, 543–576.
Chang, Y. S., Chen, M. Y. C., Chuang, M. J., & Chou, C. H. (2019). Improving creative
self-efficacy and performance through computer-aided design application. Thinking
Skills and Creativity, 31, 103–111.
Christensen-Salem, A., Walumbwa, F. O., Hsu, C. I. C., Misati, E., Babalola, M. T., &
Kim, K. (2020). Unmasking the creative self-efficacy-creative performance
relationship: The roles of thriving at work, perceived work significance, and task
interdependence. International Journal of Human Resource Management, 32(22),
4820–4846.
Chuah, H. W., & Yu, J. (2021). The future of service: The power of emotion in
human–robot interaction. Journal of Retailing and Consumer Services, 61(3), Article
102551.
Edwards, J. R., & Lambert, L. S. (2007). Methods for integrating moderation and
mediation: A general analytical framework using moderated path analysis.
Psychological Methods, 12, 1–22.
Filieri, R., Lin, Z. B., & Lu, X. Q. (2022). Customer emotions in service robot encounters:
A hybrid machine-human intelligence approach. Journal of Service Research, 25(4),
614–629.
Fountaine, T., McCarthy, B., & Saleh, T. (2019). Building the AI–powered organization.
Harvard Business Review, 62–73.
Gelbrich, K., Hagel, J., & Orsingher, C. (2021). Emotional support from a digital assistant
in technology-mediated services: Effects on customer satisfaction and behavioral
persistence. International Journal of Research in Marketing, 38(1), 176–193.
Ghosh, B., Daugherty, P., Wilson, J., & Burden, A. (2019). Taking a systems approach to
adopting AI. Harvard Business Review, 5(9), 2–6.
Gist, M. E., & Mitchell, T. R. (1992). Self-efficacy: A theoretical analysis of its
determinants and malleability. Academy ol Management Review, 17(2), 183–211.
Glikson, E., & Woolley, A. W. (2020). Human trust in artificial intelligence: Review of
empirical research. The Academy of Management Annals, 14(2), 627–660.
Guha, A., Bressgott, T., Grewal, D., Mahr, D., Wetzels, M., & Schweiger, E. (2023). How
artificiality and intelligence affect voice assistant evaluations. Journal of the Academy
of Marketing Science, 51, 843–886.
Gursoy, D., Chi, O. H., Lu, L., & Nunkoo, R. (2019). Consumers acceptance of artificially
intelligent device use in service delivery. International Journal of Information
Management, 49, 157–169.
Han, E., Yin, D., & Zhang, H. (2023). Bots with feelings: Should AI agents express positive
emotion in customer service? Information Systems Research, 34(3), 1296–1311.
Han, S., & Yang, H. (2018). Understanding adoption of intelligent personal assistants: A
parasocial relationship perspective. Industrial Management & Data Systems, 118(3),
618–636.
Hobfoll, S. E. (2002). Social and psychological resources and adaptation. Review of
General Psychology, 6, 307–324.
Hossain, M. A., Quaddus, M., & Islam, N. (2016). Developing and validating a model
explaining the assimilation process of RFID: An empirical study. Information Systems
Frontiers, 18(4), 645–663.
Huang, M. H., & Rust, R. T. (2018). Artificial intelligence in service. Journal of Service
Research, 21(2), 155–172.
Huang, M. H., & Rust, R. T. (2020). Engaged to a robot? The role of AI in service. Journal
of Service Research, 24(1), 30–41.
Hu, J. J., Xiong, L., Zhang, M. Y., & Chen, C. (2023). The mobilization of employees’
psychological resources: How servant leadership motivates pro-customer deviance.
International Journal of Contemporary Hospitality Management, 35(1), 115–136.
Hu, Q., Lu, Y., Pan, Z., Gong, Y., & Yang, Z. (2021). Can AI artifacts influence human
cognition? The effects of artificial autonomy in intelligent personal assistants.
International Journal of Information Management, 56, Article 102250.
Hunter, G. K. (2019). On conceptualizing, measuring, and managing augmented
technology use in business–to–business sales contexts. Journal of Business Research,
105, 201–213.
Jackson, J. C., Castelo, N., & Gray, K. (2019). Could a rising robot workforce make
humans less prejudiced? American Psychologist, 75(7), 969–982.
Jarrahi, M. H. (2018). Artificial intelligence and the future of work: Human–AI symbiosis
in organizational decision making. Business Horizons, 61(4), 577–586.
Jin, X. T., Wang, L., & Dong, H. Z. (2016). The relationship between self-construal and
creativity-regulatory focus as moderator. Personality and Individual Differences, 97,
282–288.
Kim, H., So, K. K. F., & Wirtz, J. (2022). Service robots: Applying social exchange theory
to better understand human-robot interactions. Tourism Management, 92, Article
104537.
Kong, H. Y., Yuan, Y., Baruch, Y., Bu, N. P., Jiang, X. Y., & Wang, K. P. (2021). Influences
of artificial intelligence (AI) awareness on career competency and job burnout.
International Journal of Contemporary Hospitality Management, 33(2), 717–734.
Lazarus, R. S., & Folkman, S. (1984). Stress, appraisal, and coping. New York, NY:
Springer.

Lazarus, R. S., & Folkman, S. (1987). Transactional theory and research on emotions and
coping. European Journal of Personality, 1(3), 141–169.
Lee, C. T., Pan, L. Y., & Hsieh, S. H. (2022). Artificial intelligent chatbots as brand
promoters: A two–stage structural equation modeling artificial neural network
approach. Internet Research, 32(4), 1329–1356.
Liang, X., Guo, G., Shu, L., Gong, Q., & Luo, P. (2022). Investigating the double-edged
sword effect of AI awareness on employee’s service innovative behavior. Tourism
Management, 92, Article 104564.
Li, J., Bonn, M. A., & Ye, B. H. (2019). Hotel employee’s artificial intelligence and
robotics awareness and its impact on turnover intention: The moderating roles of
perceived organizational support and competitive psychological climate. Tourism
Management, 73, 172–181.
Lingmont, D. N. J., & Alexiou, A. (2020). The contingent effect of job automating
technology awareness on perceived job insecurity: Exploring the moderating role of
organizational culture. Technological Forecasting and Social Change, 161, Article
120302.
Lu, L., Luo, T. H., & Zhang, Y. J. (2023). Perceived overqualification and deviant
innovation behavior: The roles of creative self-efficacy and perceived organizational
support. Frontiers in Psychology, 14, Article 967052.
Lv, X. Y., Yang, Y. F., Qin, D. Z., Cao, X. P., & Xu, H. (2022). Artificial intelligence service
recovery: The role of empathic response in hospitality customers’ continuous usage
intention. Computers in Human Behavior, 126, Article 106993.
Makarius, E. E., Mukherjee, D., Fox, J. D., & Fox, A. K. (2020). Rising with the machines:
A sociotechnical framework for bringing artificial intelligence into the organization.
Journal of Business Research, 120, 262–273.
Mao, J. Y., Quan, J., Li, Y., & Xiao, J. C. (2021). The differential implications of employee
narcissism for radical versus incremental creativity: A self-affirmation perspective.
Journal of Organizational Behavior, 42(7), 933–949.
Mathisen, G. E. (2011). Organizational antecedents of creative self-efficacy. Creativity
and Innovation Management, 20(3), 185–195.
Moussawi, S., Koufaris, M., & Benbunan-Fich, R. (2020). How perceptions of intelligence
and anthropomorphism affect adoption of personal intelligent agents. Electronic
Markets, 31, 343–364.
Nelson, A. J., & Irwin, J. (2013). Defining what we do—all over again”: Occupational
identity, technological change, and the librarian/internet-search relationship.
Academy of Management Journal, 57(3), 892–928.
Ng, T. W. H., Shao, Y. D., Koopmann, J., Wang, M., Hsu, D. Y., & Yim, F. H. K. (2022).
The effects of idea rejection on creative self-efficacy and idea generation: Intention
to remain and perceived innovation importance as moderators. Journal of
Organizational Behavior, 43(1), 146–163.
Nilsson, N. J. (1971). Problem-solving methods in artificial intelligence. New York: McGrawHill.
Ni, D., Song, L. J., Zheng, X. M., Zhu, J. L., Zhang, M. Y., & Xu, L. X. (2022). Extending a
helping hand: How receiving gratitude makes a difference in employee performance
during a crisis. Journal of Business Research, 149, 967–982.
Oksanen, A., Savela, N., Latikka, R., & Koivula, A. (2020). Trust toward robots and
artificial intelligence: An experimental approach to human–technology interactions
online. Frontiers in Psychology, 11, Article 568256.
Parker, S. K., & Grote, G. (2022). Automation, algorithms, and beyond: Why work design
matters more than ever in a digital world. Applied Psychology: International Review, 71
(4), 1171–1204.
Park, Y. A., Liu, Y., & Headrick, L. (2020). When work is wanted after hours: Testing
weekly stress of information communication technology demands using boundary
theory. Journal of Organizational Behavior, 41(6), 518–534.
Pitardi, V., Wirtz, J., Paluch, S., & Kunz, W. H. (2022). Service robots, agency and
embarrassing service encounters. Journal of Service Management, 33(2), 389–414.
Prikshat, V., Malik, A., & Budhwar, P. (2021). AI–augmented HRM: Antecedents,
assimilation and multilevel consequences. Human Resource Management Review,
Article 100860.
Prikshat, V., Malik, A., & Budhwar, P. (2021). AI-augmented HRM: Antecedents,
assimilation and multilevel consequences. Human Resource Management Review, 33
(1), Article 100860.
Puozzo, I. C., & Audrin, C. (2021). Improving self-efficacy and creative self-efficacy to
foster creativity and learning in schools. Thinking Skills and Creativity, 42, Article
100966.
Raisch, S., & Krakowski, S. (2020). Artificial intelligence and management: The
automation–augmentation paradox. Academy of Management Review, 46(2),
192–210.
Savela, N., Kaakinen, M., Ellonen, N., & Oksanen, A. (2021). Sharing a work team with
robots: The negative effect of robot co–workers on in–group identification with the
work team. Computers in Human Behavior, 115, Article 106585.
Seeber, I., Bittner, E., Briggs, R. O., de Vreede, T., de Vreede, G., Elkins, A., Maier, R.,
Merz, A. B., Oeste–Reiß, S., Randrup, N., Schwabe, G., & Söllner, M. (2020).
Machines as teammates: A research agenda on AI in team collaboration. Information
& Management, 57(2), Article 103174.
Shin, H. (2022). A critical review of robot research and future research opportunities:
Adopting a service ecosystem perspective. International Journal of Contemporary
Hospitality Management, 34(6), 2337–2358.
SIOP Administrative Office. (2020). SIOP announces top 10 workplace trends for 2020.
Society for Industrial and Organizational Psychology. https://www.siop.org/.
Song, X., Xu, B., & Zhao, Z. Z. (2022). Can people experience romantic love for artificial
intelligence? An empirical study of intelligent assistants. Information & Management,
59, Article 103595.
Spatola, N., & Normand, A. (2020). Human vs. machine: The psychological and
behavioral consequences of being compared to an outperforming artificial agent.
Psychological Research, 85, 915–925.

11

M. Yin et al.

Computers in Human Behavior 150 (2024) 107987
Wirtz, J., Patterson, G. P., Kunz, H. W., Gruber, T., Lu, V. N., Paluch, S., & Martins, A.
(2018). Brave new world: Service robots in the frontline. Journal of Service
Management, 29(5), 907–931.
Wong, S. H., Al-Hasani, H., Alam, Z., & Alam, A. (2019). Artificial intelligence in
radiology: How will we be affected? European Radiology, 29(1), 141–143.
Woods, S., Walters, M., Koay, K. L., & Dautenhahn, K. (2006). Comparing human robot
interaction scenarios using live and video based methods: Towards a novel
methodological approach. Proceedings of 9th IEEE international workshop on advanced
motion control, 750–755.
Yam, K. C., Bigman, Y. E., Tang, P. M., Ilies, R., Cremer, D. D., & Soh, H. (2021). Robots
at work: People prefer–and forgive–service robots with perceived feelings. Journal of
Applied Psychology, 106(10), 1557–1572.
Yam, K. C., Goh, E. Y., Feh, R., Lee, R., Soh, H., & Gray, K. (2022). When your boss is a
robot: Workers are more spiteful to robot supervisors that seem more human. Journal
of Experimental Social Psychology, 102, Article 104360.
Yang, H., & Lee, H. (2019). Understanding user behavior of virtual personal assistant
devices. Information Systems and e-Business Management, 17(1), 65–87.
Yoon, S. N., & Lee, D. (2019). Artificial intelligence and robots in healthcare: What are
the success factors for technology–based service encounters? International Journal of
Healthcare Management, 12(3), 218–225.
Yu, L., Cao, X., Liu, Z., & Wang, J. (2018). Excessive social media use at work: Exploring
the effects of social media overload on job performance. Information Technology &
People, 31(6), 1091–1112.
Jia, N., Luo, X.M., Fang, Z., & Liao, C.C. (2023). When and how artificial intelligence
augments employee creativity. Academy of Management Journal, in press. https://
doi.org/10.5465/amj.2022.0426.

Spekman, M. L. C., Konijn, E. A., & Hoorn, J. F. (2018). Perceptions of healthcare robots
as a function of emotion-based coping: The importance of coping appraisals and
coping strategies. Computers in Human Behavior, 85, 308–318.
Stein, J. P., Appel, M., Jost, A., & Ohler, P. (2020). Matter over mind? How the
acceptance of digital entities depends on their appearance, mental prowess, and the
interaction between both. International Journal of Human-Computer Studies, 142,
Article 102463.
Tang, P. M., Koopman, J., McClean, S. T., Zhang, J. H., Li, C. H., De Cremer, D., Lu, Y. Z.,
& Ng, C. T. S. (2022). When conscientious employees meet intelligent machines: An
integrative approach inspired by complementarity theory and role theory. Academy
of Management Journal, 65(3), 1019–1054.
Tang, P. M., Koopman, J., Yam, K. C., De Cremer, D., Zhang, J. H., & Reynders, P. (2022).
The self-regulatory consequences of dependence on intelligent machines at work: Evidence
from field and experimental studies. Human Resource Management. online.
Tarafdar, M., Tu, Q., & Ragu–Nathan, T. S. (2010). Impact of technostress on end–user
satisfaction and performance. Journal of Management Information Systems, 27(3),
303–334.
Tierney, P., & Farmer, S. M. (2002). Creative self-efficacy: Its potential antecedents and
relationship to creative performance. Academy of Management Journal, 45,
1137–1148.
Tierney, P., & Farmer, S. M. (2011). Creative self-efficacy development and creative
performance over time. Journal of Applied Psychology, 96(2), 277–293.
Tong, S. L., Jia, N., Luo, X. M., & Fang, Z. (2021). The Janus face of artificial intelligence
feedback: Deployment versus disclosure effects on employee performance. Strategic
Management Journal, 42(9), 1600–1631.
Verma, S., & Singh, V. (2022). The employees intention to work in artificial intelligencebased hybrid environments. IEEE Transactions on Engineering Management. https://
doi.org/10.1109/TEM.2022.3193664
Vlacic, B., Corbo, L., Silva, S. C. E., & Dabic, M. (2021). The evolving role of artificial
intelligence in marketing: A review and research agenda. Journal of Business
Research, 128, 187–203.
van de Weerd, I., Mangula, I. S., & Brinkkemper, S. (2016). Adoption of software as a
service in Indonesia: Examining the influence of organizational factors. Information
& Management, 53(7), 915–928.
Wang, B., Liao, Y. J., Chen, M., Zhang, L. T., & Qian, J. (2023). Work and affective
outcomes of social media use at work: A daily-survey study. The International Journal
of Human Resource Management, 34(5), 941–965.
Wang, H. T., Ding, H., & Kong, X. S. (2023). Understanding technostress and employee
well-being in digital work: The roles of work exhaustion and workplace knowledge
diversity. International Journal of Manpower, International Journal of Human Resource
Management, 44(2), 334–353.
Wilson, J., & Daugherty, P. (2018). Collaborative intelligence: Humans and AI are joining
forces. Harvard Business Review, 96(4), 114–124.

Meng Yin is a Ph.D. candidate at the Business school, University of International Business
and Economics. His research interests include workplace AI usage and employee-AI
collaboration.
Shiyao Jiang is an associate professor at the Business Administration School, Lanzhou
University of Finance and Economics. He holds a Ph.D. in Innovation & Entrepreneurship
Management from Nankai University. His research focuses on innovation & entrepre­
neurship management and digital transformation. His work has appeared in the Man­
agement Decision, Entrepreneurship Research Journal, and among others.
Xiongying Niu is a professor at the Business school, University of International Business
and Economics. He holds a Ph.D. in Applied Psychology from Chinese Academy of Sciences
(CAS). His research focuses on job research and selection, organizational change and
mental health. His work has appeared in the Journal of Applied Psychology, Journal of
Organizational Behavior, and among others.


A B S T R A C T

Keywords:
New year prints
Heritage preservation
AISAS model
Perceived value
Cultural identity
Sustainability
Digitization of intangible cultural heritage

The transformation of social development modes has led to profound changes in the pattern of
intangible cultural heritage, while simultaneously posing significant challenges to its preserva­
tion. The rapid development of artificial intelligence (AI) technology has brought new develop­
ment opportunities in various research fields. This study intends, by constructing and evaluating a
theoretical model, to investigate whether AI-generated cultural and creative products can pro­
mote the sustainability of intangible cultural heritage. The central focus of this research is to
measure the effectiveness of AI technologies in promoting the sustainability of intangible cultural
heritage. The context of the research design is rooted in the attention, interest, search, action, and
share (AISAS) model, incorporating theories of perceived value and cultural identity, to forecast
the long-term viability of AI-generated cultural and creative products in the promotion of
intangible cultural heritage. This research was conducted in Tianjin, China and carried out using
quantitative methods, a questionnaire survey, and the accidental sampling method, taking a
sample of 291 participants for analysis. The results show that 1) the attraction of and interest and
participation in AI-generated Yangliuqing New Year Print cultural and creative products have a
positive effect on perceived value; 2) the purchase and sharing of these products have a positive
impact on cultural identity; 3) the perceived value has a positive impact on cultural identity; and
4) cultural identity has a positive impact on the sustainability of intangible cultural heritage. This
study contributes to the theoretical development and practical application of the AISAS model
and offers valuable insights into the future development trajectory of intangible cultural heritage,
thereby promoting its sustainability. The limitations of this study are its small sample size and
geographical restrictions. In future studies, the sample size will be expanded and will include
more regions for data analysis.

* Corresponding author.
** Corresponding author.
E-mail addresses: zhangbolun@student.usm.my (B. Zhang), CHENGPENG@smedi.com (P. Cheng), luoguoshuai_tijmu@126.com (G. Luo),
327479685@qq.com (T. Gao).
https://doi.org/10.1016/j.heliyon.2023.e20477
Received 14 April 2023; Received in revised form 25 August 2023; Accepted 26 September 2023
Available online 27 September 2023
2405-8440/© 2023 The Authors.
Published by Elsevier Ltd.
This is an open access article under the CC BY-NC-ND license
(http://creativecommons.org/licenses/by-nc-nd/4.0/).

Heliyon 9 (2023) e20477

B. Zhang et al.

1. Introduction
Intangible cultural heritage is the embodiment of wisdom and art in the evolution of a nation and region, fully reflecting human
emotional expression and spiritual genes [1]. Therefore, in the process of social development, we are required to protect and transmit
intangible cultural heritage. New Year Prints, as a traditional folk art in China, are loved by all and are one of the aspects of China’s
excellent intangible cultural heritage.
They have huge artistic value and embody rich cultural connotations [2]. However, with the development of society and the
process of globalization and modernization, intangible cultural heritage has also suffered certain erosion and negative effects [3], and
many examples of intangible cultural heritage are finding it increasingly difficult to survive in modern society and are at risk of
disappearing [4]. In particular, New Year Prints, an example of intangible cultural heritage rooted in a traditional agricultural society,
have fallen into an embarrassing situation of imminent extinction as society develops and transforms [5]. Based on this, the Chinese
government and many scholars are committed to saving New Year Prints and addressing the crisis. In 2002, New Year Prints were
included in the first batch of the rescue list of the “China Folk Cultural Heritage Rescue Project” and in May 2006, the State Council of
China approved the inclusion of New Year Prints in the first batch of the national intangible cultural heritage list [6]. From a global
perspective, the United Nations Educational, Scientific and Cultural Organization (UNESCO) first proposed the concept of protecting
intangible cultural heritage in 2003. After the promulgation of the “Convention on the Protection of Intangible Cultural Heritage” in
the same year, the protection of intangible cultural heritage began to attract the attention of various countries [7]. All these studies and
subsequent protections aimed to allow excellent and precious aspects of intangible cultural heritage to continue to develop sustainably,
thus expressing a good cultural ecology.
In 1987, the “Our Common Future” report by the World Commission on Environment and Development first introduced the concept
of sustainable development. Sustainable development is defined as “development that meets the needs of the present without
compromising the ability of future generations to meet their own needs.” [8] The initial sustainable development paradigm mainly
included ecological, economic, and social dimensions [9]. During the United Nations Decade for Education and Development
(1988–1997), the relationship between culture and development was discussed, and since then, the link between sustainable devel­
opment and culture has become increasingly close [10]. Earlier, scholars around the world mainly discussed cultural sustainability as a
social dimension, but as they became more concerned with cultural issues in the paradigm of sustainable development, cultural
sustainability gradually moved away from the purely social dimension. In 2001, Hawkes defined cultural sustainability as the fourth
dimension of sustainability, emphasizing the role of culture in planning [ [11,12]]. Therefore, the protection and sustainable devel­
opment of intangible cultural heritage is of global concern.
Since the late 1990s, many heritage studies scholars and cultural industry practitioners have proposed using digital technology to
protect and promote cultural heritage, arguing that the application of digital technology in the field of cultural heritage can attract

Fig. 1. Cultural and creative products designed and developed by researchers: (a) keychain, (b) T-shirt, (c) desk calendar, and (d) phone case.
2

Heliyon 9 (2023) e20477

B. Zhang et al.

public attention and increase the accessibility of intangible cultural heritage. Consequently, cultural heritage digitization has become a
hot topic of study in recent years [13–17]. Regarding New Year Prints, Chinese scholars built a database during the rescue work to
better protect and preserve the paintings themselves. However, even with digitized storage of the New Year Prints, from production
methods to legacy works, people’s interest in the paintings has not recovered in current times. In particular, among the younger
generation, New Year Prints are often just a term that lingers in their minds, and most are unfamiliar with the paintings, which is
another form of negative response to New Year Prints. Therefore, we need to address the issues facing New Year Prints and adapt their
status by redesigning the product for the present era to better retain and develop the culture of New Year Prints.
Based on this, multiple designers have conducted research on New Year Prints and have renovated the design of New Year Prints by
combining different approaches. However, in the existing research on New Year Print design, the level of designers varies, making it
difficult for the final version to meet the needs of the present era. As a result, the authors proposes to generate artificial intelligence (AI)
New Year Print art images quickly and stably by training AI models that can be applied to New Year Prints as cultural and creative
products (CCPs) [2]. As shown in Fig. 1(a–d), the research results show that AI-generated art can meet the current needs of New Year
Prints and is favored by young people in the initial research. Although the product is popular, whether AI-generated art can engender
intangible cultural heritage and lead to sustainable development still needs further exploration. This study, based on this paradigm,
conducts follow-up research focusing on the quantitative study of Yangliuqing New Year Print AI-generated art CCPs, to explore
whether AI-generated art can stimulate the sustainable development of intangible cultural heritage.
Based on the above discussion, this study aims to conduct quantitative research on CCPs of New Year Prints generated using AI. By
improving the appropriate measurement model, we can measure the relationship between AI-generated New Year Print CCPs, their
perceived value, and attendant cultural identity to further measure their impact on the sustainability of intangible cultural heritage.
The essence of research on AI-generated New Year Prints is to generate new forms of New Year Print art images quickly and stably
using AI models, and users can participate in their generation. Applying it to CCPs and other applications will stimulate young people’s
interest in the New Year Print culture to learn more about the New Year Print culture and share the experience of using AI-generated
New Year Prints. They can directly perceive the value of AI-generated New Year pictures and CCPs and share them with others.
Promoting the New Year Prints generated by AI can not only spread culture better and enhance cultural identity but also impact
purchasing behavior, thereby bringing economic growth to the producers of these New Year Prints. This, in turn, can create a virtuous
circle by reinvesting profits into the creation of new prints, thus promoting the sustainable development of New Year Print culture.
However, the factors that affect users’ intention to continue using the product are complex and diverse, including not only personal
factors but also social and product-related factors. Therefore, we must consider whether the proposed models can address these three
key factors. The attention, interest, search, action, and share (AISAS) model is a new consumer behavior model developed based on
new media advertising and is mainly used in the research context related to e-commerce [18]. The five subspects of the AISAS model
can encompass the three key conceptual domains of the individual, and the social and product dimensions commonly considered in
product consumer research. The AISAS model was designed to cater to the demands of the present digital era, and its interactivity with
the internet enhances insights into consumer behavior and related activities online. Furthermore, AI-generated art is not just a
one-time creation; it also enables users to participate in the generation process and produce their unique product images, which
arouses their interest and triggers purchasing and sharing behaviors. Consequently, the authors have revised the third aspect of the
research to incorporate user participation, which stimulates purchasing and sharing.
In addition, New Year Print culture, as an aspect of intangible cultural heritage passed down from Chinese agrarian civilization,
embodies the cultural significance and value system that people of that society assigned to it, and therefore represents a collective
cultural identity. Unlike material cultural heritage, intangible cultural heritage absorbs cultural nutrients dynamically from different
historical periods during the transmission process, making it a special mechanism for transmitting cultural memory, which is presented
as a production and reproduction mechanism for recognizing social collective value [19]. The sustainability of culture essentially
refers to the concept of restoring and protecting cultural identity, transferring cultural values to future generations by various means
and thereby reconnecting with traditional customs [12]. Therefore, cultural identity factors can be used to measure young people’s
recognition and acceptance of New Year Print CCPs, addressing the larger goal of sustainability of intangible cultural heritage.
Simultaneously, a prerequisite of cultural identity is the personal experience of CCPs. A good esthetic experience and the emotional
experience of CCPs directly impact individuals’ perception of value, and the perception of value theory can help researchers identify
the relationship between the user experience and cultural identity in New Year Print CCPs.
In the current context, predicting the sustainable development of New Year painting culture can help address the current challenges
in the inheritance and development of intangible cultural heritage, particularly for items of intangible cultural heritage that today are
facing the challenge of preserving their functionality and enhancing their esthetic appeal in a rapidly modernizing society. Therefore,
this study adopts an empirical research design and uses survey methods to collect data. The data were analyzed using partial least
squares (PLS) techniques, and a theoretical framework was established based on the AISAS model, perception value theory, and
cultural identity theory to explore the user experience. The feasibility of AI-generated art in enabling the sustainable development of
traditional culture was investigated.
2. Literature review and theory development
2.1. Artificial intelligence and intangible cultural heritage
AI is a field within computer science that concentrates primarily on theoretical, methodological, technical, and practical systems
aimed at replicating, augmenting, and enhancing human intelligence. In contrast to other disciplines, the inception of AI can be traced
3

Heliyon 9 (2023) e20477

B. Zhang et al.

back to a significant milestone known as the Dartmouth Conference of 1956. During this influential event, the term “artificial intel­
ligence” was coined to designate this burgeoning field of study and the fundamental objectives of AI research were also established
[20]. John McCarthy presented a definition of AI: the science and engineering of making intelligent machines, much research has
humans program machines to behave in a clever way, like playing chess, but, today, we emphasize machines that can learn, at least
somewhat like human beings do [ [21,22]].
With the development of technology and hardware and the rapid growth in the volume of data, AI is also developing rapidly,
particularly with the emergence of deep learning. An important aspect of deep learning is its ability to learn hierarchical represen­
tations of data. This concept was first introduced by Bengio et al. [23], who proposed using deep architectures for unsupervised feature
learning. They showed that deep learning algorithms could automatically learn a hierarchy of features from raw data, leading to
improved performance in various tasks. Recent advances in deep learning have also been driven by the development of new tech­
niques, such as dropout regularization [24], batch normalization [25], and adversarial training [26]. These techniques have improved
the robustness, generalization, and efficiency of deep learning models.
Intangible cultural heritage consists of traditional and continuing cultural expressions and practices, including oral traditions,
social practices, rituals, festive events, and environmental knowledge, as well as the knowledge, skills and social practices required to
produce arts and crafts [ [7,27]]. Since the adoption of the UNESCO convention for the safeguarding of intangible heritage in 2003,
intangible cultural heritage has grown significantly as a field of study and digital workplace [28]. The booming trends in computing
heritage and information and communications technology applications play a vital role in safeguarding intangible cultural heritage, as
they generate multiple resources that are also accessible to the public [29]. The combination of these new technologies with intangible
cultural heritage has made the protection and dissemination of intangible cultural heritage through digital means increasingly widely
accepted. In addition, with the development of technology, we also recognize that digital technology plays an important role in the
protection and dissemination of intangible cultural heritage [30]. In particular, the application of AI in this field has brought new
possibilities for intangible cultural heritage. For example, in Pan’s research, developing an AI model to identify hand-painted thangkas
and machine-printed thangkas provides a powerful way to protect this precious intangible cultural heritage [31]. Tang et al. proposed
a lightweight AI neural network model named ShuiNet-A to classify and identify Shui manuscripts accurately [32]. Cui et al. also used
AI models to analyze and localize recorded martial arts motion images [33]. To summarize, it is feasible and advanced to apply AI
technology to the field of intangible cultural heritage.
2.2. Cultural and creative products
The definition of CCPs varies, using terms such as “cultural products,” “cultural creative merchandise,” and “display derivatives.”
[34] Essentially, it is a form of product that integrates cultural elements and modern design techniques to satisfy consumers’ spiritual
needs through its use. In China, CCPs are commonly found in museums, such as the Palace Museum, and local-characteristic tourism
CCPs, based on aspects of intangible cultural heritage developed by designers. These products generate significant economic impact
[35] and cater to the public’s spiritual needs [ [36,37]].
The design process of CCPs involves re-examination and reflection of the cultural factors inherent in the product. Through design,
traditional cultural elements are presented in a new form that conforms to the esthetic tastes of modern people [38]. In the field of New
Year Print culture, researchers have recently applied their findings in the extraction of cultural elements, including graphics and colors,
to design novel CCPs and to create an artistic image of New Year Prints. For instance, the artistic image of Yangliuqing New Year Prints
has been combined innovatively with the style of Pablo Picasso’s art [39], and the artistic graphics of fish in Yangliuqing New Year
Prints have been extracted to design paper-cut lanterns [40]. The colors of New Year Prints have been extracted for use in the color
design of power banks [41], and cultural symbol elements from Yangliuqing New Year Prints have been extracted to design CCPs such
as oil-paper umbrellas and emoticons [42]. However, the quality of these cultural and creative designs is dependent on the skill level
and the esthetics of the designer, and users are unable to participate in the production process. To address this issue, the author has
developed an AI design model to generate New Year Print images, which produces stable and reliable results, while also allowing users
to choose their favorite images and even participate in the production process, increasing their satisfaction.
2.3. The AISAS model
The AISAS model was proposed by the Japanese Dentsu Company to better depict consumer behavior in the internet era [43]. It is
an improvement on the Attention–Interest–Desire–Memory–Action (AIDMA) model proposed by Hall [44]. The new AISAS model is
considered more suitable for explaining consumer behavior in the internet era than the conventional AIDA model. With the emergence
of the internet, consumers can easily search for information or services related to products and are more willing to share their ex­
periences [45]. In this context, the marketing of products shifts from persuading consumers to information interaction, involving users
and increasing their satisfaction.
The AISAS model differs significantly from previous models, mainly in the way information is conveyed and interacted with. In­
formation exchange shifts from a single product provision to information sharing between users [46]. Through users’ proactive actions
and recommendations based on personal preferences and experiences, the impact of products or services is expanded [47]. This is
precisely the segmentation and behavior that traditional culture urgently needs, where users can share their good experiences and
personal feelings using traditional cultural products to expand the influence of traditional culture and diffuse it.
4

Heliyon 9 (2023) e20477

B. Zhang et al.

2.4. Perceived value
The theory of perceived value is a method for studying individuals’ perceptions and evaluations of goods and services. It endeavors
to explain why certain goods or services are deemed more valuable than others by some individuals [48]. According to the theory of
perceived value, the value of a good or service is determined by a combination of its features and factors related to the consumer’s
specific needs and preferences. For instance, one individual may place a higher value on hi-fi speakers due to their appreciation of
music, while another individual may not see this as important. This theory also involves psychological and environmental factors, such
as advertising, brand image, price, and social influence, which can impact an individual’s perception of goods and services and thus,
affect their evaluation. Research indicates that the theory of perceived value can be used effectively in market research to understand
consumers’ values and purchasing behavior. It can also be employed to help businesses enhance the appeal and competitiveness of
their products and services [49]. Burns (1993) considered perceived value to be a combination of functional value, emotional value,
social value, cognitive value, and situational value. Sweeney (2001) divided perceived value into emotional value, social value, quality
value [50], and price value, and this division was also adopted by Choi et al. in their research [51]. Deng et al. [52] categorized
perceived value into five components: perceived functional value, perceived remembrance value, perceived emotional value,
perceived social value, and perceived conditional value. Lin and Wang [53] maintained that perceived value is manifested in the
aspects of reputation, quality, monetary value, and emotional response. Fu et al. posited that the perceived value of tourism souvenirs
is embodied in memorial value, spiritual value, functional value, emotional value, and social value [54].
In general, although scholars offer different definitions of perceived value, in general terms they include the value assessment made
by consumers before purchase to maximize benefits or enhance their experience by weighing the benefits and costs. Based on this and
considering the factors frequently mentioned in other literature and the characteristics of AI-themed CCPs, this paper divides perceived
value into three dimensions: perceived esthetics, perceived innovation, and perceived emotions. Herein, users are measured by
allocating the perceived value to these three dimensions, which are used to measure the groups statistically after seeing the CCPs of
Yangliuqing New Year Prints generated by AI. Users then understand the value of the product and can enhance their cultural identity
and love this type of intangible cultural heritage more.
2.5. Cultural identity
Cultural identity refers to how an individual identifies with a particular cultural group and the values, beliefs, and behaviors
associated with that group. Cultural identity is shaped by a range of factors, including individual experiences, family background,
cultural traditions, and social and historical context [55]. Recently, research on cultural identity has focused increasingly on the
dynamic and multidimensional nature of this construct.
Studies have shown that cultural identity can have a profound impact on an individual’s self-concept, attitudes, and behaviors.
Individuals who have a strong cultural identity often report a greater sense of purpose, self-esteem, and related social connectedness
[56]. Cultural identity is also a dynamic and evolving construct that can change throughout an individual’s life. For example,
immigration, acculturation, and intermarriage can all impact an individual’s cultural identity. Additionally, global cultural exchanges
and the spread of technology have led to increased cultural integration, blurring the lines between traditional cultural boundaries and
often challenging traditional cultural identities [57].
Zhou’s research in 2022 indicated that the research direction of intangible cultural heritage should shift from the “identity
recognition” of a few inheritors to the “cultural identity” that mobilizes the enthusiasm of the majority. This is because the current
predicament faced by intangible cultural heritage is due to the development of contemporary society, leading to the inability of
traditional culture to maintain its vitality, and the traditional inheritance system of intangible cultural heritage cannot address this
problem effectively. In this context, cultural identity has become the key to addressing the problem [58]. Wang and Hu’s research in
2014 also showed that intangible cultural heritage passed down from agricultural civilization represents the efforts of several gen­
erations to protect that culture, as well as human creation and expression of the world. For the future, it should not be a mechanical
duplication but an active innovation and interpretation of different cultural identities, forming a culture recognized by the public, and
preserving and developing it. They believe that cultural identity is an important core mechanism for the sustainable development of
intangible cultural heritage [19].
In summary, cultural identity is a complex and multidimensional construct that plays a crucial role in shaping an individual’s sense
of self and their relationship with the world around them. Understanding cultural identity is essential for advancing our understanding
of human development and social behavior.
3. Research model and hypotheses
This study is based on the AISAS model, the theory of perceived value, and cultural identity, and aims to explore the key factors for
the sustainable development of AI-generated art and cultural products and traditional culture. We attempt to use the AISAS model to
summarize the dimensions of factors that enable the sustainable development of intangible cultural heritage through the process of
understanding the perceived value and cultural identity of AI-generated art and cultural products. Based on this discussion, a research
model is developed as shown in Fig. 2, and four hypotheses are put forward.
Hypothesis 1. The attention, interest, and active participation in the generation process of AI-generated Yangliuqing New Year Print
CCPs have a positive impact on perceived value.
5

Heliyon 9 (2023) e20477

B. Zhang et al.

Research suggests that factors, such as attention, interest, and active participation significantly influence perceived value. The
users’ attention to and interest in AI-generated Yangliuqing New Year Prints are captured, increasing their perceived value.
Furthermore, active participation in the production process allows users to customize the product, enhancing its uniqueness and
perceived value. Schiffman et al. and Lazar et al. have demonstrated that increased attention and interest in a product contribute to a
higher perception of its value [59,60]. Additionally, Aaker et al. demonstrated that consumers who actively engage in generating CCPs
tend to value the customized output more than passive observers [61]. Therefore, it can be hypothesized that the combination of
attention, interests, and active participation positively influences the perceived value of AI-generated Yangliuqing New Year Print
CCPs.
Hypothesis 2. Purchasing and sharing the experience of using AI-generated Yangliuqing New Year Print CCPs have a positive impact
on cultural identity.
Belk indicates that purchasing cultural products contributes to a personal expression and the reinforcement of cultural identity
[62]. AI-generated Yangliuqing New Year Prints serve as a fusion of traditional and contemporary cultures, allowing younger gen­
erations to engage with intangible cultural heritage in a more relatable and accessible manner [63].
Furthermore, sharing the experience of using these AI-generated cultural products has strengthened cultural identity by connecting
individuals with others who share similar cultural experiences [64]. When consumers share their experiences of using AI-generated
Yangliuqing New Year Prints with others, they foster a stronger connection to their cultural heritage and a deeper sense of cultural
identity.
In summary, it can be hypothesized that both purchasing and sharing the experience of using AI-generated Yangliuqing New Year
Print CCPs have a positive influence on cultural identity.
Hypothesis 3. Perceived value has a positive impact on cultural identity.
Previous research has shown that consumers who perceive CCPs to be of high value may feel a stronger sense of cultural identity
[62]. If users perceive the value of Yangliuqing New Year Print CCPs, they will feel a stronger connection with intangible cultural
heritage and thereby generate a cultural identity. Simultaneously, when most users perceive the same value, they form a group and
gain a sense of belonging. Therefore, we can suppose that the perceived value of AI-generated New Year Print CCPs, will positively
affect cultural identity.
Hypothesis 4. Strong cultural identity has a positive impact on the sustainable development of traditional culture.
A strong cultural identity, or a strong sense of self that is derived from one’s cultural background and experiences, can positively
impact the sustainable development of traditional culture. Previous research has shown that individuals with a strong cultural identity
are more likely to engage in behaviors that promote and preserve their cultural heritage [65]. It is reasonable to assume that in­
dividuals with a strong cultural identity would be more likely to support the continued development and preservation of these cultural
traditions. Furthermore, a consumer with a strong cultural identity may be more likely to purchase CCPs, such as the AI-generated
Yangliuqing New Year Print CCPs, to support the continued development of these traditional cultures. Additionally, a consumer
with a strong cultural identity may be more likely to share their experiences with others, promoting an awareness and understanding of
intangible cultural heritage and helping to disseminate it better. In conclusion, this hypothesis suggests that a strong cultural identity is
an important factor in the sustainable development of intangible cultural heritage and that promoting and reinforcing cultural identity
can help to ensure the continued development and preservation of these cultural traditions.

Fig. 2. Proposed research model.
6

Heliyon 9 (2023) e20477

B. Zhang et al.

4. Method
4.1. Questionnaire
After establishing the model, data were collected through a survey questionnaire to examine the relationship between variables.
The questionnaire was divided into two parts. The first part mainly aimed at collecting various types of information about the
respondent and extant views on New Year Prints and AI art. The second part constituted the main body of the questionnaire, and this
part was measured using the Likert 5-point scale. This is due to its suitability for capturing respondents’ perceptions and attitudes
toward AI-generated New Year Print CCPs, perceived value, and cultural identity. One study by Sullivan and Artino discussed the
effectiveness of Likert-type scales in measuring attitudes and opinions. The researchers argued that Likert scales provide a balanced
range of response options, allowing individuals to express their degree of agreement or disagreement with statements effectively. The
5-point scale, in particular, strikes a balance between granularity and simplicity, making it widely used in various research fields [66].
The
design
of
the
questionnaire
was
based
mainly
on
relevant
literature
studies.
Attrac­
tion–Interest–Participation–Action–Share—the questionnaire content design of these five dimensions is mainly modified and adjusted
based on the research of Cheah et al. [67], Wei et al. [68], Javed et al. [18], and Xu et al. [69]. The measurement methods used in these
articles are the AISAS model, and simultaneously, the model itself is discussed in depth. Perceived value theory is based on the research
findings of Wang [50] and Guo [70], which involved optimizing the design of CCPs through perceived value theory. The measurement
content of cultural identity theory is based on the research of Liu et al. [3], Zhou [58], and Wang et al. [63]. In their study, they
discussed the development of cultural identity theory and its practice in current society. Finally, sustainability measurement state­
ments for cultural heritage are based on Ma et al. [71], Vacchio et al. [72], and Wang et al. [19], particularly in Wang et al.’s study,
which explored the relationship between cultural identity and intangible cultural heritage, and in his view, cultural identity is
indispensable for the sustainable development of intangible cultural heritage. This provides great theoretical support for the research
Table 1
Statements of the questionnaire content.
Latent Variables
Attraction (ATT)

Interest (INT)

Participation (PAR)

Action (ACT)

Share (SHA)

Perceived Value (PV)

Cultural Identity (CI)

Sustainability of ICH
(SUS)

Statements
AI-generated art can catch my eye.
AI-generated art applied to intangible cultural heritage will grab my attention.
When I see an AI-generated New Year Prints artwork, I take some time to observe it.
Using AI art to generate different styles of New Year Prints images can attract all my attention.
I will be very interested when I see cultural and creative products generated by AI.
When I see the use of AI-generated art for New Year Prints, I will be interested in related products of New Year Prints.
The use of AI-generated art in cultural and creative products of New Year Prints makes me feel very innovative,
evoking my interest in the cultural significance of New Year Prints.
For AI products, I believe that I am willing to participate in the use of.
If it is possible to interact with Ai, I am willing to try it.
Participate in AI to generate different styles of New Year Prints images, I will be willing to learn about related New
Year Prints products.
After participating in AI to generate New Year Prints, I would like to learn more about culture and art related to New
Year Prints.
For cultural and creative products using AI to generate New Year Prints, I am willing to try to buy.
After participating in the cultural and creative products of AI-generated New Year Prints, I am willing to buy the
generated products at a suitable price.
If the same product can meet my needs, I am more willing to buy my own New Year Prints generated by AI.
After seeing the cultural and creative products of New Year Prints combined with AI, I will feel more interesting and
would like to share them with my friends.
After participating in the use of AI to generate New Year Prints art images, I will be willing to share the results I generated
on social platforms.
After purchasing and using AI-generated New Year Prints cultural and creative products, I will share my experience and
give my comments.
I believe that the New Year Prints cultural and creative products generated by AI have a very strong and attractive visual
style.
I believe that the New Year Prints cultural and creative products generated by AI are highly innovative and forwardlooking.
I believe that the New Year Prints cultural and creative products generated by AI can give me emotional resonance, and at
the same time can reflect the characteristics of youth.
I believe that the cultural and creative products of AI New Year Prints have unique connotations.
I can resonate emotionally when I use AI to generate cultural and creative products of New Year Prints.
I think AI-generated New Year Prints have effectively promoted the intangible cultural heritage.
I think that the cultural and creative products of New Year pictures generated by AI bridge the gap between traditional
intangible cultural heritage and modern technology, and enable intangible cultural heritage to develop better in the
present
I think that the combination of AI and intangible cultural heritage can bring intangible cultural heritage back to the
public view
I think the combination of AI and intangible cultural heritage can reactivate intangible cultural heritage
The integration of AI and intangible cultural heritage holds immense potential for fostering the sustainable development
of cultural heritage in contemporary times, leading to a positive feedback loop.

7

Sources
[ [67,68]]

[18]

[69]

[[50,70]]

[ [3,58,
63]]

[ [19,71,
72]]

Heliyon 9 (2023) e20477

B. Zhang et al.

of this study. The specific questionnaire statements are shown in Table 1.
Respondents provided ratings based on their personal feelings and experiences, with scores ranging from 1, strongly disagree, to 5,
strongly agree. Before completing the questionnaire, AI-generated New Year Print CCPs were shown to the respondents, and the
production process was explained so that they could clearly understand.
To ensure the validity and reliability of the questionnaire, we conducted a pilot study. Fifty participants were selected randomly for
this, and the internal consistency of the scale measurement was measured. Responses were collected through an online questionnaire.
According to Thompson’s research, at least 30 participants are sufficient for a pilot study, as a sample of 30 participants is sufficient for
testing musical instruments [73]. Additionally, other studies have suggested that a sample of 10–30 participants is sufficient for a pilot
study [ [74,75]]. Van Belle recommended that at least 12 participants be considered for a pilot study [76]. Therefore, we used a sample
of 50 participants in the pilot study, so the reliability of our questionnaire can be tested effectively, and this pilot study can be trusted.
To assess the reliability of the scales, SPSS version 24 was used in this study. The internal consistency of the structure was evaluated
using Cronbach’s alpha, which is a commonly used measure to determine the reliability of scales [77]. The relationship between the
items and their corresponding conceptual scales was analyzed by calculating the corrected item–scale correlations and examining their
impact on the value of Cronbach’s alpha. A maximum value of 1.0 for Cronbach’s alpha indicates the highest level of internal con­
sistency, while values < 0.5 are generally considered poor, and values > 0.70 are favorable for ensuring data consistency [78].
The reliability of all structures in this study has been confirmed, as indicated by the observed Cronbach’s alpha coefficients
exceeding 0.70 and all items meeting the standard for Cronbach’s alpha. Table 2 provides a summary of the Cronbach’s alpha scores for
the instrument scales.
4.2. Data collection
The population under investigation in this study is a young group aged 18–30, who have demonstrated relatively poor attention to
traditional Chinese New Year Prints and are the group with the most serious cultural disconnection in previous studies. Simulta­
neously, this age group is the main force and the group of most concern in terms of the consumption of CCPs [50]. Therefore, the data
collected in this study mainly came from the audience group ages 18–30.
Chinese New Year Prints are highly regionalized in terms of their types, which are categorized based on their places of origin.
Currently, 19 varieties of Chinese New Year Prints in China are classified according to their production locations. Moreover, as the
main influence of these prints is on the surrounding regions, their formation is strongly associated with the customs and traditions of
the surrounding areas. Therefore, the geographic scope of this study is limited to Tianjin, a city located in northern China.
The researchers deemed it appropriate to use accidental sampling method to select samples from the population of Tianjin, given its
large population. Therefore, in this study, the accidental sampling method was employed as the method of choice. This approach is the
simplest form of random sampling, where no distinction or restriction is placed on the survey population, ensuring equal chances for
each potential respondent to be selected. Its most significant advantage is that it allows for the collection of sufficient data in a
relatively short period, yields data that are representative of the general population, and allows for the generalizability of the data
collected.
The data collection for this study was conducted over four months from December 2020 to March 2023. The sample mainly
consisted of young people aged 18–30 from Tianjin. To obtain authentic data, the Wenjuanxing software was set up to limit each
respondent to only answer once, while enabling Internet Protocol Address tracking to exclude all non-Tianjin network IPs. To ensure
data reliability, two questions were set in the questionnaire to identify the target respondents, the first being the age range, and the
second being whether they had purchased CCPs. In the final data analysis, questionnaires that did not meet the age range and those
who had not previously purchased CCPs were excluded. All potential respondents were promised confidentiality and anonymity.
Herein, multiple methods were used, primarily using both online and offline methods. The online method involved the use of
instant messaging software and social media platforms such as alumni groups of universities in Tianjin, and cooperating with selfmedia accounts in Tianjin to invite users to complete the questionnaire. The increasing popularity of online social media makes it
suitable for building convenient sampling frameworks [79]. Instant messaging softwares including WeChat and Weibo have several
users, while also being a network area where several target age group samples gather. By publishing an online questionnaire on
platforms such as WeChat and Weibo using Wenjuanxing (an app for conducting surveys), the target audience can be accurately and
quickly located. Additionally, some users may share information that will appear in aggregated content posted by other users. As a
result, more users will be exposed to the same information [79].
Table 2
Cronbach’s alpha score of instrument scales.
Variable

No. of Items

Cronbach’s Alpha

Attraction (ATT)
Interest (INT)
Participation (PAR)
Action (ACT)
Share (SHA)
Perceived Value (PV)
Cultural Identity (CI)
Sustainability of ICH (SUS)

4
3
4
3
3
3
4
3

0.88
0.90
0.90
0.89
0.92
0.90
0.88
0.95

8

Heliyon 9 (2023) e20477

B. Zhang et al.

The offline questionnaire was distributed randomly in the Yangliuqing ancient town area in Tianjin and some tourist attractions.
This method can target the intended demographics precisely, making it more efficient. Before completing the questionnaire, partic­
ipants were introduced to the purpose of the survey.
In the final data analysis, the questionnaires that did not meet the age range and those who had not purchased CCPs were excluded.
Overall, 324 questionnaires were collected, and 291 questionnaires were included in the analysis after screening. The number of
questions in this study’s questionnaire was 27, and Tinsley and Tinsley [80] suggested that the sample size should be five to ten times
the number of questionnaire questions. Therefore, we believe that our sample size is sufficient to perform thorough analysis.
4.3. Data analysis
Herein, PLS analysis was performed. The PLS method is a component-based structural equation modeling technique that can be
used to construct reflective measurement models, formative measurement models, and a combination of both, making it well suited for
prediction and theoretical development. Hence, it is appropriate to use this technique to predict the impact of AI-generated New Year
Print CCPs on the sustainable development of intangible cultural heritage in this study. The author used a trial version of SmartPLS 4.0
to assess the validity and reliability of the questionnaire data and then tested the hypotheses based on a questionnaire administered to
291 participants. Additionally, this study conducted a bootstrapping procedure with 5000 repetitions to perform a statistical signif­
icance test of the study hypotheses.
5. Results
5.1. Sample characteristics
The distribution of the samples retrieved in this study is relatively uniform, as shown in Table 3. After excluding the responses from
individuals who have never purchased CCPs and excluding those from individuals who are younger than 18 years or older than 30
years, there were a total of 324 questionnaires. According to Wang’s research, the age range of 18–30 years old is the main purchasing
population and main consumer group for CCPs. Thus, this study focuses on this group [50]. Based on the level of understanding of
traditional Chinese New Year Prints (measured on a 5-point scale), the score of 2.247 shows that the transmission of the culture of
Chinese New Year Prints among the young population is weak, which is consistent with previous research, which has shown that the
public’s attention to this aspect is relatively poor today. The number of individuals who have not purchased New Year Prints accounts
for 82.8%, while 17.2% participants have bought such prints. Among those who have purchased prints, 64% participants were
accompanied by older family members, 26% participants were purchased during travel, and 10% participants were purchased for
festivals. It can be seen that the purchasing power of traditional Chinese New Year Prints is weak and the main purchasers are older
individuals. The level of awareness of AI-generated art is 3.417, which indicates that most people have heard of or seen AI-generated
art. The level of interest in AI-generated art is as high as 4.368, which reveals that the younger generation has a great interest in this
new and fresh aspect of art, which could strongly attract the attention of young people.
5.2. Measurement model
The formative and reflective models were evaluated using PLS. The reliability of the measurement model was demonstrated using
the values of Cronbach’s alpha (CA) for all items, where all values were >0.7. The convergent validity was tested using the three
Table 3
Participant characteristics (n = 291).
Measure

Items

Frequency

Percentage

Gender

Male
Female
18–24
25–30
High school and below
Junior college
Bachelor
Masters or above
1–3
4–6
>7
2.247
No
Yes
Accompanying family elders to purchase
Purchase in travel
Purchase during the festivals
3.215
4.368

119
172
187
104
30
82
128
51
142
103
46

40.9%
59.1%
64.3%
35.7%
10.3%
28.2%
44.0%
17.5%
48.8%
35.4%
15.8%

241
50
32
13
5

82.8%
17.2%
54%
32%
14%

Age
Education Level

Purchase Frequency (per year)
Level of understanding in New Year Prints
Have you purchased New Year Prints products?
Ways to purchase
Level of awareness in AI art
Level of interest in AI art

9

Heliyon 9 (2023) e20477

B. Zhang et al.

methods presented by Hair et al. [81]. A composite reliability (CR) value > 0.7 reflects good item reliability; the factor loading of each
item should be > 0.7 and be statistically significant; and average variance extracted (AVE) can be used to assess convergent validity,
and its value should be ≥ 0.5. As shown in Table 4, all values for factor loading, CR, and AVE follow the above three principles,
indicating acceptable convergent validity for the research construct. Furthermore, the discriminant validity of the measurement model
was established. Table 5 demonstrates that the diagonal element represented by the square root of AVE is greater than the value of all
correlation coefficients, indicating that all constructs have a stronger correlation with themselves than with other constructs.
5.3. Structural model and hypothesis testing
The hypotheses were evaluated after conducting 5000 bootstraps using SmartPLS. The explained variance of the inner structure can
be used to assess the ability of the structural model. As shown in Fig. 3 and Table 6, the inclusion of R-squared, standardized path
coefficients (β), and T values of inner structure supports, the validity of all hypotheses are supported. Attraction (β = 0.319; t = 5.617),
Interest (β = 0.185; t = 3.058) and Participation (β = 0.387; t = 6.109) of AI-generated Yangliuqing New Year Print CCPs all have a
direct positive effect on perceived value. Perceived value has a positive relationship with cultural identity (β = 0.308; t = 6.331). Both
Purchase and Share of AI-generated Yangliuqing New Year Print CCPs are positively related to cultural identity (Purchase: β = 0.284; t
= 8.94 and Share: β = 0.361; t = 7.487). Finally, cultural identity has a strong positive relationship with the sustainability of intangible
cultural heritage (β = 0.781; t = 25.452). According to Chin’s research [82], the results also show that all factors can be trusted
according to R-squared values (0.610–0.760).
6. Discussion and conclusion
6.1. Discussion based on the results of hypothesis testing
Herein, through the discussion and quantitative research on the CCPs of New Year Prints generated by AI, the main purpose was to
discuss whether it could engender the sustainability of intangible cultural heritage. Under the current social environment, most of the
world’s intangible cultural heritage is facing a serious crisis in inheritance and protection. Many scholars discuss how to better inherit
and protect intangible cultural heritage through various channels. For example, Tan et al. strengthened the connection between people
and places via themed tourism to help the sustainability of intangible cultural heritage [83]; Massing proposed to change the standards
for the protection of intangible cultural heritage, to include minority groups in the protection and to further focus on education and
dissemination [84]. Deng et al. used AI to build a virtual reality platform for intangible cultural heritage to protect and promote it [52].
However, they mostly proposed a solution and did not further verify the effectiveness of this solution in depth.
This article is based on the use of AI to generate pop-art-style Yangliuqing New Year Print CCPs as proposed by Zhang et al. [2]. We
Table 4
Results of descriptive statistics and statistical tests.
Construct

Indicator

loading

CR

AVE

VIF

Attraction

ATT1
ATT2
ATT3
ATT4
INT1
INT2
INT3
PAR1
PAR2
PAR3
PAR4
ACT1
ACT2
ACT3
SHA1
SHA2
SHA3
PV1
PV2
PV3
CI1
CI2
CI3
CI4
SUS1
SUS2
SUS3

0.796
0.809
0.822
0.807
0.823
0.803
0.815
0.807
0.774
0.838
0.808
0.799
0.835
0.847
0.823
0.827
0.83
0.835
0.83
0.781
0.803
0.817
0.803
0.809
0.842
0.809
0.809

0.883

0.654

0.855

0.662

0.882

0.652

0.866

0.684

0.866

0.683

0.856

0.665

0.883

0.653

0.860

0.672

1.670
1.709
1.490
1.783
1.754
1.486
1.457
1.513
1.700
1.905
1.720
1.493
1.579
1.672
1.563
1.552
1.584
1.564
1.544
1.412
1.707
1.777
1.672
1.732
1.601
1.496
1.490

Interest
Participation

Action
Share
Perceived Value
Cultural Identity

Sustainability of ICH

Notes. N = 291; CR: composite reliability; AVE: average variance extracted.
10

Heliyon 9 (2023) e20477

B. Zhang et al.

Table 5
Descriptive statistics, correlations, and Cronbach’s alpha.
INT
SHA
PAR
SUS
ATT
PV
CI
ACT

Mean

SD

CA

INT

SHA

PAR

SUS

ATT

PV

CI

ACT

3.911
3.701
3.905
4.022
3.896
3.896
3.901
3.943

0.795
0.629
0.846
0.825
0.621
0.607
0.583
0.729

0.745
0.768
0.822
0.756
0.824
0.748
0.823
0.769

0.814
0.772
0.794
0.744
0.669
0.738
0.781
0.771

0.827
0.713
0.675
0.574
0.754
0.610
0.760

0.807
0.717
0.719
0.595
0.706
0.680

0.82
0.768
0.772
0.681
0.770

0.809
0.779
0.700
0.690

0.816
0.792
0.743

0.808
0.688

0.827

Notes. N = 291; the p value of all correlations is < 0.05. SD: standard deviation; CA: Cronbach’s alpha.

Fig. 3. Results of hypotheses testing. ***p < 0.001; **p < 0.01; *p < 0.05. Numbers presented in the parentheses are the t values.
Table 6
Significance of direct effects-path coefficients.
Path

β Values

SE

T Values

P Values

Result

ACT - > CI
ATT - > PV
CI - > SUS
INT - > PV
PAR - > PV
SHA - > CI
PV - > CI

0.284
0.319
0.781
0.185
0.387
0.361
0.308

0.045
0.058
0.031
0.060
0.062
0.048
0.046

6.371
5.526
25.540
3.095
6.198
7.495
6.649

***
***
***
**
***
***
***

Supported
Supported
Supported
Supported
Supported
Supported
Supported

Notes. N = 291; **p < 0.01, ***p < 0.001; SE: Standard Error.

used the AISAS model to measure further through quantitative means to obtain more accurate data to prove its effectiveness for the
sustainability of intangible cultural heritage. Perceived value theory and cultural identity were introduced into the framework of the
whole model to assist in measurement. In the research of Wang and Guo, we can understand the importance of perceived value in CCPs
[ [50,70]]. Only when users perceive their value will they purchase and share further. Therefore, this paper contends that the di­
mensions of attraction, interest, and participation in the AISAS model have a positive impact on perceived value. The findings of this
study indicate a positive correlation between the public’s perception of the value of AI-generated CCPs such as New Year Prints and
their level of attraction, interest, and participation. This suggests that using AI in generating art incorporating intangible cultural
heritage is a viable avenue for preserving and developing these cultural assets. By creating rich artistic expressions and imaginative
presentations, intangible cultural heritage can be brought to the forefront, inspiring greater interest and involvement from the public.
For example, with the help of innovative CCPs, the Palace Museum quickly opened up the market among young user groups through
novel forms and fun and won the hearts of young people. Therefore, for traditional culture and intangible cultural heritage facing other
difficulties, the results of this study can be referred to, and the corresponding methods can be used to increase attractiveness, stimulate
user interest, let users participate in it, and let users publicize and promote it.
Additionally, the research highlights the positive impact of users‘ purchases and shares on cultural identity. In their 2021 study,
Wang et al. [63] pointed out that by establishing cultural identity through the fusion of intangible cultural heritage and brand values,
the esthetic and cultural value of the products can be reflected, while also increasing recognition of and pride in intangible cultural
11

Heliyon 9 (2023) e20477

B. Zhang et al.

heritage. By participating in the purchase and sharing of AI-generated New Year Print CCPs, individuals can strengthen their shared
cultural identity and increase their confidence in national culture.
Finally, the study proves that the perceived value of AI-generated CCPs, such as New Year Prints, is positively correlated with
cultural identity, which positively impacts the sustainable development of intangible cultural heritage. This highlights the importance
of using AI to generate CCPs that not only promote the preservation of intangible cultural heritage but also convey its cultural and
sustainable value to users. Overall, this research represents a new and exciting direction for the study of intangible cultural heritage.
This study provides a new research direction and an idea for interdisciplinary research on intangible cultural heritage. According to
the previous discussion, the current interdisciplinary research on AI and intangible heritage is mainly applied to intangible cultural
heritage through AI such as the construction of data sets [71], image restoration [85], and image style generation [ [4,85,86]].
However, whether the final result is beneficial to intangible cultural heritage, whether it can be better inherited and promoted,
whether it has a certain value, and whether it can stimulate the sustainable development of intangible cultural heritage have not been
discussed previously. Therefore, this article provides a research model for these fields. The model proposed in this article can be used to
conduct quantitative research on the application of AI to intangible cultural heritage, to evaluate the value of this project. This is
critical to the interdisciplinary research of AI and intangible cultural heritage, and it also underpins the significance of this article.
6.2. Conclusion and implications
This study used the AISAS model to test the sustainable impact of AI-generated New Year Print CCPs on intangible cultural heritage,
and the final result is acceptable. First of all, from previous research, we can understand that factors such as social change and eco­
nomic development have caused the traditional culture to face many difficulties, and it is difficult to rejuvenate in contemporary
society. Based on this, researchers try to stimulate intangible cultural heritage through AI-generated art. Second, the five character­
istics of the AISAS model are associated with perceived value and cultural identity to measure the impact on sustainable cultural
development. The results show that the attractiveness, interest, and participation of AI-generated New Year Print CCPs have a sig­
nificant positive relationship with users’ perceived value. Users’ purchase and sharing are positively correlated with cultural identity.
Perceived value is positively related to cultural sustainable development to cultural identity. In conclusion, this research provides
evidence that using AI to address the challenges faced by intangible cultural heritage is feasible and could serve as a reference for the
sustainable development of other examples of intangible cultural heritage facing similar difficulties.
In addition, this study provides a theoretical contribution. First, this study expands the AISAS model and applies it to the field of
CCPs of intangible cultural heritage. Although the AISAS model originated in the field of advertising marketing, its essence is a
behavioral model [46]. The AISAS model offers unique advantages for the sustainable development of intangible cultural heritage, as
outlined below: 1. Comprehensive Coverage: The AISAS model possesses the unique advantage of comprehensively covering the entire
process of consumer purchase. As AI-generated New Year Print CCPs essentially function as commodities, users need to engage in
purchase behavior to foster cultural identity and contribute to the sustainable development of intangible cultural heritage. The AISAS
model recognizes the significance of user purchase behavior in achieving these goals. 2. Comprehensive Content Dimension: Another
distinct advantage of the AISAS model is its comprehensive content dimension. This model enables the measurement of various factors
associated with the use of AI-generated New Year Print CCPs, encompassing dimensions such as product, personal, and social factors.
By considering these multiple dimensions, the AISAS model provides a holistic understanding of the factors influencing the use and
impact of these products. 3. Exploratory Nature: The AISAS model is particularly suitable for exploring the influencing factors of
cultural sustainable development, which have not yet been studied extensively using appropriate models. The exploratory nature of
this approach allows researchers to delve into the unique aspects of cultural sustainable development, shedding light on previously
unexplored factors and relationships. By employing the AISAS model, researchers can advance their understanding of how cultural
sustainability can be promoted effectively. In summary, the AISAS model offers unique advantages for the sustainable development of
intangible cultural heritage. Its comprehensive coverage, comprehensive content dimension, and exploratory nature contribute to a
more comprehensive understanding of the factors that influence the use and impact of AI-generated New Year Print CCPs.
Second, this study applies cultural identity to sustainable development research of intangible cultural heritage. Recently, research
on cultural identity has focused more on the field of crosscultural research and relatively less on the study of intangible cultural
heritage. Due to the common characteristics of intangible cultural heritage and cultural identity, it has developed dynamically over
time. Therefore, intangible cultural heritage is a culture that is passed down by people for a long time and can confirm and maintain
cultural identity. Simultaneously, it is an artistic culture or a cultured way of life that we are constantly revitalizing and actively
inheriting to show our national cultural identity. By examining the inheritance and development of intangible cultural heritage
through the lens of cultural identity, the study aims to ensure its sustainability. The essence is not only to make intangible cultural
heritage represent traditional values but also to be reinvigorated today as the reproduction of the value of the current era, and continue
to gain value in the future.
Finally, this research provides a new perspective on the innovation of other aspects of intangible cultural heritage. Recently, the
content of other nonmaterial cultural innovations is more that different designers innovate according to their content or symbols.
Relatively speaking, it is narrow, personal, and unstable, and it is difficult for the public to participate in and gain new experiences.
This is a drawback; however, AI models are advantageous in terms of stability, interactivity, and innovation. Furthermore, AI is an
attention-grabbing topic at present, from AlphaGo to AI-generated art, to ChatGPT, these topics have hit the headlines of various media
and attracted the attention of a large number of young people. Therefore, combining intangible cultural heritage with AI is also
attractive to users in terms of topic. In addition, AI has already participated in all aspects of human life, and it is also one of the
indispensable directions for future development.
12

Heliyon 9 (2023) e20477

B. Zhang et al.

In conclusion, this research is a novel approach. First, a new structure is proposed based on the AISAS model to measure the impact
of AI products on the sustainability of intangible cultural heritage. The final result is seen to be positive and effective. It can be used to
prove the value of interdisciplinary research products of AI and intangible cultural heritage and provide a reference and theoretical
support for other research in this field. Second, it is also a new research field in intangible cultural heritage. It confirms the possibility
of AI innovation in the field of intangible cultural heritage, which is more in line with the social environment of the current era. It
proves that the innovative application of AI contributes to the protection, revival, and sustainable value creation of intangible cultural
heritage.
6.3. Limitations and future research
This study also has certain limitations. Due to limited time and resources, the sample size is small and the sample region is limited.
Currently, 19 types of New Year Prints have been identified in China. Research on New Year Prints in different regions and samples
from different regions may present different characteristics. In the future, it will be possible to integrate New Year Print products from
different regions for comparison and study the cultural background and sample characteristics of different regions to explore their
differences. Simultaneously, the scope of the research and the sample selection can be extended to areas with no New Year Print
production, and we can observe the different results produced by samples in different areas.
This method can also improve the credibility of the overall research. In addition, previous studies have proved that the theories of
perceived value and cultural identity are undoubtedly suitable for the study of CCPs of intangible cultural heritage [ [19,50,58,87]]. In
this study, the content of perceived value measurement is limited, and whether it is possible to predict the sustainable development of
intangible cultural heritage through theories other than that of cultural identity is an additional issue that needs to be refined in further
research. We can consider adding more detailed perceived value theory measurements and introducing other theories to test them
further.
In addition, the generalizability and external validity of the model may have some limitations, the reason being that the findings of
this study may be limited in their generalizability due to factors such as the specific context and sample used. The study focuses on AIgenerated New Year Print CCPs, and the results may not be directly applicable to other forms of intangible cultural heritage combined
with AI. In addition, the study’s findings may be influenced by the specific cultural, social, and economic contexts, in which the
research was conducted. The results may not be directly transferable to other cultural contexts or regions. Replication studies in
different settings would be beneficial to enhance the external validity of the findings.
Meanwhile, in future research, the researchers will continue to explore the combination of AI-generated art and intangible cultural
heritage and investigate more possibilities for the sustainable development of intangible cultural heritage. Examples of this are using
AI to promote intangible cultural heritage education, create a virtual reality platform, and assist in the analysis of cultural identity
expressions, cultural emotions, and cultural dynamics in intangible cultural heritage. Simultaneously, we must always pay attention to
copyright issues and ethical issues related to AI in the follow-up research, and explore more possibilities for the sustainable devel­
opment of intangible cultural heritage.
Funding
This research was funded by Inner Mongolia University of Science & Technology, China crosswise tasks Technical report on pilot
run by oxygen enriched Inclined side-blown (Grant No. 205/0904051908).
Author contribution statement
Bolun Zhang: Conceived and designed the experiments; Performed the experiments; Analyzed and interpreted the data; Contrib­
uted reagents, materials, analysis tools or data; Wrote the paper.
Peng Cheng: Analyzed and interpreted the data.
Lujie Deng: Analyzed and interpreted the data.
Nurul Hanim Romainoor: Conceived and designed the experiments.
Jianhong Han: Contributed reagents, materials, analysis tools or data.
Guoshuai Luo: Contributed reagents, materials, analysis tools or data.
Tianbo Gao: Performed the experiments.
Data availability statement
Data will be made available on request.
Ethics approval
All procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional
research committee and with the 1964 Helsinki Declaration and its later amendments or comparable ethical standards. The ethics
approval number is 2023–29, ethics committee is Medical Ethics Committee of Tianjin Anding Hospital (Tianjin Mental Health
Centre).
13

Heliyon 9 (2023) e20477

B. Zhang et al.

Informed consent
Informed consent was obtained from all individual participants included in the study. All participants gave informed written
consent. The institution’s ethics committee also gave permission to conduct the research.
Declaration of competing interest
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to
influence the work reported in this paper.
Acknowledgements
We thank all those who assisted us in completing the paper.
’This item belongs to the item group IG000079’.
Appendix A. Supplementary data
Supplementary data to this article can be found online at https://doi.org/10.1016/j.heliyon.2023.e20477.


A B S T R A C T

Keywords:
AI art
Haiku poetry
Aesthetic evaluation
Creativity
Human-in-the-loop

With the development of technology, the quality of AI-generated text has improved. This is relevant in the AI art
field, where AI generates literature or poetry that is appreciated. This study compared human-made and AIgenerated haiku poetry, which is composed with 17 syllables and the world’s shortest and clearest rules, to
examine aesthetic evaluations of AI art and people’s beliefs about it. AI-generated haiku were divided into those
with and without human intervention. Two tasks were completed by 385 participants. The first involved eval­
uating human-made and AI-generated haiku on 21 items, such as beauty. The second involved determining
whether the haiku were human-made or AI-generated. The results showed that the beauty rating of the AIgenerated haiku with the human intervention was the highest, and those of the human-made and AIgenerated haiku without human intervention were equal. Furthermore, participants could not distinguish be­
tween human-made and AI-generated haiku. These results suggest that human–AI collaboration has better
creativity in haiku production. Moreover, a negative correlation was found between discrimination performance
and beauty rating in AI-generated haiku, suggesting that high-quality AI-generated work is believed to be humanmade. This study indicates the potential of human–AI collaboration in haiku and the underestimation of AI art
due to algorithm aversion.

1. Introduction

intellectual activities performed by humans. Studies on painting show
consistent results that the discrimination between human-made and
AI-generated paintings is difficult (Chamberlain et al., 2018; Elgammal
et al., 2017; Gangadharbatla, 2022; Ragot, Martin, & Cojean, 2020;
Ueda et al., 2021). Moreover, Chamberlain et al. (2018) found that the
discrimination was also difficult when the participants were art majors.
Interestingly, even if they cannot distinguish the artists of paintings,
when asked to rate their preference and beauty, the scores differed
(Ragot et al., 2020; Ueda et al., 2021, but it was not found in Cham­
berlain et al., 2018). Moreover, some studies showed that the preference
in art is not influenced by the actual authorship but rather whom a
person believes the author to be (i.e., attributional authorship, Cham­
berlain et al., 2018; Ragot et al., 2020, but not in Hong & Curran, 2019).
Given that AI can now generate literature and poetry, in recent years,
it is worth extending the discussion to the linguistic arts. Studies
comparing human-made and AI-generated literature and poetry has
been examined since the late 2010s (Gunser et al., 2022; Hopkins &
Kiela, 2017; Köbis & Mossink, 2021; Lau et al., 2018; Lc, 2021; Oliveira,

Artificial Intelligence (AI) art is flourishing. The main focus of AI art
has been on visual arts such as painting (Elgammal et al., 2017; Gatys
et al., 2016; Karayev et al., 2013; Li & Wand, 2016, see Cetinic & She,
2022 for review). Recently, the dramatic improvement in natural lan­
guage processing and generation technology has enabled AI to create
literature and poetry that closely resemble those created by humans.
This kind of AI art has attracted the attention of researchers in the fields
of computer science and robotics on the generation side, and those from
psychology and philosophy, where the debate centers on understanding
beauty and creativity (c.f., Daniele & Song, 2019).
Previous studies evaluating AI art have compared algorithmic and
human-made art, asking participants to discriminate the artist (human
vs. AI) and to evaluate aesthetic scores (e.g., Chamberlain et al., 2018;
Gangadharbatla, 2022; Ueda et al., 2021). Artist discrimination applies
the Turing test to AI art, which verifies that the capabilities of a machine
or artificial intelligence are equal to, or indistinguishable from, the

Abbreviations: HOTL, Human-out-of-the-loop; HITL, Human-in-the-loop; LSTM, Long short-term memory; IRI, Interpersonal Reactivity Index.
* Corresponding author. Institute for the Future of Human Society, Kyoto University, Yoshida Shimoadachi-cho 46, Sakyo, Kyoto, 606-8501, Japan.
E-mail address: ueda.yoshiyuki.3e@kyoto-u.jp (Y. Ueda).
https://doi.org/10.1016/j.chb.2022.107502
Received 25 May 2022; Received in revised form 6 September 2022; Accepted 24 September 2022
Available online 4 October 2022
0747-5632/© 2022 Published by Elsevier Ltd.

J. Hitsuwari et al.

Computers in Human Behavior 139 (2023) 107502

2009; Schwartz, 2015; see Table 1 for the summary). Oscar Schwartz
first demonstrated whether it was possible to distinguish between the
two (Schwartz, 2015). When his “Bot or Not” website asked viewers to
compare human-made and algorithmically generated poems, 65% of
algorithmically generated poems deceived the author (i.e., poems
written by AI seemed to have been written by humans). Later, Lau et al.
(2018) generated 14-line sonnets by Deep-speare consisting of language,
rhythm, and rhyme models, and asked laypersons and an expert of En­
glish literature to evaluate them. Although the laypeople could not
distinguish between AI-generated and human-made work, the expert
judged the former inferior to the latter regarding readability and evoked
emotions. Note that in the study by Lau et al. (2018), there was only one
expert, and thus, it was unclear whether other experts would also be able
to distinguish between them or whether this differentiation was unique
to this particular expert.
In these studies, AI-generated poems were ultimately selected by
humans; however, in order to make human involvement in AI poems
more rigorous, Köbis and Mossink (2021) distinguished AI poems into
human-out-of-the-loop (HOTL) and human-in-the-loop (HITL), where
the former did not require human intervention when selecting items
from AI-generated poems, while the latter required stimuli to be
generated by AI and selected by humans. The results showed that AI
poems with HOTL could be distinguished from human-made ones, but
those with HITL were not. In other words, the findings revealed that
human involvement could increase the quality of AI poetry, making it
equivalent to that of humans. More recently, Gunser et al. (2022)
replicated Köbis and Mossink (2021) using more materials and found
that participants could not distinguish between human and AI poems
with HITL. At the same time, human poems were found to be superior in
multiple evaluations, such as inspiring and well-written.
The present study attempts to extend the previous findings to the
world’s shortest poem, the haiku. Haiku, which originated in Japan, has
clear rules, such as a fixed form of 5-7-5 syllables and the inclusion of
seasonal words called “kigo” (Iida, 2008). These rules of haiku make it
different from other forms of poetry. The first aspect is ambiguity; since
the number of characters in haiku is small, the expression is ambiguous,
and readers have to supplement and interpret the scene from the little
information they have (Hitsuwari & Nomura, 2022a; 2022c). Therefore,
even though AI generates ambiguous haiku, readers will attempt to
interpret them according to the scenes they can imagine. The second is
that the impression of haiku depends on one or two mental images
evoked (Blasko & Merski, 1998; Hitsuwari & Nomura, 2022b). Other
types of poetry are generally longer than haiku and often translate to
various images depending on different scenes, which eliminates the
problem of having consistency and a sense of narrative between scenes.
Despite the difficulty of composing haiku with a small number of
characters, AI has attempted this task (Kawamura et al., 2021;
Yokoyama et al., 2019).1 These characteristics make AI-generated haiku
highly evaluated and difficult to distinguish from human-generated
ones.
In this study, we further examined the factors that contributed to the
evaluation of beauty in human-made and AI-generated haiku. Previous
studies evaluated poems with some items (e.g., readability and
emotional evocation in Hopkins & Kiela, 2017, and well-written,
inspiring, fascinating, interesting, and aesthetic in Gunser et al., 2022;
details in Table 1). Although recent studies on neuroaesthetics suggest
that aesthetic is composed of sensory–motor, emotional–valuation, and
meaning–knowledge systems (Chatterjee & Vartanian, 2014), the
number of items used in previous studies was too small to examine the

factors that evoke the feeling of beauty in haiku. To determine the
general characteristics of the beauty experience across object kinds,
Brielmann et al. (2021) proposed eleven dimensions that have been
considered by prominent philosophers of aesthetics (pleasure, wishing
to continue the experience, feeling alive, feeling that the experience is
beautiful to everyone, number of felt connections to the experience,
longing, feeling free of desire, mind wandering, surprise, wanting to
understand the experience more, and feeling that the experience tells a
story) and eight dimensions conveyed by psychologists (complexity,
arousal or excitement, learning from the experience, wanting to un­
derstand, harmony in variety, meaningfulness, exceeding one’s expec­
tation, and interest).2 In accordance with Brielmann et al. (2021), these
dimensions were used to identify factors that delineate the experience of
beauty in human-made and AI-generated haiku. In addition, we
exploratory examined feelings of awe and nostalgia, which have been
involved in a previous haiku study as well (Hitsuwari & Nomura,
2022c).
A problematic psychological characteristic in the evaluation of AI art
is algorithm aversion, the belief that beautiful things are made by
humans, not AI (Burton et al., 2020). This is also associated with a
preference for AI poetry (Köbis & Mossink, 2021). Given that Okanda
et al. (2019) showed that animism and empathy traits influenced the
evaluation of moral aspects of robots, individual differences in these
traits may influence the impressions of robots and AI, and could be
related to the discrimination between human-made and AI-generated
haiku.
2. Hypotheses
This study aimed to examine how haiku, as a literary art form created
by AI, humans, and a collaboration between them, affects beauty scores
and discrimination of authors. Our main concerns were fourfold: while
the first two focused on the evaluation of the work, the latter two
focused more on the attributional authorship.
First, we compared the beauty scores of human-made, AI-generated
without human intervention (i.e., HOTL), and AI-generated with human
intervention (i.e., HITL) haiku. Since human involvement likely in­
creases the quality of AI poetry (e.g., Köbis & Mossink, 2021), HITL
haiku would be more evaluated than HOTL. Moreover, AI-generated
haiku may be evaluated the same as, or even better than,
human-made haiku, since people can sufficiently engage their imagi­
nation, even with little information.
Second, we examined the factors that can explain the beauty of
human-made and AI-generated (HOTL/HITL) haiku. Although factors
affecting the aesthetic perception of human-made and AI-generated art
are diverse, no study of AI poetry has addressed using a copious number
of evaluation items. Following the previous study (Brielmann et al.,
2021), we expected that aesthetic evaluations are associated with both
philosophical and psychological perspectives.
Third, we examine whether participants can distinguish between
human-made and AI-generated (HOTL/HITL) haiku. Referring to the
previous study using typical poems (Köbis & Mossink, 2021), we expect
that participants would be able to distinguish between HOTL and human
haiku but not between HITL and human haiku. However, given that
haiku have less information and more reliance on the reader’s imagi­
nation than other poems, even HOTL haiku may not be distinguished
from human haiku.
Finally, we examine which factors, especially participants’ back­
grounds (education and experience of haiku) and personality traits (i.e.,
animism and empathy, which are associated with attitudes toward ro­
bots and AI), explain the discrimination accuracy of authors. Based on
the finding of Chamberlain et al. (2018), which stated that author

1

In a TV show demonstration (not an empirical study) that evaluated the
quality of five human-made and AI-generated haiku each, the highest rated
haiku was the AI-generated one although the results of the one-on-one com­
parisons showed that human-made haiku had a higher win rate than AIgenerated ones.

2
For a detailed explanation of these dimensions, please see the original text
and references in Brielmann et al. (2021).

2

J. Hitsuwari et al.

Computers in Human Behavior 139 (2023) 107502

Table 1
Literature review comparing human-made and AI-generated poetry.
ID

Study

HITL
or
HOTL

AI
algorithm

Human
poems

Number of
evaluators

Number of
poems

Rating

Discriminating

Limitations

Notes

1

Schwartz
(2015)

HITL

Various
algorithms
(e.g.,
RACTER &
RKCP)

Professional
poets (e.g.,
William Blake
& Frank
O’Hara)

Thousands of
people

NA

NA

- 65% of them
could not
identify the
author

2

Hopkins and
Kiela (2017)

HITL

LSTM

Classic poets
(e.g.,
Shakespeare)

70

Eight
manmade
and two AIgenerated
poems

- 48.6% of
human poems
were falsely
attributed to AI
and 53.8% of AI
poems were
falsely
attributed to
humans

- First attempt
to examine
whether
human and AI
poetry can be
discriminated

3

Crowdworkers
in Lau et al.
(2018)

HOTL

Deepspeare

Professional
poets (e.g.,
Shakespeare)

1000

50
manmade
and 180 AIgenerated
quatrains

- Human poems
were rated
slightly higher
quality (in total
score of form,
readability,
and emotional
evocation)
than AIgenerated
poems
- The poems
judged to be
the most
human and
aesthetic were
AI-generated
NA

- Not empirical
study (without
control of
experimental
conditions or
participants)
- Small sample
size of poems
and
participants

- No statistical
tests were
performed

- Each
participant
rated a few
poems

4

Expert in Lau
et al. (2018)

HOTL

Deepspeare

Professional
poets (e.g.,
Shakespeare)

1

30
manmade
and 90 AIgenerated
quatrains

- Accuracy was
53.2%,
indicating it was
hard to
distinguish
between human
and AI poems
NA

- Only one
evaluator

- Evaluator was
an expert in
English
literature

5

Lc (2021)

HITL

GPT-2

Author made

25

5 manmade
and 5 AIgenerated
poems

- Accuracy was
61.6% for
human-made
poems and
56.0% for AIgenerated
poems, but there
was no
significant
difference
between them

- Small sample
size of poems
and
participants

- the AI could
reproduce the
nuance of the
original text

6

Study 1 in
Köbis and
Mossink (2021)

HITL

GPT-2

Novice made

192 (About half
of them
participated in
the
discrimination
task)

20
manmade
and ten AIgenerated
poems

- 50.2% of all
answers
correctly
discriminated
the author

- Only HITL

7

Study 2 in
Köbis and
Mossink (2021)

HITL
&
HOTL

GPT-2

Classic poets
(Maya
Angelou &
Hermann
Hesse)

384 (185
participated in
the
discrimination
task)

Ten
manmade,
ten AIgenerated
with HITL,
and ten AIgenerated
with HOTL
poems

- 65.5% in the
HOTL poems
and 53.7% in
the HITL poems
could be
discriminated

- Little variety
in humanmade poems

- AI-generated
poems was
better in meter
and rhyme
than humanmade.
- Human-made
poems were
better in
emotion and
readability
than AIgenerated
- Evaluation
regarding
structure was
not
significantly
different, but
expression was
rated higher
for humanmade than AIgenerated
poems
- Human-made
poems were
rated higher
than AIgenerated
poems with a
57.0%
probability.
- Participants
chose the
better of the
human-made
and AIgenerated
poems, and
human-made
poetry was

- First
experiment
comparing
HOTL and
HITL

(continued on next page)

3

J. Hitsuwari et al.

Computers in Human Behavior 139 (2023) 107502

Table 1 (continued )
ID

Study

HITL
or
HOTL

AI
algorithm

Human
poems

Number of
evaluators

Number of
poems

8

Study 1 in
Gunser et al.
(2022)

HITL

GPT-2

Experts (
Gunser et al.,
2022)

120

18
manmade
and 18 AIgenerated
with HITL
poems

9

Study 2 in
Gunser et al.
(2022)

HITL

GPT-2

Classic poets
(Franz Kafka,
Friedrich
Hölderlin,
Robert
Gernhardt, &
Paul Celan)

302

18
manmade
and 18 AIgenerated
with HITL
poems

discrimination accuracy did not change depending on whether the
participant was an art major or not, it was expected that the participants’
backgrounds would not significantly affect the accuracy of discrimina­
tion between human-made and AI-generated ones. Moreover, it was
expected that animism and empathy, which decrease algorithmic aver­
sion, would work to the advantage of author discrimination, since
algorithmic aversion instantly attributes a work of beauty to a human
authorship.

Rating

higher
evaluated in
64.9%than AIgenerated.
(62.9% for
HITL and
66.9% for
HOTL)
- Human-made
poems were
rated higher in
5 evaluations
(well-written,
inspiring,
fascinating,
interesting,
and aesthetic)
than AIgenerated
- Human-made
poems were
rated higher in
five
evaluations
(well-written,
inspiring,
fascinating,
interesting,
and aesthetic)
than AIgenerated

Discriminating

Limitations

Notes

- 40.3% of
human-made
poems were
falsely
attributed to AI,
and 42.0% of AIgenerated
poems were
falsely
attributed to
human-made
- 33.5% of
human-made
poems were
falsely
attributed to AI,
and 40.2% of AIgenerated
poems were
falsely
attributed to
human-made

- Only HITL

- Expert poets
and GPT-2
created
continuations
of the classical
poems

- Human-made
poems could
be easily
detected due to
their historical
language
usage and
sublime style

3.2. Materials
3.2.1. Haiku stimulus
To disperse the seasons and genres of haiku, we selected ten seasonal
words that must be included in haiku. Forty human-made haiku (four for
each of the ten seasonal words) were selected from the Saijiki, which
contains several haiku poems created by professionals for each seasonal
word. All of haiku in the Saijiki are highly regarded by the professionals.
In a preliminary survey, eight laypersons (not included in the actual pool
of participants) confirmed that they had never seen these haikus before.
For AI-generated haiku, we used the haiku generation system based on
the Long Short-Term Memory (LSTM) algorithm developed by the
Harmonic System Engineering Lab at Hokkaido University, Japan
(Kawamura et al., 2021; Yokoyama et al., 2019). The system first gen­
erates a set of candidate haiku sentences using a language model trained
on haiku data by LSTM. The system then applies morphological analysis
to the generated sentences and selects those that match the form of
seasonal fixed form haiku. The similarity between the generated sen­
tences and the haiku in the training data is calculated and sentences that
are more similar than a certain threshold are removed. Depending on the
frequency of seasonal words, the number of generated haiku varies. For
each of the ten seasonal words, the system generated 36,442 to 624,130
haikus. In the algorithm, the AI itself calculated the degree of their
validity as Japanese language and finally, generated the top 500 haiku
as AI-generated haiku.
From the AI-generated haiku, we randomly selected 20 (two for each
of the ten seasonal words) and designated them as HOTL haiku. Another
20 haiku (two for each of the ten seasonal words) that were highly rated
for their beauty by three amateur/novice haiku artists were designated
HITL haiku.
The 80 haiku were then randomly divided into two stimulus lists of
40 haiku, each consisting of 20 human-made, ten HOTL, and ten HITL
haiku per list.

3. Methods
This study was approved by the institutional review board of the
Psychological Science Unit at Kyoto University (2-P-21). All data, ma­
terials, and scripts are available online (https://osf.io/s6wny/).
3.1. Participants
Assuming a small effect size, 322 subjects would be needed to
compare the three ways of the generated haiku (i.e., human-made, HITL
vs. HOTL). Therefore, we conducted a web-based experiment to recruit
400 Japanese participants through CrowdWorks (https://crowdworks.
jp). We excluded 15 participants who did not respond appropriately to
an attention check which involved asking for a specific answer in the
questionnaire. Therefore, data from 385 participants (191 male and 194
female participants, Mage = 40.9, SD = 10.1) were included in the final
analysis. All participants were informed of the study’s purpose, meth­
odology, risks, duration of the experiment, the voluntary nature of
participation, their right to withdraw, and how the participants infor­
mation was to be handled. Furthermore, written informed consent was
obtained before they participated in the experiment. They were paid 500
JPY for their participation.

4

J. Hitsuwari et al.

Computers in Human Behavior 139 (2023) 107502

or AI. After judging all of the haiku, they chose from the following 12
items that provided clues for their decisions: the rhythm of words,
consistency, regularity, repeatability, complexity, depth, abstraction,
intentionality, uniqueness, expression, nuance, and others. Finally, they
were asked to provide an open-ended explanation of their decision of
choosing the haikus as human or AI-generated.
Trait block. Here, in addition to age, sex, educational background,
and nationality, the participants were asked to answer the five types of
trait questionnaires. Educational backgrounds were categorized as: (1)
junior high school, (2) high school, (3) junior college/technical college,
(4) university, and (5) graduate school.

3.2.2. Questionnaires to investigate personality traits
To examine the effect of personality traits on judgments, we
measured personality traits using five types of questionnaires.
First, the Interpersonal Reactivity Index (IRI) (Davis, 1980; Himichi
et al., 2017) was used to measure trait empathy. The scale consists of
four subscales: empathic concern, personal distress, perspective-taking,
and fantasy, with a five-point Likert scale.
Second and third, the Adult Animism Scale (Ikeuchi, 2010) and the
Aliveness Animism Scale (Okanda et al., 2019) were used to measure
animism traits. The former is an 11-item scale with a five-point Likert
scale consisting of three subscales: the deification of natural objects, the
alterity of the owner, and anthropomorphism of possessions. This scale
reflects the tendency to perceive divinity and the existence of life in
inanimate objects, even though they do not possess life. The latter scale
reflects the tendency to think that inanimate objects are alive and asks
the participants to select all the objects that they think are alive from
eight items (lit candle, telephone, clock, doll, teddy bear, banana peel,
cloud, and mud) and four plants (tree, flower, grass, and vegetable).
Fourth, the following questions were used to measure knowledge of
and interest in haiku and art: haiku experience (“I just learned about it in
elementary school or junior high school,” “I have had few opportunities
to experience it as an adult,” “I have had opportunities to experience it as
an adult,” “I have had many opportunities to experience it as an adult,”
“I have had opportunities to experience it every day as an adult.”),
frequency of museum visits (“more than twice a month,” “about once a
month,” “a few times a year,” “about once a year,” “I rarely go,” “I have
never been”), experience in creative jobs (“no such experience,” “a lit­
tle,” “a lot,” “quite a lot”), and interest in the arts (“not at all,” “very
little,” “a little,” “a lot,” “quite a lot”).
Fifth, in addition to the above, as exploratory research, a four-item
scale developed by Sugimori and Kusumi (2014) was used to measure
the frequency of déjà vu experiences and sensitivity to similarity. Two
items measured the frequency of the déjà vu experience using a
seven-point Likert scale (1: did not have the experience in the past year
to 7: every day), and the other two items measured the degree to which
the déjà vu experience applied to them using a five-point Likert scale (1:
definitely does not apply to 5: definitely applies to me).

3.4. Data analysis
For the first purpose, we averaged each person’s beauty score for
each group and compared them with one-factor ANOVA (human haiku,
HOTL haiku, vs. HITL haiku) using the “anovakun” function (ver. 4.8.6;
Iseki, 2021) in R (ver. 4.1.0). Furthermore, we conducted the same
analysis on the 20 ratings other than beauty for exploratory analysis.
Second, we examined whether the 20 ratings other than beauty could
explain the beauty score with a linear mixed model using the lmer
package (Bates et al., 2015). A total of 15,400 observations, with 385
individuals and 40 haikus, met the sample size of the literature (Arend &
Schäfer, 2019) on the testing power of hierarchical data and repeated
measures data (called multilevel models). The dependent variable was
the beauty score, the independent variables were 20 ratings other than
beauty and haiku conditions, and educational background was the
control variable. The participants, haiku, and task order (whether the
rating block or the discriminating block was first) were put into random
effects. The independent variables were centered within a cluster. The
educational background was included as a control variable because
prior knowledge can significantly influence the evaluation of haiku
(Sato, 2007).
Third, to examine whether participants could distinguish between
human and AI haiku, we conducted a t-test to see if the hit rate signif­
icantly differed from the chance level (0.5).
Finally, to examine whether individual traits could explain the
discrimination accuracy, we analyzed a generalized linear mixed model
(logistic analysis) with hit or not as the dependent variable, individual
traits as the independent variable, and participants and haiku as random
effects. The independent variables were centered using the grand mean.

3.3. Procedure
The participants accessed the experiment page available on the
Internet. They first read the informed consent information, and started
the experiment upon agreeing to it. The experiment consisted of three
blocks: the rating block to evaluate the haiku, the discriminating block to
judge whether the creator of the haiku was human or not, and the trait
block to measure the personality traits of the participants. Following
Chamberlain et al. (2018), the influence of author attribution (prior
knowledge about whether the work produced by AI was included in the
list) was controlled with half the participants completing the rating block
first, followed by the discriminating block. The other half completed the
discriminating block first, followed by the rating block. For both sets of
participants, the trait block was completed at the end of the experiment.
Furthermore, both sets of participants were presented with two different
haiku lists (including 40 haikus, each), to investigate the consistency of
the results in both lists.
Rating block. Here, human-made and AI-generated haiku were
presented individually. Participants were asked to evaluate them using
the following 21 dimensions on a 7-point Likert scale: psychological
factors related to aesthetic evaluations such as beauty, valence, arousal,
awe, empathy, vividness, passion, novelty, nostalgia, and déjà vu, and
certain philosophical factors including pleasure, wish to continue the
experience, alive, universality, number of connections, longing, free of
desire, mind wandering, surprise, want to understand, and tells story
(see Brielmann et al., 2021 for the details).
Discriminating block. Here, the haiku were presented and the
participants were asked to judge whether each was created by humans

4. Results
4.1. Beauty scores for human-made and AI-generated haiku
Table 2 shows the descriptive statistics for each item of the haiku
evaluations. We compared the beauty scores of the human, HOTL, and
HITL conditions (i.e., the first row of Table 2). The result showed that the
main effect of condition was F(384, 2) = 212.41, p = .00, η2 = 0.06.
Following multiple comparisons showed that HITL had the highest
scores. There was no difference in the scores between the human and
HITL conditions (see Fig. 1). Table 2 also shows the results of explor­
atory analyses on other 20 ratings. These results suggest that AIgenerated haiku were more highly evaluated than the human-made
ones when humans intervened in the AI outputs (i.e., HITL).
4.2. Explanatory factors for beauty of human-made and AI-generated
haiku
Next, we determined the most explanatory factors for the aesthetic
evaluation by examining whether the 20 factors concerning the beauty
evaluation, task order, haiku list, and condition could explain the beauty
of haiku using a linear mixed model (Table 3). All factors related to the
beauty evaluation had contributions to the beauty of haiku, except alive
(b = − 0.01, SE = 0.01, t = − 0.56, p = .57), mind wandering (b = 0.01,
5

J. Hitsuwari et al.

Computers in Human Behavior 139 (2023) 107502

Table 2
Descriptive statistics for rating items of Haiku evaluation.
Mean (SD)
Beauty
Déjà vu
Image
Valence
Arousal
Awe
Nostalgia
Novelty
Empathy
Intention
Joy
Continue
Alive
Universality
Longing
Free desire
Mind wandering
Connection
Surprise
Understand
Tells story

Human

HOTL

HITL

4.15
(.75)
3.30
(1.06)
4.60
(.68)
4.11
(.58)
3.96
(.69)
3.39
(.99)
4.14
(.89)
3.63
(.70)
3.81
(.87)
4.48
(.76)
3.40
(.83)
3.80
(1.00)
3.58
(.99)
3.82
(.77)
3.58
(.97)
3.34
(.92)
3.20
(1.00)
3.34
(1.02)
3.06
(1.04)
4.10
(.97)
4.44
(.83)

4.14
(.78)
3.17
(1.05)
3.99
(.79)
4.00
(.60)
3.82
(.74)
3.36
(1.02)
4.08
(.96)
3.57
(.73)
3.53
(.92)
4.35
(.81)
3.31
(.87)
3.71
(1.05)
3.44
(1.02)
3.79
(.80)
3.49
(1.04)
3.43
(.95)
3.20
(1.02)
3.31
(1.05)
2.95
(1.04)
4.15
(1.03)
4.41
(.86)

4.56
(.74)
3.50
(1.09)
4.63
(.75)
4.28
(.64)
4.08
(.74)
3.68
(1.03)
4.28
(.90)
3.64
(.77)
3.97
(.89)
4.59
(.78)
3.57
(.87)
4.01
(1.00)
3.73
(1.02)
4.17
(.77)
3.71
(.99)
3.53
(.98)
3.39
(1.02)
3.47
(1.03)
3.07
(1.06)
4.27
(1.00)
4.60
(.84)

F value

p value

η^2

Multiple comparison

212.41

.00

.06

Human = HOTL < HITL

106.63

.00

.02

HOTL < human < HITL

302.23

.00

.13

HOTL < human = HITL

92.19

.00

.04

HOTL < human < HITL

75.88

.00

.02

HOTL < human < HITL

110.72

.00

.02

Human = HOTL < HITL

42.19

.00

.01

HOTL < human < HITL

6.70

.00

.00

HOTL < human = HITL

181.03

.00

.04

HOTL < human < HITL

54.67

.00

.02

HOTL < human < HITL

68.85

.00

.02

HOTL < human < HITL

92.46

.00

.02

HOTL < human < HITL

78.92

.00

.01

HOTL < human < HITL

177.46

.00

.05

Human = HOTL < HITL

46.68

.00

.01

HOTL < human < HITL

29.93

.00

.01

Human < HOTL < HITL

50.12

.00

.01

Human = HOTL < HITL

31.06

.00

.00

Human = HOTL < HITL

22.74

.00

.00

HOTL < human = HITL

28.67

.00

.01

HOTL < human < HITL

44.50

.00

.01

Human = HOTL < HITL

human intervention (i.e., HITL) had a higher beauty score than humanmade haiku, and the score of AI-generated haiku without human inter­
vention (i.e., HOTL) was compatible with human-made haiku. The result
also indicated that task order (i.e., prior knowledge about whether the
work produced by AI) did not affect the evaluation of the beauty of
haiku. Furthermore, the result did not depend on the stimulus set that
was presented to the participants. Refer to Supplementary Table 1 for
the results of the linear mixed model for each condition.
4.3. Distinguishing between human-made and AI-generated haiku
For the attributional authorship (i.e., the participants’ abilities to
distinguish between human-made and AI-generated haiku), hit rates (i.
e., the probability of correctly judging human-made haiku as humanmade and AI-generated haiku as AI-generated) for the human, HOTL,
and HITL conditions were .55, .50, and .43, respectively (Fig. 2; see also
Supplementary Table 2 for the hit rate of each haiku and list). Although
the hit rate in the human condition was significantly higher than the
chance level, t(39) = 3.51, p = .001, in the HITL condition it was
significantly lower than the chance level, t(19) = − 3.19, p = .005. The
hit rate in the HOTL condition was not different from the chance, t(19)
= 0.03, p = .98. These results suggest that the participants could not
distinguish between human-made and AI-generated for HOTL haiku.
Furthermore, they believed that the authorship of HITL haiku was
human rather than AI.

Fig. 1. Beauty scores in the human, HOTL, and HITL conditions.

SE = 0.01, t = 1.17, p = .24), and connection (b = − 0.01, SE = 0.01, t =
− 1.31, p = .19). Task order (b = − 0.04, SE = 0.08, t = − 0.42, p = .67),
haiku list (b = − 0.06, SE = 0.06, t = − 1.04, p = .30), and the conditional
difference between human and HOTL (b = 0.11, SE = 0.09, t = 1.35, p =
.18) did not explain the beauty of haiku, while the conditional difference
between human and HITL (b = 0.18, SE = 0.09, t = 2.16, p = .03) did. As
shown in Section 4.1, these results showed that AI-generated haiku with
6

J. Hitsuwari et al.

Computers in Human Behavior 139 (2023) 107502

Table 3
Results of the linear mixed model for factors explaining beauty.
Random effects

Name

Variance

SD

ID
Haiku ID
Residual

(Intercept)
(Intercept)

.49
.09
.70

.70
.30
.84

Fixed effects

Estimate

SE

df

t value

p value

(Intercept)
Déjà vu
Image
Valence
Arousal
Awe
Nostalgia
Novelty
Empathy
Intention
Joy
Continue
Alive
Universality
Longing
Free desire
Mind wandering
Connection
Surprise
Understand
Tells story
Task order
Haiku list
Human vs. HOTL
Human vs. HITL
Education

4.16
.09
.11
.05
.04
.10
.03
− .02
.05
.03
.03
.16
− .01
.28
− .03
.01
.01
− .01
− .02
.05
.03
− .01
− .03
.11
.18
.04

.07
.01
.01
.01
.01
.01
.01
.01
.01
.01
.01
.01
.01
.01
.01
.01
.01
.01
.01
.01
.01
.11
.10
.08
.08
.04

227.90
14940.00
14990.00
14970.00
14940.00
14990.00
14960.00
14940.00
14950.00
14950.00
14980.00
14930.00
14940.00
14990.00
14930.00
14970.00
14930.00
14920.00
14950.00
14920.00
14930.00
336.50
381.00
75.18
75.08
381.00

62.36
13.15
16.26
6.32
5.05
13.58
4.19
− 3.24
6.22
3.82
3.81
16.83
− .56
32.85
− 3.32
2.23
1.17
− 1.31
− 2.40
6.26
3.22
− .08
− .25
1.35
2.14
1.12

.00***
.00***
.00***
.00***
.00***
.00***
.00***
.00**
.00***
.00***
.00***
.00***
.57
.00***
.00***
.03*
.24
.19
.02*
.00***
.00**
.94
.81
.18
.04*
.26

Fig. 3. The scatterplot between the beauty score and the hit rate.

4.4. The relationship between hit rate and personality traits
Finally, we examined the factors explaining the discrimination ac­
curacy of authors. These factors included, the educational background,
experience of haiku, and personality traits such as animism and
empathy. As shown in Table 4, the higher the anthropomorphic ten­
dency of animism (b = .10, SE = 0.03, z = 2.81, p = .01) and the more
haiku experience (b = 0.07, SE = 0.03, z = 2.08, p = .04), the higher the
correct response. This shows that not only the artworks’ characteristics,
but also the participants’ factor such as anthropomorphic tendencies
and experience, influenced the discrimination ability of haiku authors.
Refer to Supplementary Table 3 for the exploratory results entering all
personal traits measured in this study.

Note. Dummy variables were set as follows: for Task order, − 0.5 for the rating
first condition and 0.5 for the discriminating first condition; for Haiku list, − 0.5
for list 1 and 0.5 for list 2; for Human vs. HOTL, 1 for the HOTL condition; for
Human vs. HITL, the HITL condition is 1, and the other two conditions are 0.

4.5. Exploratory analysis: the rationale behind author discrimination
We examined the relationship between the rationale behind author
discrimination (what clues participants focused on to identify the haiku
author) and hit rate. The most common clue for judging a haiku as
human-made was “depth of the work” (72% of participants), while that
for judging haiku as AI-generated was “expressiveness” (58% of par­
ticipants). Multiple regression analyses with each participant’s hit rate
as the dependent variable showed that consistency (b = 0.07, SE = 0.02,
t = 3.91, β = 0.21, p = .00) could explain the human-made haiku hit rate,
while regularity (b = 0.04, SE = 0.02, t = 2.24, β = 0.12, p = .03),
Table 4
Trait factors explaining the discrimination accuracy.
Random effects

Fig. 2. Hit rate in the human, HOTL, and HITL conditions.

If people believe that beautiful things are made by humans rather
than AI (i.e., algorithm aversion), there may be a relationship between
hit rates and beauty scores. We exploratorily examined the relationship
between the beauty score and the hit rate of each haiku. The results
showed positive but non-significant correlation in the human condition,
r(39) = 0.18, p = .26, while there were significantly negative correla­
tions in the HOTL and HITL conditions, r(19) = − .54, p = .01 and r(19)
= − .47, p = .04, respectively (Fig. 3). The higher the beauty score in the
AI haiku, the lower was the hit rate, reflecting that participants believed
that the more beautiful a haiku, the more likely it was created by a
human.

Name

Variance

SD

ID
haikuID

(Intercept)
(Intercept)

.02
.15

.16
.39

Fixed effects

Estimate

SE

z value

p value

(Intercept)
IRI
Personal Distress
Empathic Concern
Perspective Taking
Fantasy
Animism
Deification
Personalification
Anthropomorphization
Aliveness Animism
Haiku Experience
Educational Background

.04

.05

.75

.45

.06
− .11
.01
.04

.03
.06
.03
.03

1.88
− 1.82
.26
1.35

.06
.07
.79
.18

.01
− .06
.10
.01
.07
.01

.02
.03
.03
.01
.03
.02

.33
− 1.77
2.81
.57
2.08
.42

.74
.08
.01**
.57
.04*
.67

N: 15400, ID: 385, haikuID: 80.
7

J. Hitsuwari et al.

Computers in Human Behavior 139 (2023) 107502

intentionality (b = 0.09, SE = 0.02, t = 4.10, β = 0.21, p = .00), and
others (b = − 0.15, SE = 0.04, t = − 3.39, β = − 0.17, p = .00) could
explain the AI-generated haiku hit rate (Table 5).

disappeared for non-experts when there was a slight difference in
methodology.
5.2. Factors explaining beauty

5. Discussion

We identified several factors explaining the beauty and hit rate of
human-made and AI-generated haiku. One of the limitations of previous
studies was that they compared human poetry with AI poetry using
limited items such as likeability or beauty. However, this study over­
came this limitation. For instance, the vividness of mental images,
positive emotions, and higher-order emotions such as awe and nostalgia,
which have been known to explain the beauty in human haiku (Hitsu­
wari & Nomura, 2022b; 2022c), were found to be explanatory factors for
beauty in AI haiku as well. In addition, philosophical factors considered
to explain beauty by philosophers and thinkers since long before the
empirical study of beauty began (Brielmann et al., 2021) were again
found to relate to the beauty of poetry.

In this study, we evaluated haiku poetry, which has clear rules and
uses a limited number of characters (i.e., conveying only limited infor­
mation), created by humans and AI from various perspectives. The re­
sults showed that the AI-generated haiku which humans chose had
higher beauty scores than the human-made haiku. Furthermore, the AIgenerated haiku which were randomly chosen had similar beauty scores
to the human-made haiku. These results suggest that human–AI
collaboration will lead to better creativity and that AI’s generative
power is comparable to that of humans in creative fields, at least for
haiku production. This study also revealed that many factors, specif­
ically both philosophical and psychological beauty concepts, could
explain the feeling of beauty in haiku. Regarding the author’s discrim­
ination, participants could not distinguish between human-made and AIgenerated haiku. This result and the beauty scores discussed above,
show that AI can produce work of an equivalent quality as humans.
Furthermore, the personality trait of anthropomorphic tendency and
haiku experience may contribute to the discrimination ability between
human-made and AI-generated haiku.

5.3. Author discrimination of AI-generated and human-made haiku
The failure to discriminate between human-made and AI-generated
poetry is in-line with previous findings (Hopkins & Kiela, 2017; Lau
et al., 2018; Schwartz, 2015). In another study, Köbis and Mossink
(2021) found that the discrimination accuracy between human-made
and AI-generated poems was above the chance level, due to the high
accuracy for randomly chosen AI poems (i.e., HOTL; see Table 1), sug­
gesting that it was hard to identify AI poems with human intervention.
As with other poetry genres, a major factor behind the failure to
discriminate could be that the technology for the haiku generation is
improving (Ito et al., 2018; Kawamura et al., 2021; Yokoyama et al.,
2019). Moreover, the unique characteristics of haiku, such as being
much shorter and image-dependent than typical poems, may have hin­
dered their discrimination even in AI-generated haiku without human
intervention.
Considering the negative relationship between beauty scores and hit
rate in AI-generated haiku, people may have algorithm aversion (Burton
et al., 2020). Algorithm aversion is an important concept in the research
context of comparing human and AI poetry (Köbis & Mossink, 2021).
Here, the thinking may be that humans created the beautiful haiku, i.e.,
they condescended AI haiku. This study is the first to suggest a rela­
tionship between algorithm aversion and author discrimination, and the
result would reflect modern people’s attitudes toward AI art.

5.1. The beauty score between AI-generated and human-made haiku
The results showing that human-made and AI-generated haiku
without human intervention had a similar beauty score. The results are
inconsistent with a previous study (Köbis & Mossink, 2021), where
human-made poems were liked the most. One explanation for this might
be the differences in poetic style. Haiku is the shortest form of poetry
worldwide and needs to consolidate information according to a set of
rules. Thus, even in this context, the quality of AI art is well ensured. It
should also be noted that AI training and training materials were
probably better than those used in previous studies. Haiku may be
characterized by clear rules such as the 5-7-5 syllable format and the
inclusion of seasonal words, which may have made training easier.
Moreover, methodological differences might explain the discrepancies
between our results and those of previous studies (Köbis & Mossink,
2021), in which the first two lines of the AI-generated poems were the
same as the human-made ones, both poems were placed together, and
participants were asked which they preferred (i.e., two-alternative
forced choice). Two-alternative forced choice is relatively sensitive to
subtle differences between the two poems compared with the absolute
rating we employed in this study. Even if this were the case, the dif­
ferences between human-made and AI-generated works are subtle. This
study showed that the advantage that human-made artworks had

5.4. Effects of experience, personality, and clues on author discrimination
Factors like the personality traits of anthropomorphic tendency and
empathic concern have been examined in AI and robot interaction
studies (e.g., Darling et al., 2015; Okanda et al., 2019). This study

Table 5
Rationale behind author discrimination and hit rate.
Human
(Intercept)
Rhythm
Consistency
Regularity
Repeatability
Complexity
Depth
Abstraction
Intentionality
Uniqueness
Expression
Nuance
Others

AI

Mean

Estimate

SE

t value

.30
.25
.06
.02
.30
.72
.25
.52
.38
.48
.46
.03

.56
.02
.07
.03
.09
− .03
− .03
.01
.00
.00
− .01
− .01
.07

.02
.02
.02
.03
.06
.02
.02
.02
.01
.01
.01
.01
.05

29.64
1.41
3.91
.96
1.57
− 1.62
− 1.90
.53
.11
.08
− .98
− .61
1.60

Beta

p value

.07
.21
.05
.08
− .08
− .10
.03
.01
.00
− .05
− .03
.08

.00***
.16
.00***
.34
.12
.11
.06
.60
.91
.94
.33
.54
.11

8

Mean

Estimate

SE

t value

Beta

p value

.28
.41
.38
.08
.13
.23
.17
.14
.05
.58
.36
.03

.46
− .02
.00
.04
.01
.02
− .02
.01
.09
− .05
− .03
.01
− .15

.02
.02
.02
.02
.03
.02
.02
.02
.02
.03
.02
.02
.04

24.23
− .98
.26
2.24
.26
.70
− .97
.51
4.10
− 1.58
− 1.65
.68
− 3.39

− .05
.01
.12
.01
.03
− .05
.03
.21
− .08
− .08
.03
− .17

.00***
.33
.79
.03*
.80
.49
.33
.61
.00***
.11
.10
.50
.00***

J. Hitsuwari et al.

Computers in Human Behavior 139 (2023) 107502

showed that they are also meaningful in the discrimination of authors in
haiku works. From the results, it can be inferred that people with a high
anthropomorphic tendency do not impulsively judge beautiful haiku as
human-made, resulting their hit rate to be high.
Furthermore, we found that participants who paid attention to
consistency—whether the words used in haiku are consistent with each
other—had higher hit rates for human-made haiku than AI-generated
haiku. Compared with this, participants who paid attention to regular­
ity and intentionality had higher hit rates for AI-generated haiku. AI
occasionally generated haiku that contained inconsistent meanings and
were difficult to understand. Therefore, attention to consistency acted as
a tool for identifying human-made haiku. In addition, regularity is often
recognized in the appreciation of AI art (cf. Chamberlain et al., 2018),
and the presence (or absence) of intentionality is one of the major topics
in AI art research (Chamberlain et al., 2018; McCormack et al., 2019).
Although the relationship between these factors and AI art detection has
been pointed out, it has not been demonstrated. This study is the first to
show this as data.

Funding
This research was supported by Grants-In-Aid for Scientific Research
(JSPS KAKENHI Grant Number 19H01773).
Declaration of competing interest
We have no known conflict of interest to disclose.
Data availability
All data, materials, and scripts are available online (https://osf.
io/s6wny/).
Acknowledgements
We are deeply grateful to Tomohisa Yamashita (Hokkaido Uni­
veristy) for providing us with AI haiku and allowing us to use them in
our experiments.

5.5. Limitations and future research
In this study, human-made and AI-generated haiku were examined in
terms of rating and discriminating, and the relationship between beauty
scores and hit rate and various variables was clarified. However, it had
some limitations. One of them was the selection method of AI haiku for
the HITL condition. In this study, the selection was made by three nonexperts. As most participants were non-experts, it may have been easier
for them to understand the HITL haiku than the human-made haiku,
which experts selected. In the future, experiments with human-made
haiku selected by the non-experts or HITL haiku intervened by the ex­
perts could be performed. At the same time, novices and the haiku
professionals could rate the beauty or discriminate the authors as par­
ticipants. Nevertheless, at least on laypersons’ perspectives, this study
indicates that human–AI collaboration has the potential to generate
great work.
In this study, only Japanese haiku were presented to Japanese par­
ticipants. AI models of haiku generation are being refined in other
countries (Hrešková & Machová, 2018; Wong, Chun, Li, Chen, & Xu,
2008). Moreover, there was no significant difference in beauty scores in
an Eastern-Western cultural comparison of haiku (Hitsuwari & Nomura,
2022c). Hence, this study may be applicable to other cultures as well.

Appendix A. Supplementary data
Supplementary data to this article can be found online at https://doi.
org/10.1016/j.chb.2022.107502.
References
Arend, M. G., & Schäfer, T. (2019). Statistical power in two-level models: A tutorial based
on Monte Carlo simulation. Psychological Methods, 24(1), 1–19. https://doi.org/
10.1037/met0000195
Bates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-effects
models using lme4. Journal of Statistical Software, 67(1), 1–48. https://doi.org/
10.18637/jss.v067.i01
Blasko, D. G., & Merski, D. W. (1998). Haiku poetry and metaphorical thought: An
invitation to interdisciplinary study. Creativity Research Journal, 11(1), 39–46.
https://doi.org/10.1207/s15326934crj1101_5
Booten, K., & Gero, K. I. (2021). Poetry machines: Eliciting designs for interactive writing
tools from poets. Creativity and Cognition, 1–5. https://doi.org/10.1145/
3450741.3466813. Article 51.
Brielmann, A. A., Nuzzo, A., & Pelli, D. G. (2021). Beauty, the feeling. Acta Psychologica,
219, Article 103365. https://doi.org/10.1016/j.actpsy.2021.103365
Burton, J. W., Stein, M. K., & Jensen, T. B. (2020). A systematic review of algorithm
aversion in augmented decision making. Journal of Behavioral Decision Making, 33(2),
220–239. https://doi.org/10.1002/bdm.2155
Cetinic, E., & She, J. (2022). Understanding and creating art with AI: Review and
outlook. ACM Transactions on Multimedia Computing, Communications, and
Applications (TOMM), 18(2), 1–22. https://doi.org/10.1145/3475799
Chamberlain, R., Mullin, C., Scheerlinck, B., & Wagemans, J. (2018). Putting the art in
artificial: Aesthetic responses to computer-generated art. Psychology of Aesthetics,
Creativity, and the Arts, 12(2), 177–192. https://doi.org/10.1037/aca0000136
Chatterjee, A., & Vartanian, O. (2014). Neuroaesthetics. Trends in Cognitive Sciences, 18
(7), 370–375. https://doi.org/10.1016/j.tics.2014.03.003
Daniele, A., & Song, Y. Z. (2019). AI+ art= human. In Proceedings of the 2019 AAAI/ACM
conference on AI, ethics, and society (pp. 155–161). https://doi.org/10.1145/
3306618.3314233
Darling, K., Nandy, P., & Breazeal, C. (2015). Empathic concern and the effect of stories
in human-robot interaction. In 24th IEEE international symposium on robot and human
interactive communication (RO-MAN) (pp. 770–775). https://doi.org/10.1109/
ROMAN.2015.7333675
Davis, M. H. (1980). A multidimensional approach to individual differences in empathy.
Journal Supplement Abstract Service Catalog of Selected Documents in Psychology, 10,
85.
Elgammal, A., Liu, B., Elhoseiny, M., & Mazzone, M. (2017). CAN: Creative adversarial
networks generating “art” by learning about styles and deviating from style norms. ArXiv
https://arxiv.org/abs/1706.07068.
Gangadharbatla, H. (2022). The role of AI attribution knowledge in the evaluation of
artwork. Empirical Studies of the Arts, 40(2), 125–142. https://doi.org/10.1177/
0276237421994697
Gatys, L. A., Ecker, A. S., & Bethge, M. (2016). Image style transfer using convolutional
neural networks. In Proceedings of the IEEE conference on computer vision and pattern
recognition (pp. 2414–2423). https://doi.org/10.1109/CVPR.2016.265
Gunser, V., Gottschling, S., Brucker, B., Richter, S., Çakir, D., & Gerjets, P. (2022). The
pure poet: How good is the subjective credibility and stylistic quality of literary short
texts written with an artificial intelligence tool as compared to texts written by
human authors?. In Proceedings of the Annual Meeting of the Cognitive Science Society
(Vol. 44). Retrieved from https://escholarship.org/uc/item/1wx3983m.

5.6. Conclusions
Aesthetic evaluation and author discrimination of AI-generated and
human-made haiku were conducted. The beauty scores were the same
across the human-made haiku and randomly selected AI-generated
haiku. However, even AI-generated haiku had the highest beauty
scores if they were chosen by humans. Furthermore, regarding
discrimination between human-made and AI-generated haiku, it was
difficult for the participants to discriminate between them. In addition,
we found a negative correlation between beauty scores and discrimi­
nation performance in AI haiku. Overall, these results suggest that in
haiku (where information is minimal) the quality of AI art has reached a
level which is comparable to that of humans, and the collaboration
between humans and AI can produce more creative artwork (Booten &
Gero, 2021). The finding suggests that creativity can be promoted by
having AI assistance, which may impact art and other domains related to
creativity.
CRediT author statement
Jimpei Hitsuwari: Conceptualization, Methodology, Software,
Formal analysis, Writing - Original Draft, Visualization. Yoshiyuki
Ueda: Conceptualization, Methodology, Writing - Review & Editing,
Supervision. Woojin Yun: Methodology. Michio Nomura: Supervision.
9

J. Hitsuwari et al.

Computers in Human Behavior 139 (2023) 107502
meeting of the association for computational linguistics. https://doi.org/10.48550/
arXiv.1807.03491
Lc, R. (2021). Imitations of immortality: Learning from human imitative examples in
transformer poetry generation. In 10th international conference on digital and
interactive arts (pp. 1–9). https://doi.org/10.1145/3483529.3483537
Li, C., & Wand, M. (2016). Precomputed real-time texture synthesis with markovian
generative adversarial networks. In European conference on computer vision (pp.
702–716). https://doi.org/10.1007/978-3-319-46487-9_43
McCormack, J., Gifford, T., & Hutchings, P. (2019). Autonomy, authenticity, authorship
and intention in computer generated art. In International conference on computational
intelligence in music, sound, art and design (part of EvoStar) (pp. 35–50). https://doi.
org/10.48550/arXiv.1903.02166
Okanda, M., Taniguchi, K., & Itakura, S. (2019). The role of animism tendencies and
empathy in adult evaluations of robot. In Proceedings of the 7th international
conference on human-agent interaction (Vol. 7, pp. 51–58). https://doi.org/10.1145/
3349537.3351891
Oliveira, H. (2009). Automatic generation of poetry: An overview. 1st seminar of art, music,
creativity and artificial intelligence. Retrieved May 21, 2022 from https://www.resea
rchgate.net/profile/Hugo-Goncalo-Oliveira/publication/228610670_Automatic_ge
neration_of_poetry_an_overview/links/00b7d517eea41271af000000/Automatic-ge
neration-of-poetry-an-overview.pdf.
Ragot, M., Martin, N., & Cojean, S. (2020, April). AI-generated vs. human artworks. A
perception bias towards artificial intelligence?. In CHI conference on human factors in
computing systems (pp. 1–10). https://doi.org/10.1145/3334480.3382892
Sato, T. (2007). The experienced readers’ liking for haiku and their personality. 26 pp.
139–147). The Bulletin of Hachinohe Institute of Technology (in Japanese with
English Abstract) http://id.nii.ac.jp/1078/00001477/.
Schwartz, O. (2015). Can a computer write poetry?. Retrieved May 21, 2022 from http
s://www.ted.com/talks/oscar_schwartz_can_a_computer_write_poetry?utm_camp
aign=tedspread&utm_medium=referral&utm_source=tedcomshare.
Sugimori, E., & Kusumi, T. (2014). The similarity hypothesis of déjà vu: On the
relationship between frequency of real-life déjà vu experiences and sensitivity to
configural resemblance. Journal of Cognitive Psychology, 26(1), 48–57. https://doi.
org/10.1080/20445911.2013.854248
Ueda, Y., Hitsuwari, J., Ikeda, H., & Yun, W. (2021). Tell the difference between pictures
made by artists and computers: Categorization and evaluation. Journal of Vision.
Vision Sciences Society Annual Meeting, 21(9), 2923. https://doi.org/10.1167/
jov.21.9.2923
Wong, M. T., Chun, A. H. W., Li, Q., Chen, S. Y., & Xu, A. (2008, April). Automatic haiku
generation using VSM. In WSEAS international conference on applied computer and
applied computational science (Vol. 7, pp. 318–323). Hangzhou, China.
Yokoyama, S., Yamashita, T., & Kawamura, H. (2019). Generation and selection of haiku
poems using deep learning. Journal of Japanese Society for Artificial Intelligence, 34(4),
467–474. https://doi.org/10.11517/jjsai.34.4_467 (in Japanese).

Himichi, T., Osanai, H., Goto, T., Fujita, H., Kawamura, Y., Davis, M. H., & Nomura, M.
(2017). Development of a Japanese version of the interpersonal reactivity Index.
Shinrigaku Kenkyu, 88(1), 61–71. https://doi.org/10.4992/jjpsy.88.15218
Hitsuwari, J., & Nomura, M. (2022a). Ambiguity tolerance can improve through poetry
appreciation and creation. https://doi.org/10.21203/rs.3.rs-1354600/v1
Hitsuwari, J., & Nomura, M. (2022b). How individual states and traits predict aesthetic
appreciation of haiku poetry. Empirical Studies of the Arts, 40(1), 81–99. https://doi.
org/10.1177/0276237420986420
Hitsuwari, J., & Nomura, M. (2022c). Beauty and ambiguity: Japan–Germany cross cultural
comparison on aesthetic evaluation of haiku poetry. Psychology of aesthetics, Creativity
and the arts. Advance online publication. https://doi.org/10.1037/aca0000497
Hong, J.-W., & Curran, N. M. (2019). Artificial intelligence, artists, and art: Attitudes
toward artwork produced by humans vs. artificial intelligence. ACM Transactions on
Multimedia Computing, Communications, and Applications, 15(2s), 1–16. https://doi.
org/10.1145/3326337, 58.
Hopkins, J., & Kiela, D. (2017). Automatically generating rhythmic verse with neural
networks. In Proceedings of the 55th annual meeting of the association for computational
linguistics (Vol. 1, pp. 168–178).
Hrešková, M., & Machová, K. (2018, January). Michiko: Poem models used in automated
haiku poetry generation. In International conference on current trends in theory and
practice of informatics (pp. 469–476). https://doi.org/10.1007/978-3-319-73117-9_
33
Iida, A. (2008). Poetry writing as expressive pedagogy in an EFL context: Identifying
possible assessment tools for haiku poetry in EFL freshman college writing. Assessing
Writing, 13(3), 171–179. https://doi.org/10.1016/j.asw.2008.10.001
Ikeuchi, H. (2010). Animistic thinking in adults: The memorial service for dolls as a
voluntary loss. Research in Social Psychology, 25(3), 167–177. https://doi.org/
10.14966/jssp.KJ00006203282
Iseki, R. (2021). Anovakun. Available Online at: version 4.8.6. http://riseki.php.xdomain.
jp/.
Ito, T., Ono, J., & Ogata, T. (2018). Haiku generation using gap techniques. In Proceedings
of the 2018 international conference on artificial intelligence and virtual reality (pp.
93–96). https://doi.org/10.1145/3293663.3293666
Karayev, S., Trentacoste, M., Han, H., Agarwala, A., Darrell, T., Hertzmann, A., &
Winnemoeller, H. (2013). Recognizing image style. arXiv preprint https://doi.org/10.
48550/arXiv.1311.3715.
Kawamura, H., Yamashita, T., & Yokoyama, S. (2021). Jinkouchinou ga haiku wo yomu AI
Issa kun no chousen. Tokyo, Japan: Ohmsha (in Japanese).
Köbis, N., & Mossink, L. D. (2021). Artificial intelligence versus Maya Angelou:
Experimental evidence that people cannot differentiate AI-generated from humanwritten poetry. Computers in Human Behavior, 114. https://doi.org/10.1016/j.
chb.2020.106553
Lau, J. H., Cohn, T., Baldwin, T., Brooke, J., & Hammond, A. (2018). Deep-speare: A joint
neural model of poetic language, meter and rhyme. In Proceedings of the 56th annual

10

A B S T R A C T

Keywords:
Generative AI
AI-Assisted design
Schema theory
Authenticity
AI customization

Generative Artificial Intelligence (AI) empowers the AI design process. Then, how do consumers respond to AIdesigned fashion products? Building on schema theory, this research investigated the extent to which AIdesigned clothing is perceived as authentic through three online experiments. Study 1 (n = 121) and Study 2
(n = 161) showed consumers generally respond more favorably to human-designed (vs. AI-designed) clothing,
which is driven by perceived authenticity and expected product quality. Study 3 (n = 156) confirmed that
negative responses toward AI-designed clothing can be mitigated when consumers have the option to provide
input to customize the design because it enhances perceived authenticity. Study findings offer a theoretical
understanding of how and why consumers respond to AI-designed products and practical guidelines for retailers.

1. Introduction
The retail industry is experiencing unparalleled transformation
accelerated by the development of Artificial Intelligence (AI) and
computing efficiency. A promising area of AI applications is fashion
design. In the AI-assisted design process, designers can develop new
designs inspired by the future fashion trends predicted by AI-powered
search engines (Harreis et al., 2023). Furthermore, the recent growth
of generative AI powered by advanced machine learning and easier
access to big data opened the door for companies for AI-driven fashion
design. Generative AI refers to the AI techniques and models that learn a
representation of objects in input data and generate new, original output
that keeps the identity of the original data (Murphy, 2022). Leveraging
the power of generative AI to create thousands of renderings, companies
have recently started to use AI to understand customer needs and design
better-suited apparel items with increased efficiency (Figoli et al., 2022;
Lee, 2022). For example, Acne Studio showcased AI-assisted fashion
designs for its ready-to-wear collection in Paris Fashion Week 2020. Levi
Strauss & Co. used AI algorithms to create new design alternatives for
denim jackets as well as to optimize their production and manufacturing
processes.
While AI in the fashion design process is becoming more prevalent,
not many studies have been conducted focusing on the way AI in the
design process affects consumers’ perception of the product and the

subsequent evaluation. While a few studies investigated consumer re­
sponses to AI versus human design, a consensual agreement building on
theoretical knowledge of how people evaluate AI-designed fashion
products has not been sufficiently made. Furthermore, because con­
sumer responses to AI design technology are yet underresearched from
various perspectives, plenty of room remains to investigate how and
why generative AI in the fashion design process impacts consumers’
product and brand evaluation.
To fill the research gap, this study aims to advance the understanding
of how people evaluate AI-designed fashion products. Specifically,
under the framework of schema theory and the authenticity literature,
three online experiments examined consumer responses to fashion
products designed by AI by comparing those designed by a human
designer. In addition, the mediation of perceived authenticity and ex­
pected product quality was tested to see if they explain the effect of
design entity (AI vs. human) on consumer responses. Lastly, the role of
AI customization that changes consumer responses to fashion products
designed by AI is examined.
Investigating consumer evaluation of AI-designed fashion products is
timely and crucial. The recent interest in generative AI (e.g., GPT-X,
Midjourney, DALL⋅E) is incredibly surging due to technological prog­
ress, and empirical findings on consumer responses to generative AI in
fashion design are essential to help establish the direction of the relevant
business strategies. From the schema theory perspective, the findings of

* Corresponding author.
E-mail addresses: garilee@iu.edu (G. Lee), hykim@umn.edu (H.-Y. Kim).
https://doi.org/10.1016/j.jretconser.2023.103690
Received 22 September 2023; Received in revised form 12 November 2023; Accepted 15 December 2023
Available online 22 December 2023
0969-6989/© 2023 Elsevier Ltd. All rights reserved.

G. Lee and H.-Y. Kim

Journal of Retailing and Consumer Services 77 (2024) 103690

the three online experiments provide important theoretical and practical
implications by enlightening why and how consumers form particular
responses to fashion products designed by AI, compared to humandesigned (Study 1, Study 2) and AI customization (Study 3). Conse­
quently, the study findings offer implications for practitioners seeking
strategies to interact with consumers about generative AI usage in their
design process.

consumers are willing to pay more for AI-designed (vs. human-designed)
products because of curiosity. More recently, Pieconka (2023) found
that consumers are less willing to pay for AI-designed products because
of little personal benefits from already finalized AI-designed products.

2. Literature review & hypotheses development

This study draws from schema theory to conceptualize the effect of
design entity (AI vs. human) on consumer responses. Schema theory
explains that people categorize information in schemata, which are
memory-stored cognitive frameworks that represent the organization of
their background knowledge or experience for specific domains (Fiske,
1982). Schemata facilitate people’s decision-making processes as newly
incoming information is processed in an individual’s perception based
on existing schema (Bem, 1981). That is, people retrieve information
and categorize new input based on their expectations about a particular
domain (Davvetas and Diamantopoulos, 2016; Sujan and Bettman,
1989). People may have schemata of AI that has a low ability to possess
artistic intention and create artwork, which may affect their responses to
AI-created artwork (Chamberlain et al., 2018; Hong and Curran, 2019).
Consumers’ perceptions of products and brands are significantly
affected by schemata (Davvetas and Diamantopoulos, 2016; Lee and
Kim, 2022; Meyers-Levy and Tybout, 1989). When consumers view
product information from retailers or brands, they use previously
accumulated relevant knowledge to interpret the information. The
activated schemata settle the initial configuration of defining or evalu­
ating the products or brands. When new product information is consis­
tent with an individual’s preexisting schema, the information is easily
processed and often leads to a basic sense of liking without evoking
fluctuating responses toward the product (Halkias and Kokkinaki,
2014). Similarly, an individual may assimilate or accommodate the in­
formation which moderately diverges from the previous knowledge and
modify existing schemata (Mandler, 1981), and such experiences can
positively influence the evaluation of the stimuli (Meyers-Levy and
Tybout, 1989). In contrast, new product or brand information that
highly conflicts with one’s schema prevents the individual from being
willing to accommodate and thus evokes reactance and negative eval­
uation (Boush and Loken, 1991; Halkias and Kokkinaki, 2014; Mandler,
1981).
Using the schema theory as the theoretical base, the next sections
describe consumers’ perceptions of AI as a design entity, which repre­
sents discrepant information from people’s existing schemata. Specif­
ically, the subsequent evaluations of the AI-designed clothing are

2.2. Schema theory

2.1. AI in fashion design process
AI allows companies to collect and analyze massive amounts of sales
and consumer data. By leveraging such capabilities, companies utilize
various AI-powered techniques including virtual agents and personal­
ized services to offer better customer experience (Alimamy and Kuhail,
2023; Kim et al., 2023; Li et al., 2023; Yu et al., 2023). Furthermore,
generative AI creates new image-based outputs contingent on input data
or prompts, bringing about innovations in fashion design. GAN-based
models such as a Deep Convolutional GAN (DCGAN) can synthesize
design sketches, garment patterns, and texture information to generate
realistic design alternatives (Guo et al., 2023; Xian et al., 2018; Yan
et al., 2022). After input data, such as previous company designs,
budget, materials, and design features, is entered, algorithms generate,
evaluate, refine, and optimize design alternatives. The design outputs
can then be evaluated and regenerated by modifying the input data or
fine-tuning the algorithm models. Fig. 1 illustrates the AI-assisted design
process. Fashion brands can use AI to produce new profitable designs
with enhanced time and labor efficiency while identifying market trends
and patterns (Figoli et al., 2022; Harreis et al., 2023; Lee, 2022).
While the studies on people’s perceptions of AI-generated creative
works mainly focused on text-based or non-commercial arts (see Ap­
pendix A for review), only a few studies have investigated how con­
sumers respond to AI-designed fashion products. Some focused on
consumer evaluation and attitude toward the products. In a seminal
work, Lee (2022) confirmed that human-generated fashion design is
more favorably evaluated than AI-generated design. Similarly, Xu and
Mehta (2022) demonstrated that consumers form more negative brand
attitudes toward AI-designed (vs. human-designed) luxury products due
to perceived brand essence, especially for fashion. Others focused more
on willingness to pay, resulting in mixed findings. Sohn et al. (2020)
confirmed that young consumers are more willing to pay for
GAN-generated fashion design. Zhang et al. (2022) found that

Fig. 1. Illustration of AI-assisted design process.
2

G. Lee and H.-Y. Kim

Journal of Retailing and Consumer Services 77 (2024) 103690

quality judgments about the product (Rao and Monroe, 1989). Impor­
tantly, research has found that consumers’ authenticity attribution
positively affects the quality perception of stimuli (Cinelli and LeBoeuf,
2020; Moulard et al., 2016). For example, Cinelli and LeBoeuf (2020)
confirmed that the intrinsic motivation of a firm for producing products
increases anticipated product quality via perceived authenticity. Such a
relationship between perceived authenticity and product quality is
attributed to the perception of quality commitment, which is one of the
dimensions of perceived authenticity (Gilmore and Pine, 2007; Napoli
et al., 2014). Consumers are likely to perceive higher authenticity from a
product as they believe a quality commitment has been made to the
product. Consequently, perceived quality of the product is enhanced,
ultimately increasing positive consumer responses.
Extending such reasoning based on the literature to AI-designed
clothing, perceived authenticity and expected product quality are
likely to explain the negative responses to AI-designed fashion. The
product designed by genuine and passionate human designers compared
to AI will be deemed to be of quality commitment in overall product
design and thus more authentic. Given that the perceptions of dedication
to design are the critical determinant for assessing designed product
quality (Zhu et al., 2009), the clothing with a higher expected quality
commitment will be considered to be high quality.

proposed to be explained by perceived authenticity and expected
product quality.
2.3. Perceived authenticity and consumer responses toward AI-designed
clothing
This study proposes that information about design entity, either AI or
humans, serves as the critical determinant that affects perceived product
authenticity. Authenticity is defined as what is genuine, real, true, and
unique (Beverland and Farrelly, 2010; Moulard et al., 2014). Consumers
perceive specific levels of authenticity from products along various di­
mensions, including product information, influencer characteristics,
advertising messages, production methods, materials, origins, and con­
nections to firm value (Audrezet et al., 2020; Campagna et al., 2023;
Newman and Dhar, 2014). When authenticity is perceived based on
whether a product is made with the appropriate techniques and pro­
cesses or whether a passionate creator makes a product, they are also
known as craft authenticity and artist authenticity (Littrell et al., 1993;
Moulard et al., 2014), respectively. For example, a souvenir product is
perceived to be highly authentic if it is associated with uniqueness,
workmanship, artistry, aesthetics, and cultural and historical integrity.
Perceived authenticity has been found to positively affect consumer
responses, such as overall product valuation (Newman and Dhar, 2014)
and attitudes toward the products or brands and purchase intention
(Carsana and Jolibert, 2018; Moulard et al., 2014; Napoli et al., 2014).
It is expected that the discrepancy between people’s preexisting
fashion design schema and AI (vs. humans) is large that perceived
authenticity is lowered from AI-designed fashion products than humandesigned ones. Fashion design has been conventionally considered a
human-dominant area. People expect fashion design elements to
encompass designers’ intentions, knowhows, personal characteristics,
and sophisticated skills (Lamb and Kallal, 1992). This implies that
fashion design schemata are associated with human work and charac­
teristics. In contrast, AI as a design entity in fashion represents the in­
formation that highly conflicts with the existing schemata, considering
the long history of intersection between humans and fashion design
works and the relevant schemata. Generative AI is developed to create
original content, but it is true that many people question the reliability
and authenticity of the output from AI (Bang et al., 2023; Harper, 2023),
which potentially indicates low perceived authenticity. Because gener­
ative AI is trained on data lakes and question snippets to create content
responding to prompts, the originality of the content creation is often
doubted (Appel et al., 2023). While no research empirically tested the
authenticity perception of AI-generated design, Jago (2019) showed
that algorithm-made decisions across domains are perceived to be low in
authenticity and sincerity and thus less favored, compared to human
decisions. Such a pattern is predicted to be amplified for fashion design
because fashion is especially considered to be the domain where the
importance of the human touch cannot be overlooked. Thus, consumers
will perceive higher authenticity from human-designed clothing
compared to AI-designed clothing, which enhance consumers’ favorable
responses.

H3. Perceived authenticity and expected product quality will serially
explain the negative responses to AI-designed (vs. human-designed)
clothing.
2.5. The role of AI customization

H1. Consumers will form more favorable responses (i.e., attitude and
purchase intention) toward human-designed clothing than AI-designed
clothing.

How can consumers’ negative responses to AI-designed clothing be
mitigated? This study proposes that real-time customization in AI design
process will change the extent to which consumers perceive authenticity
from AI-designed clothing, and in turn, reduce negative responses. Based
on the existing literature and available technologies (Aggarwal et al.,
2020; Harreis et al., 2023; Yan et al., 2022), AI customization is
conceptualized as the process through which consumers provide input to
personalize their products in real-time based on particular design com­
ponents and AI generates designs to actualize customization accord­
ingly. Mass customization in product design utilizes flexible
computer-aided systems. The benefits of mass customization have
been well documented. Key market performance metrics such as sales
revenues and gross margin, as well as consumer evaluations, outperform
when product design pipelines encompass customer involvement
(Moreau and Herd, 2010; Nishikawa et al., 2013; Stevens et al., 2017).
Furthermore, a positive connection between personalization and
authenticity is speculated in that both draw favorable consumer atti­
tudes and intentions toward AI, as implied in the literature (Alimamy
and Kuhail, 2023; Chu et al., 2022). For example, Alimamy and Kuhail
(2023) found that both perceived authenticity and personalization of a
virtual assistant predict consumer commitment and trust. When it comes
to AI design process, AI customization is likely to increase perceived
authenticity by inducing the values of mass customization and enhanced
benefits of real-time personalization. Therefore, it is expected that the
negative effect of AI as a design entity on perceived authenticity will be
alleviated by AI customization, consequently mitigating the negative
responses to AI-designed clothing.

H2. Perceived authenticity will explain the negative responses to AIdesigned (vs. human-designed) clothing.

H4. AI customization will mitigate the negative effect of AI as design
entity on consumer responses (i.e., attitude and purchase intention).

2.4. Perceived authenticity and expected product quality

3. Research model & overview of the studies

If perceived authenticity on the basis of one’s schemata of AI explains
why consumers would respond differently to human-designed versus AIdesigned clothing, consumer expectations of product quality will likely
serve as the second serial mediator. Consumers rely on extrinsic signals
such as product information, warranty, or brand reputation to make

Fig. 2 presents the research model along with an overview of the
studies and the variables tested. This study adopted a quantitative
approach, and three online experiments were conducted to test the hy­
potheses. As a scenario-based experiment using real brand names, Study
1 examined the main assumptions of this research by testing whether
3

G. Lee and H.-Y. Kim

Journal of Retailing and Consumer Services 77 (2024) 103690

Fig. 2. Research model and overview of the studies.

design entity (AI vs. human) affects product attitude and purchase
intention (H1) and whether perceived authenticity mediates such an
effect (H2). Study 2 replicated Study 1 using stimuli of a product image
and a fictitious brand name. Further, Study 2 examined whether
perceived authenticity and expected product quality serially explain the
effects of design entity (H3). Lastly, Study 3 explored the role of AI
customization by testing whether AI design process with versus without
customization features affects product attitude, brand attitude, and
purchase intention (H4). The mediations of perceived authenticity (H2)
and the authenticity–product quality chain (H3) explaining the miti­
gating effect of AI customization were also tested in Study 3. The study
design, data analysis, results, and discussion of each study are described
below.

4. Study 1
4.1. Methods
4.1.1. Study design and procedure
A scenario-based online experiment was conducted where design
entity (AI vs. human) and two brand replicates were entered as betweensubject factors. One hundred and forty-two U.S. participants were
recruited from Amazon Mturk. After deleting those who failed multiple
qualification and attention check questions, 121 participants remained
for further analysis (Mage = 38.84, SDage = 11.59; 66.9% male; see
Appendix B and C for details). Once participants agreed to participate in
the study, they were randomly given one of the four shopping scenarios

Table 1
Measurement items.
Item Content

Study 1

Study 2

M (SD)
Perceived Authenticity
Ingenuine–Genuine
Not authentic–Authentic
Not original–Original
Unfaithful–Faithful
Not natural–Natural
Expected Product Quality
This sweater would be reliable.
This sweater would be dependable.
This sweater would be durable.
The workmanship on this sweater would be good.
Product Attitude
Dislikable–Likable1
Bad–Good123
Negative–Positive123
Unfavorable–Favorable23
Undesirable–Desirable23
Purchase Intention
The likelihood of purchasing this sweater is high.1
The probability that I would consider buying the sweater is high.1
My willingness to buy the sweater is high.1
I would consider buying the sweater.123
It is likely that I will purchase this sweater.23
It is probable that I will purchase this sweater.23
Brand Attitude
Bad–Good
Dislike very much–Like very much*
Unpleasant–Pleasant

Loadings

α = .91

M (SD)

Study 3
Loadings

α = .90

5.64 (1.52)
5.74 (1.45)
5.62 (1.41)
5.51 (1.40)
5.00 (1.83)

.90
.94
.83
.78
.71

-

5.51 (1.28)
5.50 (1.30)
5.30 (1.64)
5.34 (1.25)
5.30 (1.41)

-

5.69 (1.02)
5.58 (1.08)
5.60 (1.05)
5.66 (1.13)

.89
.89
.96
-

5.30 (1.46)
5.24 (1.48)
5.17 (1.56)
5.10 (1.55)

.93
.91
.94
.88
-

5.31 (1.64)
5.07 (1.73)
5.09 (1.67)

α = .94

α = .95

-

4.67 (1.28)
4.62 (1.27)
4.64 (1.25)
4.41 (1.35)

.91
.92
.88
.88

4.41 (1.74)
4.38 (1.72)
4.26 (1.77)
4.04 (1.72)

.90
.93
.95

3.52 (1.94)
3.01 (1.80)
3.08 (1.86)

-

Note. 1Study 1; 2Study 2; 3Study 3; *reversed and deleted in Study 2 due to low factor loading.
All factor loadings were significant at 0.001 level.
4

5.12 (1.58)
2.89 (1.57)
5.06 (1.67)

.94
.94
.91
.91

α = .97
.95
.93
.95
.92

α = .97

α = .92

-

.90
.90
.69
.70
.67

α = .96

α = .95

5.22 (1.66)
5.44 (1.65)
5.37 (1.62)
5.60 (1.48)
-

4.26 (1.59)
4.26 (1.66)
3.35 (1.75)
4.44 (1.30)
4.29 (1.47)

.86
.67
.79
.90

α = .94

5.95 (1.25)
5.92 (1.31)
5.93 (1.33)
-

Loadings

α = .88
.78
.81
.83
.76
.80

α = .85

-

M (SD)

.91
.98
.99

α = .97
.92
.38*
.92

4.34 (1.49)
4.45 (1.46)
4.27 (1.49)

.96
.94
.97

G. Lee and H.-Y. Kim

Journal of Retailing and Consumer Services 77 (2024) 103690

and completed the questionnaire. The questionnaire including the
shopping scenarios in an online repository and a diagrammatic repre­
sentation of study procedure are available in Appendix D.
Shopping scenarios manipulated the design entity (AI vs. human). In
addition, two different brand types were used in the scenarios as brand
replicates to see if the effect of design entity holds across the brands.
Based on the previous literature on brand type (Mitchell and Balabanis,
2021), Louis Vuitton and H&M were used to represent different brand
types. Design entity and brand replicates were manipulated using a
brand sweater scenario. A sweater was used in the scenario to rule out
potential confounding effects, as past literature indicates that the
conceptualization of a sweater is well-defined, consistent among various
people, and stable over time (DeLong et al., 1986).

replicates.
MANCOVA was performed with design entity and brand replicates as
independent variables and perceived authenticity, product attitude, and
purchase intention as dependent variables. Both brand familiarity and
brand attitude showed significant correlations with the dependent var­
iables, showing suitability as potential covariates. Next, while brand
familiarity did not significantly affect dependent variables (p = .076),
brand attitude showed a significant effect (p < .001) and thus was
entered as a covariate. The statistical assumptions were checked, and the
results showed the appropriateness of the methods used (see Appendix
F). The main effect of design entity on the dependent variables was
significant (Pillai’s Λ = 0.16, Wilks’ λ = 0.84, p < .001, partial η2 =
0.16) whereas brand replicates did not show a significant effect (p =
.151). The design entity × brand replicate interaction effect was not
significant (p = .415). The results remained the same sans the covariate
in that nonsignificant and significant effects hold with and without the
covariate, which supports the robustness of the findings (see Appendix G
for the results without covariates). The subsequent ANCOVA showed
participants perceived higher authenticity from human-designed (vs. AIdesigned) sweater (MAI = 5.06 vs. Mhuman = 5.97; F = 18.81, p < .001,
η2 = 0.14). Participants in the human condition showed more favorable
attitudes (MAI = 5.72 vs. Mhuman = 6.17; F = 5.18, p = .025, η2 = 0.04)
and marginally higher purchase intention (MAI = 5.17 vs. Mhuman =
5.67; F = 3.67, p = .058, η2 = 0.03). Thus, H1 was supported.

4.1.2. Measurements
The multi-item scales were drawn from the existing literature and
modified to fit the context. The measurement items for the main vari­
ables, item wise descriptive, and Cronbach’s alpha scores are presented
in Table 1. Participants’ responses to multi-item scales for a construct
were averaged to calculate an index score. Perceived authenticity was
measured using five items derived from Beverland and Farrelly’s (2010)
study. Product attitude was measured using three items from Chae and
Hoegg’s (2013) study and purchase intention was measured with four
items developed by Dodds et al. (1991). Brand luxuriousness (main­
stream–luxury; Moreau et al., 2020) and reputation (bad reputation–good
reputation; Chaudhuri, 2002) were measured on 7-point semantic scale
items from the literature to ensure whether the two brands represent
different types. Harman’s one-factor test was used to test common
method bias. The total variance extracted by one factor using the 32
items was 38.68%. As the threshold indicating common method bias is
50% (Podsakoff and Organ, 1986), common method bias was not a
major concern.

4.2.3. Mediation
PROCESS macro version 4.2 in SPSS was used for mediation analysis.
The evidence of a significant indirect effect is provided if the 95%
bootstrap confidence intervals do not contain zero. Model 4 (5000
bootstrapped samples) was performed to test the mediation of perceived
authenticity between design entity and the dependent variables while
controlling brand attitude. As hypothesized, the indirect effects of
design entity on product attitude (b = 0.57, 95% bootstrap CI = [0.2483,
0.9334]) and purchase intention (b = 0.81, CI = [0.4382, 1.2041])
through perceived authenticity were significant. The direct effect of
design entity on product attitude (p = .448) and purchase intention (p =
.139) became insignificant when perceived authenticity was entered as a
mediator, suggesting the full mediation of perceived authenticity on the
effect of design entity and the two dependent variables. Thus, H2 was
supported.

4.1.3. Covariates
Potential covariates were selected a priori based on the literature
review and the study design. Given that real brands were used in Study
1, brand attitude (negative–positive) and familiarity (unfamiliar–familiar)
were measured on 7-point semantic scale items as potential covariates.
This was because the literature suggested neutralizing the confounding
effects of existing brands by controlling for familiarity or previous
experience with and general attitude toward existing brands (Geuens
and De Pelsmacker, 2017; Ha et al., 2019).

4.3. Discussion
Study 1 confirmed that consumers more favorably respond to and are
slightly more willing to purchase clothing designed by humans than by
AI (H1). Such an effect was significant across the brand replicates in
Study 1. Also, Study 1 provided initial evidence for the mediating effect
of perceived authenticity (H2). Compared to human-designed clothing,
AI-designed clothing was perceived to be less authentic, which led to
lowered product attitude and purchase intention. As a scenario-based
study using real brands was conducted in Study 1, Study 2 utilizes
product image stimuli and a fictitious brand.

4.2. Results
4.2.1. Measurement testing
The validity and reliability of the measurement were tested by
confirmatory factor analysis (CFA) with maximum-likelihood estimation
using SPSS AMOS. The measurement model fit was adequate (χ2 =
78.86, df = 49; χ2/df = 1.61; CFI = 0.98; NNFI = 0.97; RMSEA = 0.07;
SRMR = 0.03). Construct validity was confirmed as all standardized
factor loadings were high and significant at a p-value of .001 (see
Table 1). Discriminant validity was achieved as all average variance
extracted (AVE) of the constructs were larger than the squared corre­
lations. Cronbach’s alpha (α>0.91) and composite reliability (CR>0.92)
were larger than the general threshold of 0.70, supporting reliability.
The results of measurement model testing are in Appendix E.

5. Study 2
5.1. Methods
5.1.1. Study design and procedure
A single-factor (design entity: AI vs. human) between-subject online
experiment was conducted. One hundred and eighty U.S. participants
were recruited from Amazon Mturk. After deleting those who failed the
multiple attention check questions, 161 participants remained for
further analysis (Mage = 36.88, SDage = 10.69; 67.7% male; see Ap­
pendix B and C). Similar to Study 1, shopping scenarios manipulated the
design entity. Participants were randomly given one of the two shopping
scenarios, viewed a product image, and completed the questionnaire.

4.2.2. Effect of design entity
SPSS version 29.0 was used for statistical analysis throughout the
research. A p-value at the level of 0.05 was considered to be significant.
Participants perceived Louis Vuitton as more luxurious (M = 6.52 vs.
4.34; t = 7.07, p < .001) and more reputational (M = 6.23 vs. 5.61; t =
2.95, p = .004) than H&M. No differences were found in brand attitude
(p = .126) and brand familiarity (p = .575) between the two brands.
Thus, the two real brands were appropriate to be used for brand
5

G. Lee and H.-Y. Kim

Journal of Retailing and Consumer Services 77 (2024) 103690

The scenario asked them to imagine that they found a sweater designed
by either Artificial Intelligence (AI) or fashion designers online. Again, a
sweater was used in the study based on the suggestions of the past
literature and the results of pretest (DeLong et al., 1986; see 4.1.1
above). The questionnaire and a diagrammatic representation of study
procedure are available in Appendix D.

5.2. Results
5.2.1. Measurement testing
The measurement model fit was adequate (χ2 = 212.61, df = 125; χ2/
df = 1.701; CFI = 0.97; NNFI = 0.96; RMSEA = 0.07; SRMR = 0.05; see
Appendix E). Construct validity was confirmed as the factor loadings
were high and significant at a p-value of .001 (see Table 1). Discriminant
validity was achieved as all AVE values of the constructs were larger
than the squared correlations. Cronbach’s alpha (α>0.85) and com­
posite reliability (CR>0.88) supported measurement reliability.

5.1.2. Stimuli
An identical product image was given to participants across the study
conditions to ensure testing of the causal effect of design entity. A pretest
(n = 72; Mage = 33.75, SDage = 10.38; 65.3% male; see Appendix C) was
conducted on Amazon Mturk to select appropriate product image stimuli
and fictitious brand name. The pretest questionnaire is available in
Appendix D. The pretest consisted of two parts. Participants were told
they would see multiple brand names and products and give their
opinions about them. First, participants were given a list of six fictitious
brand names which were created using an online fake brand name
generator. For each brand name, brand attitude and brand familiarity
were measured using single-item scales: “To what extent do you feel
positive or negative about these fashion brand names?” (1 = Extremely
negative–7 = Extremely positive) and “To what extent are you familiar
with the following fashion brand names?” (1 = Extremely unfamiliar–7 =
Extremely familiar). Next, participants viewed four clothing images in
random order: pique shirt, sweater, shirt, and jacket. For each product
image, product attitude was measured using three-item semantic dif­
ferential scales: negative–positive, dislikable–likable, and bad–good
(0.85<α<0.90).
A fictitious brand name ‘Camource’ were chosen because partici­
pants showed relatively neutral attitudes toward the brand name (M =
4.56, SD = 1.45) and low brand familiarity (M = 4.26, SD = 1.88),
compared to other brand names. Next, a sweater image was selected as
final because participants showed neutral attitudes toward the sweater
compared to other products (M = 4.92, SD = 1.47).

5.2.2. Effect of design entity
MANCOVA was performed with brand familiarity, perceived threats
from AI, and product involvement as covariates. All three covariates
showed significant correlations with at least one dependent variable and
showed a significant effect (brand familiarity, product involvement: p <
.001; perceived threats: p = .040). The statistical assumptions of the
methods used were met (see Appendix F). The main effect of design
entity was significant (Pillai’s Λ = 0.09, Wilks’ λ = 0.90, p = .012, η2 =
0.09). The results were generally sustained sans covariates, showing
minimal changes in statistics values1 (see Appendix G). Participants
perceived higher authenticity from the human-designed (vs. AIdesigned) sweater (MAI = 5.19 vs. Mhuman = 5.60; F = 8.80, p = .003,
η2 = 0.06), consistent with Study 1 results. Compared to the AI-designed
sweater, the human-designed sweater was perceived to be of marginally
significantly higher quality (MAI = 5.52 vs. Mhuman = 5.75; F = 3.49, p =
.064, η2 = 0.02). Participants in the human-designed condition formed
more favorable attitudes toward the sweater (MAI = 5.02 vs. Mhuman =
5.39; F = 4.94, p = .028, η2 = 0.03) and the brand (MAI = 4.93 vs.
Mhuman = 5.27; F = 4.20, p = .042, η2 = 0.03). No significant difference
was found in purchase intention between the human-designed and the
AI-designed conditions (p = .837). Thus, H1 was partially supported for
product attitude and brand attitude, but not for purchase intention.

5.1.3. Measurements
The multi-item scales were drawn from the literature and modified
(see Table 1). Perceived authenticity was measured using the same items
used in Study 1. Expected product quality was measured using Sweeney
et al.’s (1999) items which represent participants’ evaluation of quality
value of the product. Product attitude (Rajagopal and Montgomery,
2012) and purchase intention (Singh and Cole, 1993) were measured
using other sets of well-established scales. Because Study 2 used ficti­
tious brands, brand attitude was measured using the two items (Mitch­
ell, 1986) and used as a dependent variable. Harman’s one-factor test
confirmed the absence of common method bias (total variance extrac­
ted: 39.76%).

5.2.3. Mediation
PROCESS Model 4 was performed with brand familiarity, perceived
threats from AI, and product involvement as covariates. The approach of
performing model 4 first was to test the mediation of perceived
authenticity and examine H2 thoroughly in a different study context.
Consistent with Study 1, the indirect effects of design entity through
perceived authenticity were significant on product attitude (b = 0.28, CI
= [0.0853, 0.5131]), purchase intention (b = 0.31, CI = [0.0984,
0.5508]), and brand attitude (b = 0.19, CI = [0.0481, 0.3909]). Thus,
H2 was again supported.
Next, Model 6 tested the serial mediation of perceived authenticity
and expected quality simultaneously to answer H3. Fig. 3 and Table 2
shows the results of the serial mediation analysis on the effect of design
entity. The indirect effects of design entity serially through perceived
authenticity and expected product quality were significant on product
attitude (b = 0.09, CI = [0.0242, 0.1898]), purchase intention (b = 0.13,
CI = [0.0326, 0.2758]), and brand attitude (b = 0.10, CI = [0.0283,
0.2080]). The sole mediation of perceived authenticity remained sig­
nificant for product attitude and purchase intention, indicating that both
perceived authenticity and the authenticity–product quality chain
mediate the effect of design entity on the two. Thus, H3 was supported.

5.1.4. Covariates
Brand attitude was not considered a covariate in Study 2 because
Study 2 used a fictitious brand name, and the pre-existing attitude was
not a major concern (Schneider and Cornwell, 2005). Rather, brand
attitude was entered as a dependent variable to examine if design entity
affects brand attitude. Brand familiarity (Batra et al., 2000; α = 0.98)
was still measured as a potential covariate to control potential influence
of the feeling of knowing the brand. Next, perceived threats from AI
(White et al., 2012; α = 0.96) were measured because the literature
suggested the feeling of being threatened by novel technology can make
people negatively respond to outcomes produced by the technology
(Khasawneh, 2018). Lastly, product involvement (Zaichkowsky, 1985;
α = 0.96) was measured as a potential covariate. This was because a
sweater image was used as a stimulus, and one’s interest levels in
sweaters might provoke confounding effects on the evaluation of the
products (Richins and Bloch, 1986).

5.3. Discussion
Study 2 aimed to replicate Study 1 using a fictitious brand and a
product image. Study 2 showed consistent results with Study 1 such that
1
The differences in perceived quality between AI-designed versus humandesigned sweaters were marginally significant when including covariates (p
= .064) but significant excluding covariates (p = .044). The authors interpret
the results controlling for covariates to rule out the effects of covariates.

6

G. Lee and H.-Y. Kim

Journal of Retailing and Consumer Services 77 (2024) 103690

Fig. 3. Study 2 serial mediation analysis
Note. Dashed line shows non-significant path. *<0.05, **<0.01, ***<0.001.

6. Study 3

Table 2
Study 2 indirect effects.
Paths
Product Attitude
Direct effect
Design entity→authenticity→product attitude
Design entity→product quality→product
attitude
Design entity→authenticity→product
quality→product attitude
Purchase Intention
Direct effect
Design entity→authenticity→purchase
intention
Design entity→product quality→purchase
intention
Design entity→authenticity→product
quality→purchase intention
Brand Attitude
Direct effect
Design entity→authenticity→brand attitude
Design entity→product quality→brand
attitude
Design entity→authenticity→product
quality→brand attitude

b

95% bootstrap CI

0.08 (p =
.540)
0.19*
0.00

-0.1862

0.3541

0.0549
-0.0817

0.3749
0.0808

0.09*

0.0242

0.1898

-0.28 (p =
.072)
0.18*

-0.5878

0.0253

0.0379

0.3776

0.01

-0.1076

0.1252

0.13*

0.0326

0.2758

0.15 (p =
.324)
0.08
0.01

-0.1483

0.4454

-0.0040
-0.0868

0.2058
0.0975

0.10*

0.0283

0.2080

6.1. Methods
6.1.1. Study design and procedure
A single-factor (AI design process: AI vs. AI customization) betweensubject online experiment was conducted to test the effect of providing
real-time customization options in the AI design process. One hundred
and sixty U.S. participants fluent in English were recruited from Prolific,
and 156 participants remained for data analysis (Mage = 37.50, SDage =
13.26; 38.5% male; see Appendix B and C). The AI design process was
manipulated through shopping scenarios and customization tasks. Par­
ticipants were randomly assigned to one of the two conditions. Those in
the AI condition read a scenario and viewed a product image. The sce­
nario told them AI designed a sweater. Participants in the AI custom­
ization condition read a scenario telling them AI would design a sweater
based on their input. They were given options to select the sweater’s
color and pattern, and a product image based on their input was then
provided to them. This approach was adopted to ensure internal validity
by minimizing the potential differences between diverse stimuli caused
by user-typed prompts. The questionnaire and a diagrammatic repre­
sentation of study procedure are available in Appendix D.
6.1.2. Stimuli
The sweater image used in Study 2 was used in Study 3. Sixteen
variations of the sweater image were developed to reflect the design
options in the AI customization condition: four colors (light gray, gray,
light blue, and blue) and four patterns (no pattern; plain, argyle, stipe,
and dot). To avoid potential confounding effects of sweater design be­
tween study conditions and increase internal validity, the same set of
sweater images available in the AI customization condition was used in
the AI condition to show a randomly selected image.

Note. Asterisk (*) indicates significant effect.

participants formed more favorable attitudes toward human-designed
(vs. AI-designed) clothing because of perceived authenticity (H1, H2).
The effect was also significant on brand attitude, but not on purchase
intention or expected product quality. In contrast to the scenario-based
experiment in Study 1, the insignificant differences in purchase inten­
tion between the study conditions may be due to the product image
stimuli used in Study 2. Additionally, Study 2 confirmed the serial
mediation of perceived authenticity and expected product quality be­
tween design entity (AI vs. human) and the three consumer responses
(H3). Although the perceived authenticity–product quality chain
explained the effect of design entity, the mediation of perceived
authenticity still remained significant. Next, Study 3 examines the role
of AI customization in alleviating consumers’ negative responses to AIdesigned clothing by testing the effect of AI design process.

6.1.3. Measurements
The scales used in Study 2 were used to measure perceived authen­
ticity, expected product quality, product attitude, purchase intention,
and brand attitude (see Table 1). Additionally, perceived automation
and customization in design were measured to check similar perceived
automation and different perceived customization between the study
conditions. Participants indicated perceived automation in design by
specifying the extent to which the design process seemed more like (1 =
mostly by computer—10 = mostly by humans). Perceived customization
was measured by employing the items from Srinivasan et al.’s (2002)
study on a 7-point Likert scale (α = 0.93): “This sweater design was
customized to my needs,” “I believe that this sweater design was
customized to my characteristics,” and “This sweater was designed
based on my input.” Harman’s one-factor test confirmed the absence of
7

G. Lee and H.-Y. Kim

Journal of Retailing and Consumer Services 77 (2024) 103690

common method bias (total variance extracted: 34.70%).

indicating that the effects of AI design process are partially mediated by
perceived authenticity and the authenticity–product quality chain.
Thus, H3 is supported in the context of AI design process.

6.1.4. Covariates
Similar to Study 2, brand familiarity (α = 0.98), perceived threats
from AI (α = 0.92), and product involvement (α = 0.95) were measured
as the potential covariates using the same measurements.

6.3. Discussion
Study 3 confirmed the role of AI customization in mitigating the
negative effect of AI as design entity by comparing AI versus AI cus­
tomization (H4). Participants’ negative attitudes and purchase in­
tentions toward AI-designed clothing were mitigated when they
provided their input to customize the product design. While expected
product quality did not differ, Study 3 confirmed the mediation of
perceived authenticity (H2) and the serial mediation of perceived
authenticity and expected product quality (H3) when comparing AI
versus AI customization. In line with Study 2, the mediation of perceived
authenticity remained significant when the perceived authenticity–­
product quality chain was entered. Unexpectedly, the direct effect of AI
design process on the responses was found to be significant, suggesting
that a third factor may explain such a relationship. The following sec­
tions present a general discussion of the study findings along with
theoretical and practical implications.

6.2. Results
6.2.1. Measurement testing
The measurement model fit was adequate (χ2 = 264.01, df = 141; χ2/
df = 1.872; CFI = 0.97; NNFI = 0.96; RMSEA = 0.07; SRMR = 0.05; see
Appendix E). Construct validity was confirmed as the factor loadings
were high and significant at a p-value of .001 (see Table 1). Discriminant
validity was achieved as all AVE values of the constructs were larger
than the squared correlations. Cronbach’s alpha (α>0.88) and com­
posite reliability (CR>0.88) supported measurement reliability.
6.2.2. Effect of AI design process
There were no differences in perceived automation between the two
study conditions (p = .487). Compared to those in the AI condition,
participants in the AI customization condition believed more that the
sweater was designed with customization (M = 2.62 vs. 5.13; t = -11.31,
p < .001). Thus, the manipulation of AI design process was successful.
MANCOVA was performed with brand familiarity, perceived threats
from AI, and product involvement as covariates. The three covariates
showed significant correlations with at least one dependent variable and
showed a significant effect (perceived threats, product involvement: p <
.001; brand familiarity: p = .003). The statistical assumptions were met
(see Appendix F). The main effect of the AI design process was signifi­
cant (Pillai’s Λ = 0.18, Wilks’ λ = 0.82, p < .001, η2 = 0.18). The results
were generally sustained sans covariates, showing minimal changes in
statistics values2 (see Appendix G). Participants in the AI customization
(vs. AI) condition perceived higher authenticity (MAI = 3.91 vs. MAI­
2
custom = 4.32; F = 4.81, p = .030, η = 0.03). Also, participants in the AI
customization (vs. AI) condition formed higher product attitude (MAI =
3.84 vs. MAIcustom = 4.70; F = 12.65, p < .001, η2 = 0.08), purchase
intention (MAI = 2.52 vs. MAIcustom = 3.87; F = 29.79, p < .001, η2 =
0.17), and brand attitude (MAI = 4.05 vs. MAIcustom = 4.65; F = 9.18, p =
.003, η2 = 0.06). Expected product quality between the two conditions
did not differ (p = .353). Thus, H4 was supported for all variables except
for expected quality.

7. General discussion
The huge progress in generative AI, an algorithm-based computer
system that enables new content creation, is clearly bringing revolutions
to retail and consumer environment. Companies adopt AI-assisted
product design processes to optimize overall operations and improve
efficiency while better meeting market demand. To provide a theorybased understanding of AI-designed clothing from the consumer psy­
chology perspective, this study investigated how consumers respond to
AI-designed fashion products, focusing on clothing.
The findings indicate that consumers generally form negative re­
sponses to AI-designed (vs. human-designed) clothing. This pattern is
attributed to low perceived authenticity from AI, which is based on the
large discrepancy between consumers’ preexisting fashion design
schema and AI. Further, the authenticity–product quality chain also
explains consumer responses to fashion products designed by AI versus
humans. AI versus humans as design entity does not always lead to
significantly different expected product quality. Still, they serially
explain the effect on consumer responses because perceived authenticity
positively affects expected product quality. Finally, the findings confirm
the role of AI customization. Although consumers form negative bias
regarding the authenticity of AI-designed clothing, such bias against AIassisted design processes can be attenuated through the option to
customize their own product design. Consequently, consumers’ attitudes
and purchase intentions toward clothing designed through AI custom­
ization become more positive compared to non-AI-customization.
Perceived authenticity increased through AI customization in turn im­
proves expected product quality, making them serially explain the effect
of AI customization.

6.2.3. Mediation
PROCESS Model 4 was performed with brand familiarity, perceived
threats from AI, and product involvement as covariates. The indirect
effects of the AI design process through perceived authenticity were
significant on product attitude (b = 0.32, CI = [0.0362, 0.6244]), pur­
chase intention (b = 0.28, CI = [0.0334, 0.5444]), and brand attitude (b
= 0.28, CI = [0.0261, 0.5465]). Thus, the mediation of perceived
authenticity was confirmed in the context of AI design process.
Model 6 was performed to test the serial mediation. Fig. 4 and
Table 3 shows the results of the serial mediation analysis. The indirect
effects of AI design process through perceived authenticity and expected
quality were significant on product attitude (b = 0.06, CI = [0.0015,
0.1445]), purchase intention (b = 0.06, CI = [0.0032, 0.1488]), and
brand attitude (b = 0.07, CI = [0.0067, 0.1639]). The sole mediation of
perceived authenticity still remained large and significant for all three
dependent variables. In addition, the direct effects of AI design process
on the responses were significant after specifying the serial mediations,

7.1. Implications
This study contributes to the literature by providing theoretical im­
plications on consumer responses to fashion products designed through
the AI-assisted process. First, this study helps advance the knowledge of
AI-assisted design processes in the consumer environment by demon­
strating consumers’ negative biases against to AI-designed (humandesigned) clothing. These findings align with the studies that humangenerated (vs. AI-generated) fashion design is more favorably evalu­
ated (Lee, 2022; Xu and Mehta, 2022). Furthermore, extending the
findings to marketing outcomes, the current study found that the
negative responses to AI-designed clothing may or may not impact sales
revenue by lowering purchase intention. These findings have the po­
tential to describe the discrepancy in the literature that consumers form

2
The differences in perceived authenticity of the sweater designed by AI
versus AI customization were significant when including covariates (p = .030)
but marginal excluding covariates (p = .073). The authors interpret the results
controlling for covariates to rule out the effects of covariates.

8

G. Lee and H.-Y. Kim

Journal of Retailing and Consumer Services 77 (2024) 103690

Fig. 4. Study 3 serial mediation analysis
Note. Dashed line shows non-significant path. *<0.05, **<0.01, ***<0.001.

authenticity and expected product quality also explain the benefits of AI
customization.
Third, this study contributes to the question of how negative bias
against AI-designed clothing can be attenuated. The findings empirically
reveal that AI customization, the process where AI generates designs
based on consumers’ real-time personalization of their product design, is
effective in raising perceived authenticity and thus drawing more pos­
itive consumer attitudes and intentions. These findings extend the pre­
vious research on the benefits of mass customization or customer
involvement (Moreau and Herd, 2010; Nishikawa et al., 2013; Stevens
et al., 2017) to AI design process. Notably, the relationship between
personalization and perceived authenticity is proven in the context of AI
customization.
The findings have important implications for practitioners who
adopt generative AI in the product design process. First, practitioners
can have insights into how and why consumers would negatively eval­
uate AI-designed clothing compared to human-designed clothing.
Considering that fashion design schema is established based on previ­
ously accumulated information revolving around fashion design, it may
be beneficial to first target the young generations who are deemed
digital natives and more familiar with advanced technology when pro­
moting AI-assisted design. Rather than pursuing a short-term increase in
sales through AI-assisted design processes, the long-term business goal
of helping consumers become more familiar with AI as a design entity
will be needed. More importantly, as perceived authenticity and ex­
pected product quality explain the negative evaluations, practitioners
can focus on enhancing and emphasizing the uniqueness of fashion
design generated through AI-assisted design processes.
Second, this study offers practitioners valuable insights regarding the
benefits of AI customization for making consumers more favorably
respond to fashion products designed with AI-assisted processes. AI
customization is suggested as a customer-centric way to better align
with the consumers’ ever-growing and changing needs while sustaining
the fashion design innovation driven by generative AI. Practitioners can
maintain computer-aided customization systems that are available to
individual consumers to compensate for the decreased perceived
authenticity and mitigate negative responses to AI-designed clothing.
For example, brands can produce designated product lines exploiting a
range of design options that consumers can use for their AI custom­
ization and increase the perceived authenticity of the AI-customized
product. Nevertheless, further efforts will be inevitable to overcome
the challenges in adapting the AI customization as the production dif­
ficulty increases with customization (Aggarwal et al., 2020).
Some implications for policymakers regarding AI design can be
considered based on the findings and the topic of this research, although
the study findings provide meaningful implications mainly for re­
searchers and practitioners. First, a guideline that companies utilizing AI

Table 3
Study 3 indirect effects.
Paths
Product Attitude
Direct effect
AI design process→authenticity→product
attitude
AI design process→product quality→product
attitude
AI design process→authenticity→product
quality→product attitude
Purchase Intention
Direct effect
AI design process→authenticity→purchase
intention
AI design process→product quality→purchase
intention
AI design process→authenticity→product
quality→purchase intention
Brand Attitude
Direct effect
AI design process→authenticity→brand
attitude
AI design process→product quality→brand
attitude
AI design process→authenticity→product
quality→brand attitude

b

95% bootstrap CI

0.54* (p
= .005)
0.27*

0.1668

0.9128

0.0236

0.5272

-0.01

-0.1005

0.0876

0.06*

0.0015

0.1445

1.09* (p
< .001)
0.22*

0.6650

1.5054

0.0278

0.4582

-0.01

-0.1076

0.0939

0.06*

0.0032

0.1488

0.34* (p
= .023)
0.21*

0.0469

0.4454

0.0267

0.3992

-0.01

-0.1196

0.1055

0.07*

0.0067

0.1639

Note. Asterisk (*) indicates significant effect.

negative responses but may be willing to pay more due to its novelty for
AI-designed products. While it is beyond the current study’s scope, it
will be interesting if future research explores which design aspects of AI
versus human-designed clothing differentially affects purchase intention
and willingness to pay more.
Second, this study unveils the mechanisms under the negative re­
sponses to AI-designed clothing building on the schema theory. Because
consumers’ schemata about fashion design are mainly associated with
human work and traits, clothing designed by AI that uses existing data is
perceived as less genuine or authentic. Consequently, perceived
authenticity formed by the information about design entity shapes ex­
pected product quality and thus explains negative attitudes and pur­
chase intentions. Extending the previous findings on schema,
authenticity, and product quality perception to AI-assisted design pro­
cesses (e.g., Bem, 1981; Cinelli and LeBoeuf, 2020; Halkias and Kokki­
naki, 2014; Meyers-Levy and Tybout, 1989; Rao and Monroe, 1989), the
current study shows that fashion design schemata explain how and why
consumers evaluate AI-designed clothing. Furthermore, perceived
9

Journal of Retailing and Consumer Services 77 (2024) 103690

G. Lee and H.-Y. Kim

design clearly disclose the use of AI is deemed to be important. Since
consumers do not see AI-designed clothing as sincere and authentic as
human-designed clothing, not sharing information about AI usage in the
product design process can lead to a potential discussion about con­
sumer deception. Second, as AI customization options become more
accessible to consumers, a policy to monitor consumers’ unethical AI
usage for product design can be discussed. Nevertheless, future research
is needed to dig into the policy implications as the objective of the
current study is not to provide a full, detailed picture for policy
implications.

CRC Press, pp. 129–141. https://doi-org.ezp2.lib.umn.edu/10.1201/97810030
32410.
Alimamy, S., Kuhail, M.A., 2023. I will be with you Alexa! The impact of intelligent
virtual assistant’s authenticity and personalization on user reusage intentions.
Comput. Hum. Behav. 143, 107711 https://doi.org/10.1016/j.chb.2023.107711.
Appel, G., Neelbauer, J., Schweidel, D.A., 2023. Generative AI has an intellectual
property problem. Harvard Business Review. https://hbr.org/2023/04/generativeai-has-an-intellectual-property-problem.
Audrezet, A., De Kerviler, G., Moulard, J.G., 2020. Authenticity under threat: when social
media influencers need to go beyond self-presentation. J. Bus. Res. 117, 557–569.
https://doi.org/10.1016/j.jbusres.2018.07.008.
Bang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., et al., 2023. A multitask,
multilingual, multimodal evaluation of ChatGPT on reasoning, hallucination, and
interactivity. arXiv preprint arXiv:2302.04023. https://doi.org/10.48550/
arXiv.2302.04023.
Batra, R., Ramaswamy, V., Alden, D.L., Steenkamp, J.B.E., Ramachander, S., 2000.
Effects of brand local and nonlocal origin on consumer attitudes in developing
countries. J. Consum. Psychol. 9 (2), 83–95. https://doi.org/10.1207/
S15327663JCP0902_3.
Bem, S.L., 1981. Gender schema theory: a cognitive account of sex typing. Psychol. Rev.
88 (4), 354–364. https://doi.org/10.1037/0033-295X.88.4.354.
Beverland, M.B., Farrelly, F.J., 2010. The quest for authenticity in consumption:
consumers’ purposive choice of authentic cues to shape experienced outcomes.
J. Consum. Res. 36 (5), 838–856. https://doi.org/10.1086/615047.
Boush, D.M., Loken, B., 1991. A process-tracing study of brand extension evaluation.
J. Market. Res. 28 (1), 16–28. https://doi.org/10.2307/3172723.
Campagna, C.L., Donthu, N., Yoo, B., 2023. Brand authenticity: literature review,
comprehensive definition, and an amalgamated scale. J. Market. Theor. Pract. 31
(2), 129–145. https://doi.org/10.1080/10696679.2021.2018937.
Carsana, L., Jolibert, A., 2018. Influence of iconic, indexical cues, and brand schematicity
on perceived authenticity dimensions of private-label brands. J. Retailing Consum.
Serv. 40, 213–220. https://doi.org/10.1016/j.jretconser.2017.10.006.
Chae, B., Hoegg, J., 2013. The future looks “right”: effects of the horizontal location of
advertising images on product attitude. J. Consum. Res. 40 (2), 223–238. https://
doi.org/10.1086/669476.
Chamberlain, R., Mullin, C., Scheerlinck, B., Wagemans, J., 2018. Putting the art in
artificial: aesthetic responses to computer-generated art. Psychology of Aesthetics,
Creativity, and the Arts 12 (2), 177–192. https://doi.org/10.1037/aca0000136.
Chaudhuri, A., 2002. How brand reputation affects the advertising-brand equity link.
J. Advert. Res. 42 (3), 33–43. https://doi.org/10.2501/JAR-42-3-33-43.
Chu, S.C., Deng, T., Mundel, J., 2022. The impact of personalization on viral behavior
intentions on TikTok: the role of perceived creativity, authenticity, and need for
uniqueness. J. Market. Commun. 1–20. https://doi.org/10.1080/
13527266.2022.2098364.
Cinelli, M.D., LeBoeuf, R.A., 2020. Keeping it real: how perceived brand authenticity
affects product perceptions. J. Consum. Psychol. 30 (1), 40–59. https://doi.org/
10.1002/jcpy.1123.
Davvetas, V., Diamantopoulos, A., 2016. How product category shapes preferences
toward global and local brands: a schema theory perspective. J. Int. Market. 24 (4),
61–81. https://doi.org/10.1509/jim.15.0110.
DeLong, M.R., Minshall, B., Larntz, K., 1986. Use of schema for evaluating consumer
response to an apparel product. Cloth. Text. Res. J. 5 (1), 17–26. https://doi.org/
10.1177/0887302X8600500103.
Dodds, W.B., Monroe, K.B., Grewal, D., 1991. Effects of price, brand, and store
information on buyers’ product evaluations. J. Market. Res. 28 (3), 307–319.
https://doi.org/10.2307/3172866.
Figoli, F.A., Rampino, L., Mattioli, F., 2022. AI in design idea development: a workshop
on creativity and human-AI collaboration. In: Proceedings of the DRS2022
Conference. https://doi.org/10.21606/drs.2022.414.
Fiske, S.T., 1982. Schema-triggered affect: applications to social perception. In: Affect
and Cognition: 17th Annual Carnegie Mellon Symposium on Cognition. Lawrence
Erlbaum, Hillsdale, pp. 55–78.
Geuens, M., De Pelsmacker, P., 2017. Planning and conducting experimental advertising
research and questionnaire design. J. Advert. 46 (1), 83–100. https://doi.org/
10.1080/00913367.2016.1225233.
Gilmore, J.H., Pine, B.J., 2007. Authenticity: what Consumers Really Want. Harvard
Business School Press, Cambridge, MA.
Guo, Z., Zhu, Z., Li, Y., Cao, S., Chen, H., Wang, G., 2023. AI Assisted Fashion Design: A
Review. IEEE Access. https://10.1109/ACCESS.2023.3306235.
Ha, S., Huang, R., Park, J.S., 2019. Persuasive brand messages in social media: a mental
imagery processing perspective. J. Retailing Consum. Serv. 48, 41–49. https://doi.
org/10.1016/j.jretconser.2019.01.006.
Halkias, G., Kokkinaki, F., 2014. The degree of ad–brand incongruity and the distinction
between schema-driven and stimulus-driven attitudes. J. Advert. 43 (4), 397–409.
https://doi.org/10.1080/00913367.2014.891087.
Harper, S., 2023. ChatGPT Threatens Authenticity of DEI Communications from Leaders.
Forbes. https://www.forbes.com/sites/shaunharper/2023/02/19/chatgpt-will-wea
ken-authenticity-of-executive-communication-about-dei/?sh=2a06f8974d85.
Harreis, H., Koullias, T., Roberts, R., Te, K., 2023. Generative AI: Unlocking the Future of
Fashion. McKinsey & Company. https://www.mckinsey.com/industries/retail/our
-insights/generative-ai-unlocking-the-future-of-fashion.
Hong, J.W., Curran, N.M., 2019. Artificial intelligence, artists, and art: attitudes toward
artwork produced by humans vs. artificial intelligence. ACM Trans. Multimed
Comput. Commun. Appl 15 (2s), 1–16. https://doi.org/10.1145/3326337.
Jago, A.S., 2019. Algorithms and authenticity. Acad. Manag. Discov. 5 (1), 38–56.
https://doi.org/10.5465/amd.2017.0002.

7.2. Limitations and future research
The current study is among the first to conduct a theory-based study
exploring consumer responses to AI-designed fashion products. Still,
several study limitations remain, which can be considered in future
research. First, AI customization design process can be operationalized
in different ways other than customizing colors and patterns for
sweaters. Arising platforms for product customization using generative
AI provide diverse customization options to incorporate customers’
input, including selecting or typing in not only certain design compo­
nents (e.g., colors or patterns) but also materials (e.g., cotton or linen),
trims (e.g., buttons), features (e.g., pockets), or adjectives (e.g., fash­
ionable). Further, this study used a sweater image to control product
category effects. It will be interesting to test how perceptions of AIdesigned clothing vary depending on product categories (e.g., coat,
dress, leggings).
Second, the current study developed the hypotheses building upon
schema theory, focusing on the influence of schemata on product per­
ceptions (i.e., perceived authenticity and product quality). Given that
this study did not directly examine how AI is perceived as a design entity
from schema perspectives because it was out of scope, future research
can explore factors resulting from one’s schemata that may affect per­
ceptions of AI itself working for clothing design. It will be valuable to
test whether consumers’ particular AI schemata affect how they respond
to AI as a design entity.
Lastly, Study 3 yielded interesting findings that the effects of AI
design process are partially mediated by perceived authenticity and the
authenticity–product quality chain and that the direct effect of AI design
process on consumer responses still remains. While this study does not
entirely unveil which factor explains different responses to clothing
designed by AI versus AI customization, these findings call for future
studies employing diverse perspectives.
Funding
This work was supported by College of Design, University of
Minnesota.
Declaration of competing interest
None.
Data availability
Data will be made available on request.
Appendix A. Supplementary data
Supplementary data to this article can be found online at https://doi.
org/10.1016/j.jretconser.2023.103690.
References
Aggarwal, S., Bhardwaj, P., Arora, J., 2020. AI in fashion: present and future
applications. In: Transforming Management Using Artificial Intelligence Techniques.

10

G. Lee and H.-Y. Kim

Journal of Retailing and Consumer Services 77 (2024) 103690
Rajagopal, P., Montgomery, N., 2012. Remembering better or remembering worse: age
effects on false memory. In: Gürhan-Canli, Zeynep, Otnes, Cele, Zhu, Rui (Juliet)
(Eds.), Advances in Consumer Research, 40. Association for Consumer Research,
Duluth, MN, 928-928.
Rao, A.R., Monroe, K.B., 1989. The effect of price, brand name, and store name on
buyers’ perceptions of product quality: an integrative review. J. Market. Res. 26 (3),
351–357. https://doi.org/10.2307/3172907.
Richins, M.L., Bloch, P.H., 1986. After the new wears off: the temporal context of product
involvement. J. Consum. Res. 13 (2), 280–285. https://doi.org/10.1086/209067.
Schneider, L.P., Cornwell, T.B., 2005. Cashing in on crashes via brand placement in
computer games: the effects of experience and flow on memory. Int. J. Advert. 24
(3), 321–343. https://doi.org/10.1080/02650487.2005.11072928.
Singh, S.N., Cole, C.A., 1993. The effects of length, content, and repetition on television
commercial effectiveness. J. Market. Res. 30 (1), 91–104. https://doi.org/10.2307/
3172516.
Sohn, K., Sung, C.E., Koo, G., Kwon, O., 2020. Artificial intelligence in the fashion
industry: consumer responses to generative adversarial network (GAN) technology.
Int. J. Retail Distrib. Manag. 49 (1), 61–80. https://doi.org/10.1108/IJRDM-032020-0091.
Srinivasan, S.S., Anderson, R., Ponnavolu, K., 2002. Customer loyalty in e-commerce: an
exploration of its antecedents and consequences. J. Retailing 78 (1), 41–50. https://
doi.org/10.1016/S0022-4359(01)00065-3.
Stevens, J., Esmark, C.L., Noble, S.M., Lee, N.Y., 2017. Co-producing with consumers:
how varying levels of control and co-production impact affect. Market. Lett. 28,
171–187. https://doi.org/10.1007/s11002-016-9413-2.
Sujan, M., Bettman, J.R., 1989. The effects of brand positioning strategies on consumers’
brand and category perceptions: some insights from schema research. J. Market. Res.
26 (4), 454–467. https://doi.org/10.2307/3172765.
Sweeney, J.C., Soutar, G.N., Johnson, L.W., 1999. The role of perceived risk in the
quality-value relationship: a study in a retail environment. J. Retailing 75 (1),
77–105. https://doi.org/10.1016/S0022-4359(99)80005-0.
White, K., Argo, J.J., Sengupta, J., 2012. Dissociative versus associative responses to
social identity threat: the role of consumer self-construal. J. Consum. Res. 39 (4),
704–719. https://doi.org/10.1086/664977.
Xian, W., Sangkloy, P., Agrawal, V., Raj, A., Lu, J., Fang, C., et al., 2018. Texturegan:
controlling deep image synthesis with texture patches. In: Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, pp. 8456–8465. https://
doi.org/10.48550/arXiv.1706.02823.
Xu, L., Mehta, R., 2022. Technology devalues luxury? Exploring consumer responses to
AI-designed luxury products. J. Acad. Market. Sci. 50, 1135–1152. https://doi.org/
10.1007/s11747-022-00854-x.
Yan, H., Zhang, H., Liu, L., Zhou, D., Xu, X., Zhang, Z., Yan, S., 2022. Toward intelligent
design: an AI-based fashion designer using generative adversarial networks aided by
sketch and rendering generators. IEEE Trans. Multimed. https://doi.org/10.1109/
TMM.2022.3146010.
Yu, J., Dickinger, A., So, K.K.F., Egger, R., 2023. Artificial intelligence-generated virtual
influencer: examining the effects of emotional display on user engagement.
J. Retailing Consum. Serv. 76, 103560 https://doi.org/10.1016/j.
jretconser.2023.103560.
Zaichkowsky, J.L., 1985. Measuring the involvement construct. J. Consum. Res. 12 (3),
341–352. https://doi.org/10.1086/208520.
Zhang, H., Bai, X., Ma, Z., 2022. Consumer reactions to AI design: exploring consumer
willingness to pay for AI-designed products. Psychol. Market. 39 (11), 2171–2183.
https://doi.org/10.1002/mar.21721.
Zhu, Y., You, J., Alard, R., Schönsleben, P., 2009. Design quality: a key to improve
product quality in international production network. Prod. Plann. Control 20 (2),
168–177. https://doi.org/10.1080/09537280802705062.

Khasawneh, O.Y., 2018. Technophobia: examining its hidden factors and defining it.
Technol. Soc. 54, 93–100. https://doi.org/10.1016/j.techsoc.2018.03.008.
Kim, J., Kim, J.H., Kim, C., Park, J., 2023. Decisions with ChatGPT: reexamining choice
overload in ChatGPT recommendations. J. Retailing Consum. Serv. 75, 103494
https://doi.org/10.1016/j.jretconser.2023.103494.
Lamb, J.M., Kallal, M.J., 1992. A conceptual framework for apparel design. Cloth. Text.
Res. J. 10 (2), 42–47. https://doi.org/10.1177/0887302X9201000207.
Lee, J., Kim, H., 2022. How to survive in advertisement flooding: the effects of
schema–product congruity and attribute relevance on advertisement attitude.
J. Consum. Behav. 21 (2), 214–230. https://doi.org/10.1002/cb.1991.
Lee, Y.K., 2022. How complex systems get engaged in fashion design creation: using
artificial intelligence. Think. Skills Creativ. 46, 101137 https://doi.org/10.1016/j.
tsc.2022.101137.
Li, H., Lei, Y., Zhou, Q., Yuan, H., 2023. Can you sense without being human? Comparing
virtual and human influencers endorsement effectiveness. J. Retailing Consum. Serv.
75, 103456 https://doi.org/10.1016/j.jretconser.2023.103456.
Littrell, M., Anderson, L.F., Brown, P., 1993. What makes a craft souvenir authentic?
Ann. Tourism Res. 20 (1), 197–215. https://doi.org/10.1016/0160-7383(93)90118M.
Mandler, G., 1981. The Structure of Value: Accounting for Taste. Center for Human
Information Processing, Department of Psychology, University of California, San
Diego, pp. 3–36.
Meyers-Levy, J., Tybout, A.M., 1989. Schema congruity as a basis for product evaluation.
J. Consum. Res. 16 (1), 39–54. https://doi.org/10.1086/209192.
Mitchell, A.A., 1986. The effect of verbal and visual components of advertisements on
brand attitudes and attitude toward the advertisement. J. Consum. Res. 13 (1),
12–24. https://doi.org/10.1086/209044.
Mitchell, V.W., Balabanis, G., 2021. The role of brand strength, type, image and productcategory fit in retail brand collaborations. J. Retailing Consum. Serv. 60, 102445
https://doi.org/10.1016/j.jretconser.2021.102445.
Moreau, C.P., Herd, K.B., 2010. To each his own? How comparisons with others
influence consumers’ evaluations of their self-designed products. J. Consum. Res. 36
(5), 806–819. https://doi.org/10.1086/644612.
Moreau, C.P., Prandelli, E., Schreier, M., Hieke, S., 2020. Customization in luxury
brands: can Valentino get personal? J. Market. Res. 57 (5), 937–947. https://doi.
org/10.1177/0022243720943191.
Moulard, J.G., Raggio, R.D., Folse, J.A.G., 2016. Brand authenticity: testing the
antecedents and outcomes of brand management’s passion for its products. Psychol.
Market. 33 (6), 421–436. https://doi.org/10.1002/mar.20888.
Moulard, J.G., Rice, D.H., Garrity, C.P., Mangus, S.M., 2014. Artist authenticity: how
artists’ passion and commitment shape consumers’ perceptions and behavioral
intentions across genders. Psychol. Market. 31 (8), 576–590. https://doi.org/
10.1002/mar.20719.
Murphy, K.P., 2022. Probabilistic Machine Learning: an Introduction. MIT press.
Napoli, J., Dickinson, S.J., Beverland, M.B., Farrelly, F., 2014. Measuring consumerbased brand authenticity. J. Bus. Res. 67 (6), 1090–1098. https://doi.org/10.1016/j.
jbusres.2013.06.001.
Newman, G.E., Dhar, R., 2014. Authenticity is contagious: brand essence and the original
source of production. J. Market. Res. 51 (3), 371–386. https://doi.org/10.1509/
jmr.11.0022.
Nishikawa, H., Schreier, M., Ogawa, S., 2013. User-generated versus designer-generated
products: a performance assessment at Muji. Int. J. Res. Market. 30 (2), 160–167.
https://doi.org/10.1016/j.ijresmar.2012.09.002.
Pieconka, J., 2023. Creative Machines-Consumers’ Perception Of AI Designed Products
(Doctoral Dissertation, Leopold-Franzens-Universität Innsbruck).
Podsakoff, P.M., Organ, D.W., 1986. Self-reports in organizational research: problems
and prospects. J. Manag. 12 (4), 531–544. https://doi.org/10.1177/
014920638601200408.

A B S T R A C T

Keywords:
AI
Generative AI
Copyright
Creativity
Originality
Artificial intelligence
Data
Feist
David Guetta
ChatGPT
Input
Output
Machine Learning
Authorship
Intellectual Property

This paper takes the occasion of French DJ David Guetta’s use of generative AI tools to create lyrics and a voice in
the style of Eminem, which he then used in one of his concerts, as the basis for an exploration of the shifting
meaning of creativity and originality in the age of generative AI. Our main contention is that the Guetta form of
creativity with generative AI tools differs in certain important respects from what has come before. The paper
describes an iterative, dynamic process of conception, prompting, generation, refining, and deployment to charac­
terise creativity in this context. Nevertheless, we contend that copyright – specifically the concept of originality
as articulated in US federal law – is a sufficiently durable legal mechanism that can manage these new cultural
forms, and that the two basic requirements of modern copyright law (a tangible medium of expression and a
modest degree of creativity) remain relevant in identifying the scope of legal protection.
The paper argues that the David Guetta story reveals something more general about creativity in a digital age,
namely that while hybrid-networked (i.e., human – corporate – machine) creators have always created hybridnetworked cultural forms (i.e., creations that blend human and technology-constituted elements), such hybrid­
ity becomes increasingly visible and complex in the context of a new world of generative AI. At the very least,
earlier – and influential – models of creativity as human-driven involving creation ex nihilo become harder to
sustain in a new age of generative AI. But this does not mean copyright or notions of originality are redundant or
that copyright law cannot accommodate Guetta and other cases.
Such an account seems important as it challenges the hegemonic and reductive view that AI “generates”
artistic works autonomously and avoids reducing the copyright issues raised by such creative works to the related
but distinct question of whether learning models rely on copyrighted data. As such, copyright law should remain
an important mechanism to facilitate genuine creators who are using AI systems in innovative and unique ways
to push the boundaries of their creativity.

1. “Let me introduce you to … Emin-AI-Em”
In February 2023, one of the most prolific dance music producers in
the world, French DJ, David Guetta, posted on his personal Instagram
account a short clip from one of his latest concerts.1 In the clip, you can
hear what appears to be Eminem’s voice saying, “This is the future rave
sound; I’m getting off the underground,” accompanied by energetic
dance music. Future Rave, or FR, is a genre of electronic music associ­
ated with Guetta and Danish DJ, Morten Breum.

Guetta explained that this was something he “made as a joke,” but it
worked “so good that I could not believe it.”2 He described how he had
discovered several generative AI websites that could be used to “create”
lyrics and voices. One of them helped Guetta generate lyrics in the style
of any artist, so he typed the prompt, “Write a verse in the style of
Eminem about the Future Rave.” He then used another generative AI
website that recreated Eminem’s voice. Finally, he combined the words
in Eminem’s voice with some music. The Instagram clip ends with
Guetta talking about the effect of his “creation” on the audience: “People

* Corresponding author: 1090 Eddy St. Atp. 403 San Francisco, CA, USA
E-mail address: pjurcys@gmail.com (P. Jurcys).
1
See <https://www.instagram.com/p/CoNqQuFqIHZ/> accessed 12 February 2023.
2
Ibid.

https://doi.org/10.1016/j.clsr.2023.105892
Available online 10 October 2023
0267-3649/© 2023 Published by Elsevier Ltd.

M. Fenwick and P. Jurcys

Computer Law & Security Review: The International Journal of Technology Law and Practice 51 (2023) 105892

went nuts.”
Several commentators observed that this was not the first time
Guetta paid tribute to Eminem – in 2019, he played Eminem’s “Lose
Yourself” at the MDL Beast Festival.3 But on that occasion, and in
contrast to his later usage, he played Eminem’s original music (and
voice).4 However, soon after making the initial Instagram post, Guetta
gave an interview where he explained that he would not release the mix
publicly because of his respect for Eminem and the ambiguous legal
framework concerning copyright entitlements.5 In another interview to
BBC, he stated that, “I’m sure the future of music is in AI. For sure.
There’s no doubt. But as a tool. … Nothing is going to replace taste.
What defines an artist is, you have a certain taste, you have a certain
type of emotion you want to express, and you’re going to use all the
modern instruments to do that.”6
The emergence and proliferation of generative AI technologies in the
first half of 2023 spurred a huge global debate among lawyers, policy­
makers, and technologists, as well as the general public.7 The rapid
development of generative AI even caused waves of public outcry and
calls to halt the development of AI for several months or at least until
some legal, technological, and ethical guardrails are established.8
However, since many generative AI tools are open source, technology
entrepreneurs rushed to embrace the new wave of innovation and start
building specific solutions for diverse use cases across enterprise and
consumer settings.9

From a copyright law and regulatory perspective, generative AI
technologies raise important questions around four main areas. The first
area of uncertainty relates to the legality of data scraping and using
publicly available information (including content that is both protected
by copyright laws and content in the public domain) to train machine
learning and AI models.10 Here, the question arises whether the scraping
of data done by machines should be treated differently from the retrieval
of the same information by humans.11 Should permissions to use or
licenses be obtained by entities that are scraping data for machine
learning purposes?12 Should the use of data scraped from the Internet be
deemed to be a copyright infringement and thus not permissible?13 In
common law jurisdictions, for instance, one of the main issues is
whether data scraping for machine learning models could be justified
under the copyright law doctrine of fair use.14 Then there are questions
about remuneration.15
The second major area of controversy surrounding generative AI
technologies relates to data privacy and image rights issues. What if the
data scraped from the Internet contains some personal information of
individuals?16 Could such data be used to train machine learning
models? And which laws should be applied to such activities? The law of
the state where the allegedly infringing AI company is based or is
operating? Or the law of the place where individuals’ personal infor­
mation is being used? Or some other country’s law? Can anyone create
chatbots and avatars representing celebrities’ and influencers’ person­
alities and use the likeness to offer certain commercial products (e.g., a
virtual representation of a notorious figure who acts as my shopping
assistant)?17 Furthermore, there seems to be no legal framework that
would govern the interaction between multiple AI systems and agents

3
See, eg, ‘David Guetta plays Eminem’s “Lose Yourself”’ (Southpawers, 5
February 2023) <https://southpawers.com/2023/02/05/david-guetta-emine
m-ai/> accessed 12 February 2023.
4
Southpawers, ‘MDL Beast Fest 2019’ <https://www.youtube.com/watch?
v=BTA6LmwhNYk&t = 2s> accessed 12 February 2023.
5
Sam Roche, ‘David Guetta: “If you have terrible taste, your music is still
gonna be terrible, even with AI”’ (MusicTech, 24 July 2023) <https://musictech
.com/news/david-guetta-on-ai/> accessed 30 August 2023.
6
‘David Guetta says the future of music is in AI’ (BBC, 13 February 2023)
<https://www.bbc.com/news/entertainment-arts-64624525> accessed 30
August 2023.
7
See eg, Franklin Graves, ‘Accelerated Innovation: In Less Than a Year,
We’ve Seen a Decade’s Worth of AI and IP Developments’ (IP Watchdog, 13
August 2023) <https://ipwatchdog.com/2023/08/13/accelerated-innovation
-less-year-weve-seen-decades-worth-ai-ip-developments/id=164842/>
accessed 29 August 2023; ‘Secretary-General Urges Security Council to Ensure
Transparency, Accountability, Oversight, in First Debate on Artificial Intelli­
gence’ (United Nations, 18 July 2023) <https://press.un.org/en/2023/sgsm2
1880.doc.htm> accessed 30 August 2023; Gideon Lichfield & Lauren Goode,
‘The World Isn’t Ready for the Next Decade of AI’ (Wired, 16 August 2023)
<https://www.wired.com/story/have-a-nice-future-podcast-18/> accessed 30
August 2023; Colleen Walsh, ‘How to think about AI: Delving into the legal and
ethical challenges of a game-changing technology’ (Harvard Law Bulletin,
Summer
2023)
<https://hls.harvard.edu/today/how-to-think-about-ai/>
accessed 29 August 2023.
8
The Future of Life Institute, ‘Pause Giant AI Experiments: An Open Letter’
<https://futureoflife.org/open-letter/pause-giant-ai-experiments/> accessed
29 August 2023; Mustafa Suleyman a& Michael Bhaskar, The Coming Wave
(Crown 2023); Ben Tarnoff, ‘Weizenbaum’s nightmares: how the inventor of the
first chatbot turned against AI’ (The Guardian, 25 July 2023) <https://www.th
eguardian.com/technology/2023/jul/25/joseph-weizenbaum-inventor-eliza-ch
atbot-turned-against-artificial-intelligence-ai?CMP=Share_iOSApp_Other>
accessed 29 August 2023.
9
Sam Altman: ‘The reason people love this stuff [AI] is because it’s providing
real utility. And that doesn’t come along too often.’ See ‘A conversation with
OpenAI CEO Sam Altman’ (YouTube, 18 May 2023) <https://www.youtube.
com/clip/UgkxNvSNAau93YdpBGWEe9rUGyhajFfi9jsb> accessed 30 August
2023. It is expected that by the end of 2023, there will be appr. 12,000 startups
working on AI projects. see For an updated list of such AI solutions, see:
<https://theresanaiforthat.com/> accessed 30 August 2023. David G Widder,
Sarah West & Meredith Whittaker, ‘Open (For Business): Big Tech, Concen­
trated Power, and the Political Economy of Open AI’(2023) <https://papers.ss
rn.com/sol3/papers.cfm?abstract_id=4543807> accessed 30 August 2023.

10
‘AI is setting off a great scramble for data’ (Economist, 13 August 2023)
<https://www.economist.com/business/2023/08/13/ai-is-setting-off-a-great-s
cramble-for-data> accessed 29 August 2023.
11
Mark A Lemley & Bryan Case, ‘Fair Learning’ (2021) 99 Tex L Rev 743
12
Sharon Goldman, ‘Generative AI datasets could face a reckoning’ (Venture
Beat, 21 August 2023) <https://venturebeat.com/ai/generative-ai-datasets-c
ould-face-a-reckoning-the-ai-beat/> accessed 29 August 2023.
13
See Kali Hays, ‘OpenAI now tries to hide that ChatGPT was trained on
copyrighted books, including J.K. Rowling’s Harry Potter series’ (Business In­
sider, 15 August 2023) <https://www.businessinsider.com/openais-latest-ch
atgpt-version-hides-training-on-copyrighted-material-2023-8>
29
August
2023; Winston Cho, ‘Scraping or Stealing? A Legal Reckoning Over AI Looms’
(Hollywood Reporter, 22 August 2023) <https://www-hollywoodreporter-com.
cdn.ampproject.org/c/s/www.hollywoodreporter.com/business/business-new
s/ai-scraping-stealing-copyright-law-1235571501/amp/> accessed 29 August
2023.
14
Lemley & Case, supra n 11, 748; Peter Henderson, Xuechen Li, Dan
Jurafsky, Tatsunori Hashimoto, Mark A. Lemley, Percy Liang, ‘Foundation
Models and Fair Use’ (2023) <https://arxiv.org/abs/2303.15715> accessed 30
August 2023.
15
Martin Senftleben, ‘Generative AI and Author Remuneration’ <https
://papers.ssrn.com/sol3/papers.cfm?abstract_id=4478370>
accessed
30
August 2023; Miranda Nazzaro, ‘Diller confirms plans for legal action over AI
publishing’ (The Hill, 16 JUly 2023) <https://thehill.com/policy/technolog
y/4100533-diller-confirms-plans-for-legal-action-over-ai-publishing/>
accessed 30 August 2023.
16
Will Oremus, ‘Meet the hackers who are trying to make AI go rogue’
(Washington Post, 8 August 2023) <https://www.washingtonpost.com/tech
nology/2023/08/08/ai-red-team-defcon/> accessed 30 August 2023; ICO,
‘Joint statement on data scraping and data protection’ <https://ico.org.
uk/about-the-ico/media-centre/news-and-blogs/2023/08/joint-statement-on-d
ata-scraping-and-data-protection/> accessed 30 August 2023.
17
See <https://goshopwith.ai/chat> accessed 30 August 2023.

2

M. Fenwick and P. Jurcys

Computer Law & Security Review: The International Journal of Technology Law and Practice 51 (2023) 105892

with one another or third parties.18
The third area of legal uncertainty pertains to the large language
models themselves. Different stakeholders have called for greater
transparency in understanding what data is used to train large language
models, and the core technology takes on the character of a “black
box.”19 Much work from a technological, legal, and ethical perspective
needs to be done to get a better insight into how LLMs work and what
oversight mechanisms need to be in place.20
Finally, greater legal certainty is desirable with regard to the legality
of outputs generated by individuals utilizing generative AI tools. Do
such works created with generative AI tools meet the originality con­
dition for the protection of works under copyrightlaw?21 Who has what
rights to outputs generated with generative AI tools?22 In practice,
having (any) rights to the output generated with the help of AI tools is a
huge problem that will determine whether such works can be
commercialized. At the time of writing, one of the main reasons for
delays in the adoption of generative AI technologies by Fortune 1000
companies is uncertainty whether the outputs of machine learning
models are infringing or not.23 Then, there are questions about the
relationship between the training data and the outputs.24 Should the
attribution of the rights to the output generated by an artist depend on
what data was used to train the underlying model? Could output results
be considered to be “derivative works” (from a copyright law perspec­
tive) of the training data?25 If so, then there may be massive restrictions
on how those outputs might be used.

In this paper, we suggest that the Guetta example constitutes a
typical creative use case of generative AI in a contemporary context.
Such generative AI increasingly finds applications across every domain
of the creative industries.26 From composing music, drafting text,
writing software code and other technical documents rendering a room
with a particular design or filled with a specific style of furniture27 –
generative AI permeates every area of creative work and defines digital
culture, more generally.
Judging by the initial reaction to recent developments in generative
AI, the initial response seemed to be, at best, one of anxiety and, at
worst, outright horror.28 There are widespread concerns that these
trends will result in machines taking over many aspects of work or
worries about the capacity of the existing regulatory framework to deal
with these unprecedented creative forms.29 These developments
certainly raise some interesting and important legal and philosophical
questions about the meaning of creativity and the value of works created
by individuals using generative AI tools. Are such works genuinely
creative and original? What – if anything – is their value to society? How
can we determine if such creations should be protected as creative works
under copyright law? If so, how much protection should be afforded to
such works created using generative AI tools? And, more dramatically,
does this mark a new phase in human history, and will AI tools soon
replace (or, in the doomsday account, eliminate) humans?30
Our intention here is to clarify one point about the degree and
character of human involvement and the legal implications of that
involvement. Firstly, and most obviously, it is essential to acknowledge
that there is no such thing as a purely AI-generated work,31 in the sense
that some degree of prompting, refinement, and approval is required.
Equally, some works with minimal human prompting are not of high
value; therefore, copyright should be thin.32 However, this recognition
of the human/author in the loop has important implications. Most
obviously, it chimes with the enterprise discourse around such products

18
Joon Sung Park, et al, ‘Generative Agents: Interactive Simulacra of Human
Behavior’ (2023) <https://arxiv.org/abs/2304.03442> accessed 30 August
2023; Quingyun Yu, et al., ‘AutoGen: Enabling Next-Gen LLM Applications via
Multi-Agent Conversation Framework’ <https://arxiv.org/pdf/2308.08155.
pdf> accessed 30 August 2023; Aneesh Tickoo, ‘Google DeepMind and the
University of Tokyo Researchers Introduce WebAgent: An LLM-Driven Agent
that can Complete the Tasks on Real Websites Following Natural Language
Instructions’ (Markettechpost, 29 July 2023) <https://rb.gy/qs5cv> accessed
30 August 2023; in August 2023, Andreesen Horowitz launched “AI-town”, a JS
starter kit for customizing your own “AI simulation” where AI characters live,
chat and socialize: <https://github.com/a16z-infra/AI-town> accessed 30
August 2023.
19
Carol Mullin Hayes, ‘Generative Artificial Intelligence and Copyright: Both
Sides of the Black Box’ <https://papers.ssrn.com/sol3/papers.cfm?abstrac
t_id=4517799> accessed 30 August 2023.
20
‘Biden-Harris Administration Announces New Actions to Promote Respon­
sible AI Innovation that Protects Americans’ Rights and Safety’ <https://www.
whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-bi
den-harris-administration-announces-new-actions-to-promote-responsibleai-innovation-that-protects-americans-rights-and-safety/> accessed 30 August
2023.
21
Vincenzo Iaia, ‘To Be, or Not to Be … Original Under Copyright Law, That Is
(One of) the Main Questions Concerning AI-Produced Works’ (2022) 71 GRUR
Int 793.
22
See e.g., Dan L Burk, ‘Thirty-Six Views of Copyright Authorship, by Jackson
Pollock’ (2020) 58 Hous L Rev 263, 266; Ryan Benjamin & Elizabeth Rothman,
‘Disrupting Creativity: Copyright Law in the Age of Generative Artificial Intel­
ligence’ Fla L Rev (forthcoming) <https://papers.ssrn.com/sol3/papers.cfm?
abstract_id=4185327> accessed 29 August 2023; See e.g., David Newhoff, ‘AI
Machine Learning: Remedies Other Than Copyright Law?’ <https://illu
sionofmore.com/ai-machine-learning-remedies-other-than-copyright-law/>
accessed 30 August 2023.
23
Paulius Jurcys, ‘Event Recap: Augmenting Consumer Experiences in the Age
of Data & AI’ <https://www.prifina.com/blog/event-recap-augmenting-cons
umer-experiences-in-the-age-of-data-ai> accessed 29 August 2023.
24
See eg, Matt Growcoot, ‘Stability AI Boss Admits to Using ‘Billions’ of Im­
ages Without Consent’ (Petapixel, 13 July 2023) <https://petapixel.com/2023/
07/13/stability-ai-boss-admits-to-using-billions-of-images-without-consent/>
accessed 29 August 2023.
25
Daniel J Gervais, ‘AI Derivatives: the Application to the Derivative Work
Right to Literary and Artistic Productions of AI Machines’ (2002) 53 Seton Hall
L Rev 1.

26
For a general overview see Sonya Huang, Pat Grady and GPT-3, ‘Generative
AI: A Creative New World’ <https://www.sequoiacap.com/article/generati
ve-ai-a-creative-new-world/> (Sequoia, 19 September 2022) accessed 12
February 2023; for the investment landscape, see ‘The state of generative AI in
7 charts’ (CB Insights, 25 January 2023) <https://www.cbinsights.com/resea
rch/generative-ai-funding-top-startups-investors/> accessed 12 February 2023.
27
See eg, <https://interiorai.com/> accessed 12 February 2023; Mark WIl­
son, ‘OpenAI’s first acquisition is an AI design company’ (Fast Company, 17
August 2023) <https://www.fastcompany.com/90940634/openais-first-ac
quisition-is-an-ai-design-company> accessed 29 August 2023.
28
‘Expert AI as a Healthcare Superpower’ (A16z Podcast, 10 January 2023)
<https://rb.gy/lcayeo> accessed 12 February 2023; Gerard Baker, ‘Is There
Anything ChatGPT’s AI ‘Kant’ Do?’ (The Wall Street Journal, 13 February 2022)
<https://rb.gy/hlbqpx> accessed 12 February 2023; Hugh Stephens, ‘AI and
Computer-Generated Art: Its Impact on Artists and Copyright’ (Hugh Stephens
Blog, 25 October 2022), <https://rb.gy/srndpb> accessed 12 February 2023;
Stephen L Carter, ‘Can ChatGPT Write a Better Novel Than I Can? (Bloomberg,
11 February 2023) <https://rb.gy/pnbrvx> accessed 13 February 2023.
29
See e.g., Andy Kessler, ‘AI’s Growing Legal Troubles’ (The Wall Street
Journal, 30 July 2023) <https://www.wsj.com/articles/ais-growing-legal-trou
bles-section-230-publisher-class-action-9efaf374> accessed 29 August 2023.
30
See eg, Allison Whitten, ‘Me, Myself, and AI’ (Stanford Magazine, July 2023)
<https://stanfordmag.org/contents/me-myself-and-ai?sf179987774=1>
accessed 29 August 2023; Shana Lynch, ‘Will Generative AI Make You More
Productive at Work? Yes, But Only If You’re Not Already Great at Your Job’
<https://stanfordmag.org/contents/me-myself-and-ai?sf179987774=1>
accessed 29 August 2023.
31
See eg, Emmanuel Salami, ‘AI-Generated Works and Copyright Law: To­
wards a Union of Strange Bedfellows’ (2020) 16 J Intell Prop L & Prac 124.
32
Here, it is important to note the concept coined by Rochelle C Dreyfuss, “if
value then right” in her seminal article ‘Expressive Genericity: Trademarks as
Language in the Pepsi Generation’ (1990) 65 Notre Dame L Rev 397, 405; for
the applicability of this idea to works created with generative AI tools, see
Lemley, supra n 61, 12-13.

3

M. Fenwick and P. Jurcys

Computer Law & Security Review: The International Journal of Technology Law and Practice 51 (2023) 105892

and systems, which frequently uses terms like co-piloting, co-creation,
or companions to capture this dynamic element of prompting, editing,
remixing, and approval in creating a final output.
In thinking about the legal implications of this recognition of the
human/author in the loop, we focus on one aspect of this issue, namely
the meaning of “originality” in a copyright law context and the capacity
of this concept as manifested in US federal law to accommodate the
Guetta case and generative AI. Originality is a concept frequently
referred to when talking about copyright, as it provides an important
means to differentiate works considered socially valuable and worthy of
copyright protection from those that lack this quality of originality. To
be clear, it is not our intention to defend the status quo but merely to
clarify the scope of copyright protections under contemporary condi­
tions, focusing on US federal copyright law.
We limit our current analysis to US federal copyright law for three
reasons: First, the United States (and the State of California in particular)
is the place where most of the leading generative AI companies are
headquartered.33 Second, the United States is the main source of venture
capital investments pouring into companies building AI technologies.34
Finally, the fact that all of the major copyright lawsuits concerning
generative AI are filed before US courts warrants the focus of this paper
on the US copyright framework.35
In this paper, we focus on the originality requirement; other issues –
e.g., the legality of using publicly available data to train large language
models, whether and how fair use might factor into this discussion36 –
are only briefly addressed in Section 5, which deals with broader issues
that surround the debate on the issue of originality. Our reason for
narrowing the scope and focusing on originality is motivated by our
observation of several misconceptions about the degree of human
involvement in the creative process where AI tools are used and how this
issue is approached in the increasingly heated public debates.
For this reason, we begin our analysis in Section 2 by characterising
the creative process when artists like David Guetta rely on generative AI
tools in their creative processes. We offer a comparative illustration by
contrasting these AI tools with a more traditional form of creation, such
as painting a picture or writing a novel. This will highlight some of the
distinctive features of creation in an age of generative AI. The question
we then pose is whether the creative process with AI tools is any
different from creativity where “traditional” creative tools are involved
and whether this form of creation where generative AI tools are used
represents something new. Our answer is that it does, but we need to be
careful and precise in our characterisation of exactly what constitutes
“newness” in the context of generative AI.
Section 3 turns to a brief discussion of extant copyright law in the
United States. Two foundational distinctions – first, between ideas
(which should remain free and not protected by copyright) and ex­
pressions (which can be subject to copyright protection) and second, the
standard legal requirements of originality as a tool to differentiate works
deserving of copyright protection – are introduced. The concept of
originality will help us better address the “copyrightability” of works

Fig. 1. The creative process in an age of generative AI.

created using generative AI tools. This issue is addressed in Section 4.
Section 5 explores how the human-in-the-loop concept connects with
the broader discussion about the copyrightability of works created by
human authors using generative AI tools and whether the assessment of
originality of such works should include the lawfulness of the use of data
for the training of the underlying large language models. Finally, Sec­
tion 6 concludes.
Finally, we recognise that generative AI raises several other ques­
tions. For example, whether it makes a difference where works are
created by humans or AI, and what are the interests of other participants
in the ecosystem (e.g., an author who is upset that other people use
generative AI tools the create “in the style of” the author), the justifi­
cation of copyright, or the use of copyrighted material in machine
learning models. These questions were not the subject of this paper and
should be explored separately, as they are important.
2. A new model of creativity, or old wine in new bottles?
In the following, we aim to demystify what happens during the
creative process, and we suggest that a “black box” approach that
minimizes human involvement in AI-generated work is inadequate. To
illustrate our point, we will rely on the example of David Guetta intro­
duced at the beginning of this article. We first describe the process that
characterises Guetta’s usage of generative AI. Our suggestion is that his
creative process is typical and a representative use case of generative AI.
In elaborating this account, a contrast is made with a more typical case
of creation, namely, an artist painting a picture. This comparison will
allow a more precise clarification of the distinctiveness of creation in a
world of generative AI and – crucially – a better understanding of the
role of technology and a broader network of actors – legal, as well as
natural persons – in all creation, but especially in a contemporary
context.
Five steps of David Guetta’s usage of technology should be noted (see
Fig. 1).37 Based on some concept of what he wanted to achieve (an
iteration of FR music featuring the lyrics in the style of and the voice of
Eminem); Guetta prompted the AI with a request to create a few lines of
lyrics in the style of Eminem. Then, the AI – a piece of software utilising
machine learning produced by a third party or parties – generated the
requested text material and delivered the results back to Guetta. Another
prompt was similarly used with a different AI system to generate the
voice. Guetta refined the version of the piece by re-prompting, regenerating, editing, compiling, and integrating the results generated by
the two different “AIs” with music creating an output, which – finally –
was deployed in his DJ set.
A premise of the discussion is that this process of conception,
prompting, generation, refining, and deployment characterises the creative

33
42 out of 50 top AI companies are located in the US (35 in California), Ryan
Heath, ‘AI boom’s big winners are all in four states’ <https://www.axios.com/
2023/07/24/ai-goldrush-concentrated-4-states> accessed 29 August 2023.
34
Kyle Wiggers, ‘VCs continue to pour dollars into generative AI’ (TechCrunch,
28 March 2023) <https://techcrunch.com/2023/03/28/generative-ai-venturecapital/> accessed 29 August 2023; Anna Cooban, ‘AI investment is booming.
How much is hype?’ (CNN Business, 23 July 2023) <https://www.cnn.com/202
3/07/23/business/ai-vc-investment-dot-com-bubble/index.html> accessed 29
August 2023.
35
See eg, PM v. OpenAI LP, ND Cal, No 3:23-cv-03199 (complaint filed 28
June 2023); Tremblay v. OpenAI Inc., ND Cal, No 3:23-cv-03223 (complaint
filed 28 June 2023); for up-to-date status of the Github Copilot litigation, see
<https://githubcopilotlitigation.com/> accessed 30 August 2023; Getty Images,
Inc v Stability AI, DC Del., No. 1:23-cv-00135 (complaint filed 3 February 2023)
36
See Lemley & Casey, supra n 11, 743.

37

Other scholars have also tried to visualise the human-machine interactions
in the creative process, see Jane C Ginsburg & Luke A Budiardjo, ‘Authors and
Machines’ (2019) 34 Berkeley Tech L J 343 and P Bernt Hugenholtz and João
Pedro Quintais, ‘Copyright and Artificial Creation: Does EU Copyright Law
Protect AI-Assisted Output?’ (2021) 52 IIC 1190.
4

M. Fenwick and P. Jurcys

Computer Law & Security Review: The International Journal of Technology Law and Practice 51 (2023) 105892

Fig. 2. Mapping creativity in the two use cases.

instruction, i.e., an input of some kind39 (in this case, “Write a verse
in the style of Eminem about the Future Rave).” This instruction was
a self-conscious and deliberative choice on the part of a human
creator aiming to materialise their concept. This second step does
appear to be novel – there is nothing equivalent or comparable in the
artist’s case, even if certain aspects or conditions of prompting –
engaging in some sort of background or preliminary research, for
example – may be part of more traditional modes of creativity.
• Generation. The act of generation, in itself, is obviously not new –
the painter paints, after all – and generating something would seem
to be a necessary condition of all creative activity. Moreover – and
this may be a slightly more contentious observation – the reliance on
technology is not new either. A painter depends on simpler tech­
nology – brushes, paints, and paper – but some technology and by
extension the producers of that technology are implicated in all
creative processes and content generation. In an important sense,
therefore, all creativity is a co-creation of human and machine and
implicates the involvement of third parties. As such, technologies can
be thought of as actors in the creative process, not in the sense that
they take action, but in that they facilitate action and put action in

use of generative AI. There are several aspects of this creative process
that we would emphasise:
• Conception. Guetta started with an idea and knew what he wanted –
Eminem-style lyrics and voices accompanying energetic four-to-thefloor FR – although he did not know, specifically, what he would get
from the AI. He had a vision when he started, but he was not working
with or from a fixed plan or script – i.e., he didn’t know, precisely,
where he was going. This is nothing new – all artists, our painter for
example, presumably start the creative process with a similar vision
or conception, however, minimal of what it is they are trying to
achieve in a particular instantiation of the creative process, even if
they don’t always have a fixed conception of what it is they want to
create.38 In a creative context, intentions are important but
malleable and incomplete and contingent upon context, especially
previous works by dominant figures in the genre and tradition, as
well as related genres and traditions.
• Prompting. Crucially, generative AI is not – for the moment, at least –
acting independently, in the sense that it requires external

39
See comment by Sam Altman at the 2023 Bloomberg Technology Summit:
“[t]here is this sci-fi idea that those [AI] systems can better address themselves,
can discover new architectures, can write new code. I think we are miles away
from that; but it’s worth paying attention to.” ‘OpenAI CEO Sam Altman on the
Future of AI’ available at: <https://www.bloomberg.com/news/videos/202306-22/openai-ceo-sam-altman-on-the-future-of-ai> accessed 30 August 2023.

38

See the comments of Davey Whitcraft, who stated that he “use[s] generative
AI tools to experiment push forward the boundaries of human creativity.”
Paulius Jurcys, ‘Creativity in the Age of AI’ (YouTube, 15 May 2023)
<https://www.youtube.com/watch?v=9qoY19B6MJk> accessed 30 August
2023.
5

M. Fenwick and P. Jurcys

Computer Law & Security Review: The International Journal of Technology Law and Practice 51 (2023) 105892

motion and “make a difference in another agent’s action.”40 In the
context of his work on scientific invention, the French sociologist,
Bruno Latour, talked of the need for a “flat ontology” in which we
don’t artificially over-emphasise the role of human beings in human
activities (such “purification” is what he thought of as the arrogance
of modernity) but rather see creativity as an effect of “networks” of
human and machines. However, what is certainly distinctive in the
Guetta case is the (nearly) complete delegation of the act of gener­
ation to a third party or parties (the generative AI software). The
content that generative AI tools create depends on the prompts
provided by the human author: the human author provides in­
structions and tasks for the generative AI assistant to deliver an
iteration of the ideas that the human author is prompted to explore.
And even though what the AI created or gave back to Guetta in its
unedited form was not simply a copy of anything that already existed
but something genuinely new and unique and that didn’t exist
before, such generated output is molded and shaped by initial
prompts provided by a human author. The generated content is in
some obvious sense new, even if the act of creating the lyrics and the
voice, the AI software relied on enormous quantities of data accu­
mulated, typically, off the Internet. However, it is important to note
that generation happens as a response to the prompting of the human
author, David Guetta, looking to manifest a specific vision.
• Refining. Once he received the generated content, Guetta edited the
received content and integrated it with some music. In this respect,
refining is not simply the editing of a human-created text/picture (i.
e., part of a process generation) but a distinctive stage of working
with something given back to the creator by the third-party gener­
ative AI. In this respect, it does differ from our artist. Refining, in the
sense used here, includes a broad spectrum of activities ranging from
a crude copy-pasting (e.g., a lazy, dishonest student using ChatGPT
to “write” their report) to a more sophisticated bundle of processes,
including curation, collation, compilation, and assemblage. It also
may involve re-visiting the prompting and generation stages, and the
simple sequential model introduced above may become a more dynamic,
cyclical, and iterative process of ongoing prompting, generating, and
filtering. We don’t know exactly, based on the Instagram post, how
this worked in the Guetta case, i.e., whether he relied on the first
versions produced by the AI, but the general point about the possi­
bility and centrality of refining still stands. And this seems particu­
larly relevant in the context of recent generative AI (ChatGPT, for
instance) where the AI remembers the context from an earlier phase
of the interaction. This is a recent feature and might be thought of as
refining-by-design, i.e., refining is a core feature built into the
operation of the technology that allows the AI to improve its per­
formance over time based on a process of iteration and learning.41 The
final, approved result of refining is what we would call output. Think
of it as the created piece of music in the Guetta case.
• Deployment. When, where, and how the output material is used is
subject to a high degree of external (i.e., human) influence. The
generative AI, for the moment, cannot determine when, where, and
how its creations will be used. This points to a more general feature
of the current state of this technology, namely that it has no under­
standing of what it is creating or doing and lacks the quality of selfconsciousness or individual autonomy. Again, however, the act of
deployment is nothing new, and creators – including our artist – have
always exerted some degree of autonomous control over whether
and how their works are first published, disseminated, and used,
even if that control was never total (intermediaries, such as critics

and galleries in the case of painting, play a crucial role, for instance)
and non-sanctioned uses frequently occur, hence the need for IP
protection.
The results of the comparison are illustrated in Fig. 2. The different
actors and technologies that they utilise are added. Think of these two
graphics as illustrations of the network of “actors” – understood in the
broad sense of human, corporate and machine actors – that constitute a
creative work in any given case.
What becomes clear from the above is that the sophistication of the
technologies and the network of actors (human, corporate and machine)
is broader and more complex in the case of David Guetta. The degree of
involvement of third parties in the generative moment (the AI software
developer and the data they rely on) does, therefore, seem different from
the painting example. We can question whether the creator has the same
role in the creative process. But again, this appears to be a question of
degree rather than a qualitative difference. All of this is simply to say
that modern Romantic notions of creativity as purely human-generated
involving creation ex nihilo need to be replaced by a vision of creativity
as the multi-staged effects of complex networks of human, corporate,
and machine (both software and hardware) “actors.” The Romantic
fiction of the lone genius creator is a fantasy that retroactively obscures
the cultural and technological tradition implicated in all creative works.
And this observation is certainly not meant to denigrate the role of
creators as they play an essential role in driving a tradition forward in
new and unexpected ways through their novel use of technology and reimagining of tradition. Rather, our point is to suggest that the imposition
of constraints upon such creative re-imagining of a tradition and use of
technology should be minimised and only introduced when there is a
compelling justification.
3. Assessing originality in modern US copyright law
Having described the model of creativity in the Guetta case, we now
turn to copyright. This section briefly introduces the two requirements
that form the basis of the “originality” test in modern copyright law, at
least in a US context. We start with the fundamental idea/expression
distinction (Section 3.1.) and then explore how the US courts have
interpreted the twin elements of the “originality” test (Section 3.2.).
Section 4 then analyses the originality of Guetta’s composition as
characterised in Section 2 above using this framework.
3.1. A tangible medium of expression
One of the foundational principles of modern copyright law is that
ideas are not protected by copyright law and that only expressions can
be copyrighted. In the US, for example, the Copyright Act provides that
copyright protection does not extend “to any idea, procedure, process,
system, method of operation, concept, principle, or discovery.”42 In
other words, ideas and facts are not protected by copyright law; only the
way in which an author expresses ideas or facts can be protected.43 This
decision that ideas receive no protection, which is now codified in
Federal Law, was settled in the 1879 case, Baker v. Selden. The plaintiff’s
book describing a method of accounting was not protected, because “[w]
here the truths of a science or the methods of an art are the common
property of the whole world, any author has the right to express the one,
or explain and use the other, in his own way” (our emphasis).44
There are three main reasons for this. The first is pragmatic and
evidential: How can we establish who had what ideas when? Without any

40

42

Bruno Latour, Reassembling the Social: An Introduction to Actor-Network
Theory (OUP 2005) 72.
41
See Ari Seff, ‘How ChatGPT is Trained’ (YouTube, 25 January 2023)
<https://www.youtube.com/watch?v=VPRSBzXzavo> accessed 13 February
2023.

17 US Code § 102(b). See also Pamela Samuelson, ‘Why Copyright Law
Excludes Systems and Processes from the Scope of Its Protection’ (2007) 85 Tex
L Rev 1921.
43
Nichols v Universal Pictures Corp, 45 F2d 119 (2d Cir 1930).
44
Baker v Selden, 101 US 99 (1879).
6

M. Fenwick and P. Jurcys

Computer Law & Security Review: The International Journal of Technology Law and Practice 51 (2023) 105892

tangible evidence expressed in tangible form (e.g., paint, paper, vinyl), it
is impossible to say that Person A had the idea independently from
Person B.45 This means that if there is a dispute between people accusing
each other of stealing each other’s ideas, it is practically impossible to
determine the fact of copying without any tangible evidence, i.e., the
administrative costs of resolving such disputes are prohibitively high.
Furthermore, the emphasis on the function of the fixation (i.e., that the
can be perceived or retrieved) rather than on form (e.g., on paper, on
canvas, in writing) was to ascertain that the rights of authors are unaf­
fected by the advancements in technology that could not have been
anticipated by the legislator.46
A second reason that ideas do not enjoy copyright protection is the
notion that limiting the use of ideas would have an inhibiting effect on
scientific development and progress. This notion can be found in Article
I Section 8 of the US Constitution, for example.47
A third reason for excluding ideas from copyright protection con­
cerns freedom of speech. In the Eldred case, for example, the United
States Supreme Court suggested that the idea/expression distinction is
necessary to reconcile copyright law with the principle of freedom of
speech embodied in the First Amendment of the Constitution.48

Image 1. . The easter bunny cake52.

publishing telephone directories where Rural accused another company
of copying Rural’s white pages without permission. The Court held that
a “sufficient amount of originality” is required for works eligible for
copyright protection. In applying this test, the Court held that the mere
arrangement of publicly known facts in alphabetical order is not creative
– i.e., anyone could have done it.
So how do we explain the “modest creativity” required for works to
be subject to copyright protection? The Feist case could be a good
starting point to reverse engineer the definition of “originality.” To be
considered as “original,” the work must contain something more than a
mere collection of real-world facts. According to Feist, spending some
time to arrange such facts in some obvious fashion (e.g., writing names
of town residents alphabetically) does not meet the threshold of “modest
creativity”; there must be something more that emanates from a person.
Besides, whether a work is modestly creative is a question of fact in
every single case, and it is for lawyers or judges to decide based on
circumstances of the case at hand. As long as the work is the result of
some creative endeavour by a human being, it will be deemed “modestly
creative” and thus original under the US copyright law.
It should be noted – and emphasised – that the originality threshold
of US copyright law is very low. Basically, according to Feist, anything
that rises above the threshold of facts, formulas, and natural discoveries
and can be attributed to an individual’s creative expression can be
protected by copyright. (This paper does not address the theories that
might expand our understanding of why copyright exists).
Originality does not, therefore, require the author’s intent to be
original.51 How come? Let’s discuss a couple of examples. Imagine you
are trying to bake a cake, but something in the process goes hilariously
wrong. One example could be a failed Easter Bunny case that was
photographed at one of the major US grocery chains Safeway and later
appeared on Cakewrecks.com website (Image 1).
Looking at this photo, we may wonder: Did the creator intend to
make such an odd-looking cake? One presumes not. What if the baker
had an idea or concept of a “perfect” Easter Bunny cake but failed to
materialise her vision? Would this cake still be considered original?
US courts generally agree that the author’s intent to be original is
irrelevant in deciding whether the work should be copyrightable. Instead,
it is important to look at the outcome of the author’s activity. Copyright
protection is available to works that are sufficiently distinguishable
regardless of whether an author tries to create something of her own. The
Easter Bunny cake shown above is unique in its appearance – clearly, it is
one of a kind. Also, very few people would be able to bake such a version of
an Easter Bunny. Thus, it is going to be considered as original. There may be

3.2. The originality test
To be protected under copyright law in the United States, a work also
must be original. The originality of a work is determined by considering
two factors. First, the author must create the work independently. This
means that if two people create an identical work (let’s say they write an
identical verse or draw an identical image of a cat), each of their works can
be protected under copyright even though they are completely identical. As
long as the author creates their works separately, the US courts will
consider it sufficient to meet the requirement of independent creation.49
The second element of originality is that a work must be somewhat
creative. This is also known as the “modest creativity” requirement. The
US Copyright Act clearly states that copyright protection “does not
extend to any idea, procedure, process, system, method of operation,
concept, principle, or discovery” (S. 17 USC 102(b)). In other words,
naturally occurring events, real-world facts, and mathematical formulas
are considered matters of the physical world. Therefore, if an author
writes down something that is considered factual, such content will not
be considered original.
Probably the most well-known illustration of the “modest creativity”
test could be drawn from the Feist case decided by the US Supreme Court
in 1991.50 In this case, a dispute arose between two companies
52
Luara Northrup, ‘Safeway Doesn’t Want You Photographing Their Terrible
Cakes For That Blog About Terrible Cakes’ (Consumerist, 13 November 2012).
<https://consumerist.com/2012/11/13/safeway-doesnt-want-you-photo
graphing-their-terrible-cakes-for-that-blog-about-terrible-cakes/> accessed 12
February 2023.
45
Nichols v Universal Pictures Corp, 45 F2d 119, 121 (2d Cir 1930).
46
Dan Hunter, Intellectual Property (OUP 2012) 35.
47
Art I S 8 of the US Constitution provides that the Congress has the power,
“To promote the Progress of Science and useful Arts, by securing for limited
Times to Authors and Inventors the exclusive Right to their respective Writings
and Discoveries.”
48
Eldred v Ashcroft, 537 US 186, 219-220 (2003) (‘[C]opyright law contains
built-in First Amendment accommodations. First, it distinguishes between ideas
and expression and makes only the latter eligible for copyright protection.’);
Golan v Holder, 565 US 302, 329 (2012). Critically, see Neil W Netanel, Copy­
right’s Paradox (2008) 4.
49
“To qualify for copyright protection, a work must be original to the author,”
which means that the work must be “independently created by the author” and
it must possess “at least some minimal degree of creativity.” Feist Publications,
Inc v Rural Telephone Service Company, Inc, 499 US 340 (1991) 345.
50
Feist Publications, Inc v Rural Telephone Service Company, Inc, 499 US 340
(1991).

51
See Compendium of the US Copyright Office Practices (Chapter 300), S
310.5 <https://www.copyright.gov/comp3/chap300/ch300-copyrightable-a
uthorship.pdf> accessed 12 February 2023.

7

M. Fenwick and P. Jurcys

Computer Law & Security Review: The International Journal of Technology Law and Practice 51 (2023) 105892

situations where a work is distinguishable from other similar works
because of the author’s bad eyesight, trembling muscles, or a shock caused
by a clap of thunder. If an author adopts the work as her own, the copyright
protection will, nevertheless, attach.53
How about those works that do not appear appealing to the eye?
Should copyright protect works we may find not pretty, ugly, or even
insulting? In the US and many other countries, copyright practice adopts
a principle of aesthetic neutrality which means that lawyers (i.e., at­
torneys, judges, or government agencies) should not stand in Judgment
as to whether works are beautiful and aesthetically pleasing or not.
Beauty is in the eye of the beholder, after all. The Easter Bunny cake will
be deemed to meet the threshold of minimum creativity, even if most
people find it distasteful or otherwise unattractive.
Finally, originality does not mean that the work must be new. You
can obtain copyright protection even if the work – let’s say a phrase – is
not new. If it is “modestly creative” (and we now know this threshold is
very low), then you can obtain the copyright in the work. The crucial
point here is the distinction of the terminology used when artistic works
are protected by copyright and technological inventions protected under
patent law. An invention can be patented only if the three requirements
of novelty, inventive step and practical utility are satisfied. To determine
whether an invention is new, patent examiners usually check all avail­
able databases and determine whether the invention is new: has anyone
already come up with this idea? Has this type of invention been patented
already? If patent examiners determine that the idea in the patent
application is “new”, then the invention can be protected by a patent
provided that two other requirements are satisfied.
As such, novelty is not required to benefit from copyright protection:
the work must simply be original. If the author creates something
independently, and it is not a literal copy of another work, such work can
be granted protection under copyright law.

be deemed original? Was this work created independently? Does the
composition meet the “minimum creativity” threshold? Should works be
considered original, and thus subject to copyright protection, when
created using generative AI tools such as Midjourney or ChatGPT? Let us
address the elements of originality in turn.
4.1. Independent creation
The question of whether a work is independently created most
frequently arises in copyright disputes where someone is accused of
copying a plaintiff’s work.55 It would then be up to the defendant to
prove that they created the work independently, without having seen or
heard the plaintiff’s work. If we simplify it, their argument would be, “I
created it on my own.” So, in David Guetta’s words, he would argue that
he was sitting alone in his studio and came up with the concept to try
and see what happens when he mixes Eminem’s rap with the AIgenerated music which we would get by adding the prompt “the
future of rave.” It is David Guetta and no one else who came up with the
prompts for the text and music.
One of the essential points of independent creation is that the work
emanates from a human being and that the work is created by a natural
person.56 However, and as emphasised above, people always use some
kinds of tools to achieve their desired results in the real world. Leonardo
da Vinci used a palette to paint the Mona Lisa. The baker of the Easter
Bunny used various ingredients, presumably a spoon, a spatula, and an
oven to (albeit ineffectually) bake the cake. Photographers and graphic
designers use Adobe Photoshop to edit their images. Typically, David
Guetta would use a computer, DAW software, software plugins, turn­
tables, and a collection of vinyl recordings to create music. But this time
he also used generative AI tools (ChatGPT and Uberduck) to create his
remix. That all seems totally normal and unproblematic.
When we talk about generative AI tools in their current phase of
adoption, it should be noted that prompts may need to be modified, clar­
ified, and adjusted many times to get usable and satisfying results. In a
generative AI environment, the content does not emerge from nowhere but
must be initiated by a person who types in a prompt or prompts, and then
possibly spends time improving the results by further modifying the
prompts as part of the process of refining.57 And just like in the baking of
the Easter Bunny cake example, it is up to each individual to choose which
combination of tools and ingredients to use and choose the colour of the
cake, so to speak. David Guetta would appear to have a strong case that the
prompts he used contributed to an “independent creation” and that the
“independent creation” element of the originality test is, therefore, met.
More generally, the question then arises of how the creative process
differs between using conventional tools (e.g., a brush) and generative
AI tools. Intuitively, we might assume that the creator has less control
over the final output when machine learning and data are used to
generate content. But it seems that the question here is more about the
degree of human involvement (as opposed to the input from the tech­
nology) in the creative process rather than any qualitative difference.
Again, a Romantic conception of creative ex nihilo may affect (distort)
our Judgment on this point, as it raises the threshold beyond the
traditional legal standard.
As observed in Section 2, it is important to avoid the over-simplistic
suggestion that with the emergence of generative AI, we are moving

4. The originality of works created with generative AI tools
Much ink has been spilled discussing how AI will change everything.
In the creative and legal domains, there are many discussions about
whether “AI-generated” works should be protected by copyright.54 Here,
we want to make a case that the existing framework, as laid out in
Section 3 is sufficiently durable to handle the mode of creativity
described in Section 2. Considering what we already know about
assessing the originality of works, can the composition of David Guetta
53
Opinion by Judge Jerome Frank in Alfred Bell & Co v Catalda Fine Arts, Inc,
191 F2d 99 (2d Cir 1951).
54
See eg, Yang Xiao, ‘Decoding Authorship, Is There Really no Place for an
Algorithmic Author Under Copyright Law?’ (2023) 54 IIC 5; Michael D Murray,
‘Generative and AI Authored Artworks and Copyright Law’ (2023) 43(1)
Hastings Comm & Ent L J 28; Begona Gonzalez Otero, ‘Machine Learning
Models Under the Copyright Microscope: Is EU Copyright Fit for Purpose?’
(2021) GRUR Int 1043; Yong Wang and Hongxuyang Lu, ‘Copyright protection
for AI-generated outputs: The experience from China’ (2021) 42 CLSR; Jane
Ginsburg, ‘People Not Machines: Authorship and What It Means in the Berne
Convention’ (2018) IIC 131; Giancarlo Frosio, ‘The Artificial Creatives: The Rise
of Combinatorial Creativity from Dall-E to GPT-3’ <https://papers.ssrn.com/s
ol3/papers.cfm?abstract_id=4350802> accessed 29 August 2023; Ryan
Abbott and Elizabeth Rothman, ‘Disrupting Creativity: Copyright Law in the
Age of Generative Artificial Intelligence’ <https://papers.ssrn.com/sol3/papers
.cfm?abstract_id=4185327> accessed 29 August 2023; Jon McCormack et al, ‘Is
Writing Prompts Really Making Art?’ <https://arxiv.org/abs/2301.13049>
accessed 23 February 2023; Jane C Ginsburg & Luke A Budiardjo, ‘Authors and
Machines’ (2019) 34 Berkeley Tech L J 343; Vicenç Feliú, ‘Our Brains Beguil’d:
Copyright Protection for AI Created Works’ (2021) USF Intell Prop & Tech L J
105; Carys Craig and Ian Kerr, ‘The Death of the AI Author’ (2021) OLR 35;
Daniel J Gervais, ‘The Protection Under International Copyright Law of Works
Created with or by Computers’ (1991) IIC 628; Pamela Samuelson, ‘The Future
of Software Protection: Allocating Ownership Rights in Computer-Generated
Works’ (1986) 47 U Pitt L Rev 1185.

55
This issue of independent creation is conceptualised as an affirmative
defence, see Feist, 499 US 340 (1991) 345-46.
56
Alfred Bell & Co v Catalda Fine Arts, Inc, 191 F2d 99, 102 (2d Cir 1951)
(“‘Original’ in reference to a copyrighted work means that the particular work
‘owes its origin’ to the ‘author.’”)
57
See comments by Davey Whitcraft who noted that creating truly amazing
works with generative AI tools requires much time (weeks, or months), Paulius
Jurcys, ‘Creativity in the Age of AI’ (YouTube, 15 May 2023) <https://www.
youtube.com/watch?v=9qoY19B6MJk> acccessed 30 August 2023.

8

M. Fenwick and P. Jurcys

Computer Law & Security Review: The International Journal of Technology Law and Practice 51 (2023) 105892

from a world of human-driven creation to a world of machine-driven
creation. Instead, our suggestion is that creation has always been the
product of human-machine hybrid forms of collaborative creation –
what we might characterise as a co-creation of a human author or authors
(in a case where there are multiple creators) and technology – and that
generative AI is merely the latest and most sophisticated iteration of
such a trend. Moreover, as highlighted in Section 2, multiple third
parties are implicated in any creative act in a contemporary context
where a wide and diverse range of companies produce the technologies
that are utilised by creators. The number and degree of involvement of
third-party actors involved is much greater in the Guetta case, for
example.
This point is particularly pertinent in the context of generative AI.
Machine learning and generative AI software of the kind used by David
Guetta relies on enormous quantities of data accumulated, typically, off
the Internet and which the third-party AI developer oftentimes does not
have any clear or obvious right to use. Certainly, they do not have the
permission of the original creators or owners of such data. Nevertheless,
generative AI completely depends on this dataset to produce anything of
value.58 However, as we further elaborate in Section 5.2., the determi­
nation of independent creation should not depend on the question of
whether the third-party developer of generative AI tools has used the
training data lawfully.

What do these principles covered by the “modest creativity” element
suggest in our analysis of the clip created by David Guetta with gener­
ative AI tools? If the author’s intentions do not matter, it probably means
that we do not need to analyse whether Guetta’s prompts were original
or creative; rather, we would probably need to focus on the question of
whether the final work meets this threshold of “minimum creativity.”
We would posit that the “Future Rave with Eminem” piece created by
Guetta clearly rises above a mere compilation of facts (the telephone
directory of Feist). Regardless of what Guetta had in mind or what his
intentions were when he started out, the output clearly and obviously
meets the threshold of being “somewhat creative.”
What about the fact that Guetta did not know what the result would
be at the concept stage of the creative process? Does this matter in
assessing originality? As highlighted with our Easter Bunny Cake
example, unexpectedly created works – be they successful and appealing
to the eye, or a disastrous blunder – can still be protected by copyright.
Following this line of reasoning, the fact that we cannot fully predict ex
ante what results the generative AI might deliver does not matter in
making a final assessment as to whether the work is “modestly creative”
or not.
One might also argue that such works are modestly creative because
they are created using tools that have not existed before. The second
element of the originality test means that the work merely possesses
some minimum level of creativity. What David Guetta has created using
generative AI tools is a piece of music that did not exist before. He
devised an original concept to combine Eminem’s voice with FR rave
music and reimagined what the future rave might look like. Yes, indeed,
he used AI tools to materialise his vision, but it was his idea to create this
kind of mix. He also used those AI tools himself and refined the results to
create a unique output that he deployed in his show. A new concept. An
iterative process of creation. New content, new beats, and the crowd
loved it!

4.2. Modest creativity
The element of “modest creativity” in determining the originality of a
work raises more intricate questions. How can we apply “modest crea­
tivity” in a generative AI context? At which point in the creative process
should we assess whether the “modest creativity” test is met? Should the
prompt itself be original, or should we look at the final version of the
work created using “generative AI” tools (what we characterised as the
output in Section 2)? It is not our intention to suggest that these can be
easily answered in all cases – and we would accept the Guetta case is a
relatively simple one. Moreover, harder cases may involve difficult
judgments about whether to offer protection at all or the form of pro­
tection and its amount. Nevertheless, courts are routinely confronted
with difficult and delicate questions of this kind, and we would
cautiously suggest that expert courts in concrete cases are well or, at
least, best placed to answer such questions.59 And even if the courts get
these decisions wrong from time to time, such a system seems preferable
to the imposition of a crude rule that limits the use of technologies and
stifles opportunities for creativity.
In Feist, for example, the US Supreme Court held that to benefit from
copyright protection, works have to rise above being mere facts of the
physical world. But as we discussed before, the threshold of “modest
creativity” is very low, at least under the US copyright law. Furthermore,
in assessing what is “modestly creative,” US courts only analyse the
outcome of the creative process, or the actual expression, that a person
came up with (not the author’s intention).

5. Copyright re-visited
When it comes to creative works, isn’t it always the case that artists
try to create something that gains the attention of a mass audience and
generates media interest? Writers dream of landing publishing contracts
with major publishers and making it to the New York Times bestseller
list. Visual artists aspire to create the next Mona Lisa. It is natural that
machine learning and generative AI tools make everyone excited
because they expand and share this feeling of being capable of creating
something unique and beautiful. And, from that perspective, don’t all
artists always aspire to create something truly original?
One of the key advantages of generative AI is that it accelerates the
process of creativity: rather than spending time in front of an empty
sheet of paper, we can now prompt AI to provide us with some initial
ideas and possible suggestions that provide impetus to the process of
creating.60 From that perspective, generative AI tools are appealing to
people working in creative industries. For individual users businesses,
generative helps save time and curtail the costs of production.61 People
who are worried that AI tools will replace humans should, perhaps,
worry less and learn how to use those tools to increase their own pro­
ductivity.62 Even if we don’t completely rely on such tools, they stim­
ulate creativity and – when combined with a process of refining – they
are opening new opportunities and possibilities.

58
For a discussion, see Jenny Quang, ‘Does Training AI Violate Copyright
Law?’ (2021) 36 Berkeley Tech L J 1401. Watermarking has been explored as a
possible solution to prevent copyright violations by ML models, see eg, Sofiane
Lounici, ‘Protect your machine learning models with watermarking’ (SAP, 8
November 2021) <https://blogs.sap.com/2021/11/08/protect-your-machine
-learning-models-with-watermarking/> accessed 23 February 2023 and ‘Pro­
tecting the Intellectual Property of AI with Watermarking’ (IBM, 20 July 2018)
<https://www.ibm.com/blogs/research/2018/07/ai-watermarking/>
accessed 23 February 2023.
59
Richard Lawler, ‘The US Copyright Office says you can’t copyright Mid­
journey AI-generated images’ (The Verge, 23 February 2023) <https://www.the
verge.com/2023/2/22/23611278/midjourney-ai-copyright-office-kristina-k
ashtanova> accessed 23 February 2023. For a critical analysis see also Van
Lindberg, ‘A mixed decision from the US Copyright Office’ (Process Mechanics,
22 February 2023).

60

Reid Hoffman, Impromptu: Amplifying Our Humanity Through AI (Dallepedia
2023) 18.
61
Ibid 110; Mark A Lemley, ‘How Generative AI Turns Copyright Upside
Down’
(2023)
<https://papers.ssrn.com/sol3/papers.cfm?abstrac
t_id=4517702>, accessed 29 August 2023 who discusses the concept of
“cheap creativity.”
62
See Hoffman, supra n 60, 49-50, who makes a comparison between creating
in the style of John Lennon, and asking how would John Lennon use this tool.
9

M. Fenwick and P. Jurcys

Computer Law & Security Review: The International Journal of Technology Law and Practice 51 (2023) 105892

to warrant such a historic introduction of disclosure requirements.66
Second, it may be questioned whether such disclosure requirements are
in line with the no formalities principle adopted in Article 5(2) Berne
Convention.67 Finally, not only contemporary copyright law is not well
designed to support a prompt-based system,68 it also seems like a
dangerous trend that misconceives the character of the creative process
in the case of generative AI.
In mass media publications, it is easy to catch the attention of wide
audiences with such and bold statements that certain legal institutions
do not meet the test of time and that technology moves faster than the
law. But this has always been the case, and laws and social norms are
constantly adjusted to meet the test of rapidly evolving technologies.
With regard to the issue of originality in copyright, we would pro­
pose a more modest approach against the quick and easy dismissal of
legal concepts that have evolved and stood the test of time. Looking back
at history, technology has always preceded the existing copyright laws
(think of the printing machine, the invention of cars, VCRs, live audio,
and video streaming).69 And, as we hopefully demonstrated here, the
two elements of originality developed by courts in solving real cases
prove to be helpful in approaching David Guetta’s music composition.
We would modestly suggest that they might also be helpful in other
cases where similar questions arise. We would concede that drawing a
bright line is hard and that – as mentioned already – it will require
difficult and delicate decisions. Nevertheless, this is preferable to the
alternative – denying protection completely – which risks throwing the
baby out with the bath water and placing the artists at the cutting edge
of creativity in a weak position.
And finally, the David Guetta story reveals something more general
about creativity in the digital age. Earlier – and influential – models of
creativity as purely human-driven and involving creation ex nihilo do
become harder to sustain in a new age of generative AI. The creator –
understood as an abstract or pure will operating independently of any
technology has always been a fantasy and never existed. Creation has
always been over-determined by a collaborative combination of humans
and machines. We need to be more attuned both to hybridity and the role
of the nonhuman in the constitution of creativity. Hybrid-networked (i.
e., human – corporate – machine) creators have always created hybrid –
networked cultural forms (i.e., creations that blend human and
technology-constituted elements). But – we would suggest – this hy­
bridity becomes increasingly visible and complex in the context of a
world of generative AI. Crucially, however, as we have suggested here,
this does not mean copyright or notions of originality are redundant or
copyright is unable to accommodate Guetta and other similar cases.
Quite the contrary, notions of originality provide a robust framework for
managing new technologies and the new forms of creativity that such
technologies facilitate.

5.1. Identifying the human author-in-the-loop
Against this emerging background, what we might label “AI literacy”
becomes vital. There is no turning back, and our society must find ways
to cultivate the ability to work with these technologies in a responsible
and effective manner. In order to better understand how to adjust the
existing legal frameworks to the world where generative AI technologies
are ubiquitous, it is important to understand in what ways those new AI
tools change the well-known creative process that copyright law aims to
incentivize and reward. In light of what we discussed about the creative
process where human authors use generative AI tools in Section 2 above,
we believe that in most cases, it is not very difficult to identify at which
stages of the creative process a human author is involved.
We also see how the unpacked notion of the creative process, which
we described in Section 2, provides a clear response to those who have
been questioning whether the notions of independent creation and
modest creativity are of any use in the age of generative AI. In the
copyright law literature, the idea of doing away with the requirement of
independent creation is not entirely new,63 and it seems to emerge again
in the context of generative AI. As explained previously, one of the key
functions of the “independent creation” requirement is to identify that
there was a human being who came up with an idea and created
something that is fixed in tangible form. Hence, we are of the opinion
that the notion “AI-generated” work is inaccurate and leads to confu­
sion; it is misleading because, as we showed in Section 2, there is always
a human/author in the loop, also in those cases when creators utilize
generative AI tools.
Curiously, the US Copyright Office has adopted a more cautious
approach on this point requiring artists to disclose which parts of a work
have been created using generative AI tools.64 Pursuant to this “promptbased approach”, the US Copyright Office ignores the creativity
contributed by the AI system and focuses on rewarding creativity
contributed by human creators, provided that human authors are able to
show how the series of prompts rise to meet the threshold of minimum
creativity.65
Although such an approach could be considered as a practical step
forward, it could be criticised from at least three possible angles. First,
until now, artists have never been required to disclose the tools used in
the creative process in copyright application forms in the US, but a view
seems to be gaining traction that now might be the time to reverse this
and adopt new requirements. One can argue whether generative AI is all
that different from other digital creation tools such as Adobe Photoshop

63
Christopher Buccafusco, ‘There’s No Such Thing as Independent Creation,
and it’s a Good Thing, Too’ (2023) 64 Wm & Mary L Rev 1617.
64
See Copyright Office Statement of Policy, 88 Fed Reg 16192 (16 March
2023)
<https://www.govinfo.gov/content/pkg/FR-2023-03-16/pdf/202305321.pdf> accessed 29 August 2023: “In the case of works containing AIgenerated material, the Office will consider whether the AI contributions are
the result of ‘mechanical reproduction’ or instead of an author’s ‘own original
mental conception, to which [the author] gave visible form.’ The answer will
depend on the circumstances, particularly how the AI tool operates and how it
was used to create the final work.” For a critical account, see Van Lindberg, ’A
mixed decision from the US Copyright Office’ (Process Mechanics, 22 February
2023) <https://processmechanics.com/2023/02/22/a-mixed-decision-fromthe-us-copyright-office/> accessed 5 October 2023).
65
There is at least one lower court decision in the District court of Washington
DC which seems to have followed this approach. See Stephen Thaler v Shira
Perlmutter, Case 1:22-cv-01564-BAH; Riddhi Sethi & Isaiah Poritz, ‘AI-Gener­
ated Art Lacks Copyright Protection, D.C. Court Says (1)’ (Bloomberg Law, 18
August 2023) <https://news.bloomberglaw.com/ip-law/ai-generated-art-lac
ks-copyright-protection-d-c-court-rules> acccessed 30 August 2023; Heather
Whitney, ‘Court Says No Human Author, No Copyright (but Human Authorship
of GenAI Outputs Remains Uncertain)’ (Technology & Marketing Law Blog, 22
August 2023) <https://rb.gy/7hmaz> acccessed 30 August 2023.

5.2. Does the lawfulness of training data affect originality?
An important complicating factor in the case of generative AI is the
direct dependence of the AI systems on aggregated data used to train the
66
See comments by Katrina M Kershner, Paulius Jurcys, ‘Creativity in the Age
of AI’ (YouTube, 15 May 2023) <https://www.youtube.com/watch?v=9q
oY19B6MJk> accessed 30 August 2023.
67
Article 5(2) of the Berne Convention states, “[t]he enjoyment and the ex­
ercise of [the copyright owner’s] rights shall not be subject to any formality.”
For a broader discussion, see Jane C Ginsburg, ‘Berne Forbidden Formalities
and Mass Digitisation’ (2016) 96 B U L Rev 745; David R. Carducci, ‘Copyright
Registration: Why the U.S. Should Berne the Registration Requirement ’ (2020)
33 Ga St U L 873.
68
Lemley, supra n 61.
69
See e.g., Mark Rose, Authors in Court: Scenes from the Theater of Copyright
(Harvard Univesity Press, 2016). For an overview of how technologies and
underlying business models have affected the music industry, see Allen Bag­
frede & Cecily Mak, Music Law in the Digital Age (Berklee Press 2009).

10

M. Fenwick and P. Jurcys

Computer Law & Security Review: The International Journal of Technology Law and Practice 51 (2023) 105892

whether generative AI models are used in a corporate environment by
employees in enterprises. It is easy to envisage several different sce­
narios involving business, which require further discussion. For
example, where enterprises train their own models based on the com­
pany’s own data (for example, an architecture or interior design firm
training its own image generation model). In such a case, the costs
should be internalized by the firm. Another case, when one firm uses
another firm’s generative AI platform, a contractual arrangement be­
tween the parties might be necessary, with companies relying on in­
surance to protect against any potential legal or business risks.
5.3. Policy choices in fringe cases
Another possible example where the issue of so-called “AI author­
ship” is raised relates to content generated from snippets of videos
captured by cameras embedded in various IoT devices (e.g., Ring
doorbell cameras or smart pet feeders such as Furbo). Such smart IoT
devices are initially installed by their owners who buy and place these
devices in their preferred locations: smart doorbells with cameras are
usually installed at the entrance door, while pet feeders are usually
positioned in the location of the room where the camera is able to
capture the “best view” of the space. Such smart IoT devices also have an
accompanying application, which users download onto their mobile
phones and can “opt-in” to get regular notifications and stitched videos
capturing the highlights of the day, a week, or a month.
The legal question is whether such content is copyrightable or not?
And, if so, who owns the content? The device maker? The device owner?
Nobody?70
To address these questions, we would like to make two observations.
First, the videos that are captured, stored, and processed by companies
selling such “smart” IoT devices should not be considered as content that
is “autonomously generated by AI”. While it is true, that such videos are
captured by video cameras that automatically turn on when movement
is detected, such snippets or compilations thereof are a result of sensors
and software that are programmed to perform a specific function, i.e., to
recognise, categorize, and stitch the snippets together. Although some
might potentially turn out to be relevant, interesting, funny, or news­
worthy, such uses of smart IoT devices equipped with motion recogni­
tion sensors and night-vision cameras are not really at the core of
copyright.
Second, it is a matter of policy choice whether such content is
copyrightable or should be protected under certain contractual ar­
rangements between the device manufacturer and the owner/user of the
device. Notably, there is a software layer that combines computer vision
and data labelling technologies to recognize, categorize, and stitch the
snippets of content together. From an institutional perspective, the

Fig. 3. Situating creativity.

AI models. One question that needs to be addressed is whether the use of
publicly available data for training purposes is justifiable or not. More
precisely, we need to ask whether the reliance on such data by genera­
tive AI is sufficiently different from earlier technologies to justify
excluding the works that are created using generative AI tools from the
scope of copyright protection.
Our intention is not to answer this question here but merely to
provide greater clarity and precision to the issues that need to be
resolved as we move forward. It is important that this question of
training data does not “crowd out” the discussion about the key justi­
fications of copyright law and originality; questions of copyright should
not be reduced to this issue of the data used to train underlying models
that power AI solutions.
This danger seems particularly unfortunate when combined with an
account that locates the key moment of creativity at the point where the
black box of the AI systems generate content. A privileging of this aspect
of the creative process, seems likely to result in a myopic emphasis on
the status of the training data, whereas a more nuanced account of
creativity shifts the focal point of the discussion towards the issue of
originality and human authorship explored here. And just to reiterate,
this is not to deny the importance of these questions, merely to highlight
how the black box moment is only one – albeit very important stage – in
a more nuanced and complex process (Fig. 3).
Another distinct question that we would like to highlight here relates
to the question of whether the legality of the use of publicly available
data for training purposes should be included in assessing the originality
of the output created by the user of the generative AI platform. More­
over, and crucially, when we talk about consumer-facing AI platforms
like Chat-GPT or Midjourney, it seems unfair that the question of the
lawfulness of the use of training data, in general, is added to the copy­
rightability assessment of an individual work created by an individual
using that generative AI system. More specifically, the burden (and cost)
for sorting out the legality of the training data conundrum should be
placed on the shoulders of the platform providing the generative AI
system rather than the individual user that merely used it as one element
of the creative process as described in Section 2 above.
A final consideration as to the relevance of the training data is
whether the generative AI tools are used by an individual user/creator or

70
By way of illustration, the Ring Terms of Service provide that “You are
solely responsible for all of your Content (including Content you share through
the Ring Neighbors feature or application). “Content” means all audio, video,
images, text, or other types of content captured by Products or provided to us
(including content posted by you) in connection with the Services. You repre­
sent and warrant that:(a) you own the intellectual property rights in Content
posted by you or otherwise have the right to post the Content and grant the
license set forth below, and (b) the posting and use of your Content on or
through the Services does not violate the privacy rights, publicity rights,
copyrights, contract rights, intellectual property rights or any other rights of
any person.” <https://ring.com/terms> accessed 29 August 2023.The Terms
and Conditions of Furmo, a camera-equipped smart pet feeder are less clear:
“Our Service may allow you to publicly share and otherwise make available
certain information, graphics, videos, or other material (“Content”), including,
without limitation, Content captured through or in connection with your use of
the Services. … You are solely responsible for the Content that you publicly
upload, transmit, share or otherwise disseminate on and through the Services,
including its legality, reliability, and appropriateness.” <https://furbo.
com/us/pages/terms-conditions> accessed 30 August 2023.

11

M. Fenwick and P. Jurcys

Computer Law & Security Review: The International Journal of Technology Law and Practice 51 (2023) 105892

responsibility to decide on copyright ownership may lie with either (a)
the policymaker, who has to make a decision on this issue, or (b) the
camera maker, who sets forth the solution in the terms of use, which the
buyer of the device must agree to and live with. Such a policy choice
with regard to copyrightability and the allocation of initial title to the
content captured by smart IoT devices could be deemed as a layer of a
higher-level normative framework. The debate about content captured
by sensor-equipped cameras, such as capturing cats, dogs, and mailmen
around houses, distracts us from the broader conversation about the
purpose of copyright, which traditionally centers around human
creators.
More specifically, The Firefighter case in the US,71 where a gas
maintenance station employee captured a photo of a fireman carrying a
baby out of a destroyed building following an explosion in Oklahoma
City provides an illustration of the policy choice at stake. In this case, the
question was whether the photo was a work made for hire, or whether it
was a sole-authorship work? Situations might usefully be framed as law
and economics issues: Who is in a better position to utilize or monetize
the photo, the employee or the employer? As such, they might be best
thought of as case-by-case decisions, and it is impossible for the regu­
lator to anticipate all such scenarios. On a more general note, we again
reiterate the view that videos captured by security cameras are not
“works that are autonomously generated by AI.” Shifting attention to
that aspect to answer the question of whether it is copyrightable seems,
once again, overly reductive and simplistic.

As such, it is important that new concepts and terminology are
developed that more accurately characterize the forms of creativity
emerging in our rapidly evolving digital culture. We prefer the idea of
“co-creation of works with AI tools” as this type of expression seems to
capture the hybrid character of the creative process that is happening in
the generative AI space right now. We believe that our effort to unfold
the five dimensions of human authorship in creating works by using
generative AI tools (i.e., conception, prompting, generation, refinement
and deployment) can shed new light on the legal concept of human
authorship which during the 19th and 20th centuries increasingly shif­
ted focus from the author to the work.72
In this context, we might borrow Lawrence Lessig’s term “remix” and
think about how it might be deployed in an age of generative AI.
Crucially, this concept points to an essential feature of digital culture,
namely the centrality of quotation and iteration, and our struggles with
imagining the future and developing new artistic forms.73 Perhaps, the
only or, at least, best response to a culture where we struggle to imagine
the future is remixing and recycling – a self-conscious, often ironic,
revisiting and repackaging of the past – and in that respect AI tools offer
a contemporary and timely means to navigate the impasse of the current
historical moment.
From a legal perspective, our purpose here has been to suggest that
the low threshold of creativity in US copyright law is easily met in a case
such as David Guetta’s. Nevertheless, further research is needed to
analyse more specific use cases involving music, voice, multiple gener­
ative art segments, as well as the use of specific applications across these
different media. As such, we need to have an open and enlightened
discussion about hard or fringe cases, where there may well be far less
human creativity than discussed here, and a more restrictive approach
may be justified.
Our conclusion is that when it comes to genuine creators, who are
using AI systems as innovative and unique tools to push the boundaries
of their creativity, copyright law remains one of the primary mecha­
nisms to facilitate them in this pursuit. Exaggerated claims about the
role and capacity of AI in creation and possible flaws in the training data
of such models should not be used as a mechanism or justification to
curtail the discussion, stifle creativity, and limit opportunities to use AI
tools in pushing digital culture forwards and in new interesting
directions.

6. Conclusions
The main claim of this paper is that current copyright law in the US
provides a durable framework that can and should manage a Guetta-like
case. However, such an accommodation does raise several novel issues
and questions, first, about the relationship between humans and ma­
chines in the creative process and, secondly, about the shifting character
of the network of relevant stakeholders implicated in this process.
Our main argument here seeks to clarify the notion of an AIgenerated work – as used in many provocative recent headlines. Our
point is to emphasize that there is no such thing as purely AI-generated
work, at least not yet, and that there is always a human/author in the
loop of the creative. The idea of “AI-generated work” is overly simplistic
and potentially misleading and does a disservice to those seeking to
experiment creatively with generative AI systems. Even more so, the
notion of “AI-generated work” implies that AI can act completely
autonomously in generating AI content - something that is not factually
true. As we try to show in the paper using the Guetta example, human/
author involvement usually occurs either at the input (prompting) or
output stage; and the creation of somewhat creative works usually re­
quires human intervention and refinement of interim iterations of a
work.

A B S T R A C T

Keywords:
Artificial intelligence technology
Traditional Chinese opera
Stage engineering
Bivariate t-value check
Chinese opera

To combine traditional Chinese opera with modern intelligent technology, we use Artificial In­
telligence (AI) technology to conduct innovative research on traditional stage design. In this
paper, we mainly focused on the production of scientific and technological equipment for stage
design, the cooperation between intelligent technology and opera culture creation, and the stage
design effect and the overall stage effect after the introduction of AI technology. We elaborate on
the background of AI in traditional opera art creation space and associate it with the internet
collaborative creation from multiple angles through the survey as satisfaction, staff salary dif­
ference, calculation comparison, etc. The performance analysis study reveals that combining
traditional Chinese opera with AI resulted in significant performance efficiency compared to
conventional techniques.

1. Introduction
Each scene in traditional Chinese opera art contains the five components of "gold, wood, water, fire, and earth" cooperating, among
which the stage of the earth system acts as the carrier, the gold soldier Ge, fire pottery, water system apparel, and wood furnishings.
According to Mei Chen [1], the clothes and items directly connected to the performers were the first to appear in the performance
before the set progressively arose. Every scene on stage, props, costumes, and even the curtain are carefully studied; each opera has its
place, perhaps a table, sometimes a cup; even such small details, like the performers on stage, are indispensable, are closely related,
and together staged a gorgeous visual feast for the audience; this is the charm of traditional opera.
Randolph [2] revealed that traditional opera art is more than just props and sets; it is used to foil the performer’s green leaves, a sad
are hidden in it, and sometimes it changed, becoming the focus of the normal stage, such as according to Mr. Lao She novel of the same
name, the camel Xiang Zi in the set design, the old Beijing city gate and city walls, metaphor the old China will collapse, the deep
connotation of the audience deeply as
Tallón Ballesteros [3] stated that in the early traditional opera stage engineering, pure handwork was generally used to create
various props, and the materials were greatly consumed, time-consuming, and laborious, resulting in the expensive price of props and
the rare quantity, and the production is difficult to supply large-scale commercial performances, which is also the reason for the
high-ticket price of song-and-dance duet popular in the Northeast [3].
The biggest difference between the song-and-dance duet popular in the Northeast and the adaptation is to pull scene requirements
with a full set of opera stage facilities, and the play can use more modern stage elements, such as Light Emitting Diode (LED) display

This paper is for special section VSI-sacs Reviews were processed by Guest Editor Dr. Antonio Zuorro and recommended for publication.
E-mail address: mohayasr6819@gmail.com.
https://doi.org/10.1016/j.compeleceng.2022.108395
Received 23 June 2022; Received in revised form 7 September 2022; Accepted 12 September 2022
Available online 24 September 2022
0045-7906/© 2022 Elsevier Ltd. All rights reserved.

Computers and Electrical Engineering 103 (2022) 108395

Z. Yang

instead of cloth embroidery background, even with modern clothing instead of traditional Peking Opera costumes, etc. Section 2
discusses Artificial Intelligence (AI) technology for the opera art environment. Section 3 discusses multi-entity collaboration in the
formation of theatrical culture in the Internet era. Section 4 discusses the stage design effect and the overall stage effect following the
implementation of AI technology. The conclusion is presented in Section 5.
2. AI Equipment of opera art space
2.1. Existing AI equipment for opera stage choreography
Three Dimensional (3D) Printer: Ding and Ng [4] said that 3D printing is a type of fast-forming technology, also known as additive
manufacturing, that is based on digital model files and uses adhesive materials such as powder metal or plastic to produce products
layer-by-layer printing. Potter Phillip [5] revealed that 3D printing is typically implemented using a digital technology material
printer, which works on a similar principle to a standard printer but with a few differences. Standard printer print material is paper and
toner, whereas 3D printer print material is a variety of metals, ceramics, plastics, and so on. And, unlike a regular printer, which prints
two-dimensional planes on paper, a 3D printer prints three-dimensional objects. This technique was sometimes referred to as 3D stereo
printing technology. According to Najarian [6], 3D printers were frequently employed in the manufacture of models in mold
manufacturing and industrial design and were subsequently gradually utilized in the direct fabrication of various items, with parts
produced using this technology. Jewelry, footwear, industrial design, architecture, engineering and construction, automotive, aero­
space, dentistry, and medical sectors all use the technology. Faraz [7] was aware that Charles Hull, an American scientist, invented the
first commercial 3D printing process in 1986. Over the next four decades, experts from around the country dedicated themselves to
inventing 3D printers for use in a variety of areas. 3D printers are not unique in today’s science and technology, since they can be found
in all aspects of life.
Six-axis processing lathe (processing center): Tallón Ballesteros [3] stated that clothe processing is part of machining and that there
are primarily two types of processing: one is to fix the blade and process the unformed workpiece in the rotation; the other is to fix the
piece through high-speed rotation, horizontal and longitudinal movement of the blade (frame). Drill head, hole expansion drill, hinge
knife, silk cone, plate teeth, and rolling tools on the lathe is the most often used type of machine tools in mechanical production and
repair industries, and it is mostly used for processing shafts, discs, covers, and other workpieces with rotational surfaces.
Sewing machine with Computer Numerical Control (CNC) embroidery: According to Mei Chen [1], an embroidery machine is a special
sewing machine that can be directly through the Internet embroidery design, construct the pattern, and then let the machine auto­
matically work for embroidery, abandoning the complicated steps of manual operation, and the embroidery machine can be operated
by only one person through electronic modeling, convenient method, and easy operation. And the design generated is delicate and
silky, much like hand embroidery weaved.
Fig. 1 Shows the path of AI set in the stage design space. It consists of the below components.
• Computer 3D modeling: A 3D model made using a computer;
• Graphic Artist Designer: Art designs a 3D model;
• 3D printing: Printing was performed using the 3D model designed to produce;
• 3D cutting:Cut off the printed items;
• 3D clipping:The cleaved 3D model was trimmed;
• Wax mold:Wax xed items that have been 3D printed;
• Replace wax:Remove the wax particles from the item;
• Computer embroidery:Texture analysis is used to import the embroidery into an embroidery sewing machine for AI embroidery;

Fig. 1. Application path of AI set in the stage design space.
2

Computers and Electrical Engineering 103 (2022) 108395

Z. Yang

• NC sewing:Do the embroidery sewing machine for the embroidery processing;
• NC sewing:Ironing of the obtained embroidery products;
• Fine grinding: The resulting products will be finely processed;
• Coloring/assembly: Color the products already obtained and;
• Forming:Get the product for use.
Fig. 1 depicts the combination of conventional opera stage engineering with AI via computer plane design and 3D stereo modeling.
Such enormous objects may be detailed and polished by using a 3D printer and 3D cutting. The coloring may then be completed, and
minor props can be cut. The CNC embroidery machine is used to process iron-on cloth art goods. The six-axis processing center will
handle the whole operation.
2.2. Use of AI to reproduce traditional props
Tilt photography in three dimensions, based on a revolving platform. Slant photogrammetry was employed by Ahirwal [8]. Slant
photogrammetry is a novel technique developed in recent years, allowing for simultaneous photography from numerous angles using
several sensors on the same aircraft platform. Tilt photography means that he can capture measurements at a 45˚angle at a low height,
allowing for higher-resolution aerial photos. Unlike standard projections, they can not only shoot from a vertical viewpoint but also
five or more angles, considerably improving data collecting efficiency. In this work, reference photos were used for stage photography
and 3D stereo modeling.
Randolph [2] demonstrated texture analysis by acquiring images and extracting processing techniques to extract texture feature
parameters. By integrating technology with an embroidered sewing machine, you may learn the directional quantitative description of
the texture. Stage props can have the same texture as handcrafted props.
Fig. 2 shows the traditional prop engraving scheme of AI. It consists of below components.
• Tilt camera PTZ: Use the tilt photography cloud platform for photography;
• Smart 3D synthesis: The collected images were subjected to 3D synthesis;
• 3D prop model: The resultant 3D image model was processed specifically;
• Cutting drive code: The resulting model was cut and made;
• Printer driver code: Part of the 3D model was printed;
• Laser scanning: Items that require embroidery for laser scanning;
• Texture analysis: The results of the props were scanned for texture scan analysis;
• Pin analysis: A more detailed analysis of the texture analysis;
• Sewing machine drive code: large areas of props were made for sewing; and
• Embroidery machine driver code: More detailed needle embroidery for embroidery production.
To make AI engraving props to achieve the purpose of traditional handmade props, large props using tilt photography platform for
multi-angle shooting to collect props related data, data input into the computer, using smart3D data synthesis, and build 3D props
model, get large props electronic mold, using 3D printer cutting and printing, finally color assembly into large props. Small props
principle is similar, first using laser scanning, scanning its texture structure, and then use computer texture analysis, then use smart3D
data synthesis, and build 3D props model, then use 3D printer cutting and printing, details embroidery uses needle analysis, needle
sequence code input, can use digital embroidery sewing machine embroidery to refine details complete props.
3. Multi-entity collaboration of drama culture creation in the internetþ Era
The Internet+ economic model is based on the comprehensive division of labor and tight coordination of tiny business organi­
zations, which is equally relevant in drama stage artworks. According to traditional Chinese opera art, each scene includes five
components that collaborate: "gold, wood, water, fire, earth." The stage project is likewise produced following its five elements.
Fig. 3 shows the Internet+ opera cluster creation system. It consists of below the components.

Fig. 2. Traditional prop engraving scheme of AI.
3

Computers and Electrical Engineering 103 (2022) 108395

Z. Yang

• Drama dance planning: Opera stage art for the overall stage design;
• 3D modeling: Based on the 3D model being built as required;
• 3D design: Design and production of the 3D model were performed;
• Wumei weapon processing: Make the weapons needed for the stage;
• Wumei furniture processing: Make the furniture needed for the stage;
• Dance costume processing: Make the costumes needed for the stage;
• Wumei porcelain processing: Make the porcelain needed for the stage; and
• Dance curtain processing: Make the curtain needed for the stage.
Fig. 3 depicts the Internet and opera culture’s combined creation. The traditional mode’s drama stage is entirely hired by its troupe.
The stage props will be changed after each performance, using significant personnel and material resources. And, using the opera art
planning draught, a new AI mode connected to the Internet may develop 3D modeling, as well as stage scene furniture, weapons,
clothes, porcelain, and curtains based on the five aspects of ancient China, as categorized by many intelligent technology businesses.
Unified the opera stage personnel assembly and planning, resulting in cost savings and a reduction in production time.
4. Impact analysis using AI technology
4.1. . Bivariate t-calibration algorithm
Elsevier [9] had told that the t-test, also known as the student t-test (Student’s t-test), was mainly used for a normal distribution
with a small sample content (e. g., n < 30) and the overall standard deviation is unknown. The t-test is to infer the probability of the
difference occurring by the t-distribution theory, and thus to compare whether the difference between the two averages is significant.
The t-value formula:
t=

|X − μ0 | X − μ0
= √̅̅̅
SX
s/ n

(1)

where, t represents Bivariate t-value test, X represents variables required for the test, μ0 represents fixed constant, SX represents the
mean synthesis of the variables tested and n represents the number of variables tested.
4.2. P-value
Tinnirello [10] had used that the P-value. The P-value is the probability that results are more extreme than the resulting sample
observations appear when the null hypothesis is true. If the P-value is small, the probability of the null hypothesis is small, and the
smaller the P-value, the more significant the results. In this study, the setting was considered significantly significant between the two
data groups when T < 10.000 and P < 0.01. Throw a coin 20 times with 14 frontal appearances, drawing the occurrence probability of
the event as a normal distribution, then the one-sided P-value of the sample was calculated as follows:
Prob(14 heads) + Prob(15 heads) + … + Prob(20 heads)
[( ) ( )
( )]
1
20
20
20
60, 460
+
+…+
=
≈ 0.058
20
14
15
20
1, 048, 576
2

(2)

where, Prob represents get the required situation.
4.3. Practitioner income survey
The actors include wrist horns such as ugliness, gongs, drums, silk tube musicians, and dance actors. The backstage includes stage
props, the director group, production group, production, and group staff [11–17]. This study was sampled in various Peking Opera
troupes around Beijing, with some actors, backstage staff, and producers’ salaries and compared, and recorded in Table 1:

Fig. 3. The Internet + opera culture creation system related to the stage choreography.
4

Computers and Electrical Engineering 103 (2022) 108395

Z. Yang

• Traditional mode: Salary and profit of each staff member in the traditional mode;
• AI model: Salary and profit of each staff member in the AI mode;
• The average price: Average fare in two different modes;
• The average daily wage for an actor: The average salary of an actor in both modes;
• Background daily wage: Average salary for background staff in both modes; and
• Yield of the producer: The profits that the producers reap in both modes.
According to the statistics in Table 1, the conventional mode’s ticket price is about six times that of the AI mode, but the daily
compensation of actors is around the same. When combined with the high daily wage in the background and the producer’s revenue,
the traditional mode’s ticket price income is largely utilized for the manual backdrop set and the material cost of manual production. In
contrast, the AI model resulted in much-reduced ticket prices and lower wages for background workers [17–24].
Fig. 4 shows below factors:
• The average daily wage for an actor: The average salary of an actor in both modes;
• Background daily wage: Average salary for background staff in both modes; and
• Yield of the producer: The profits that the producers reap in both modes.
The ratio increases the difference between the conventional and AI mode means in Table 1 and Fig. 4. The t and P are calculated
using the results of a bivariate T-test run by the Statistical Package for Social Sciences (SPSS) analytic program on two different types of
data. When T < 10.000 and P < 0.01, a statistically significant difference between the two data groups were considered.
4.4. Organizational efficiency analysis
Under the premise of the fixed script and complete rehearsal, a commercial performance of about 2 h of opera needs to conduct
stage confirmation, market publicity, stage processing and deployment, stage test stage, and other preparatory processes in advance.
After the performance, dismantle the stage props, restore the stage and return the rental equipment are needed. This study also
investigated the staff of Peking Opera troupes around Beijing and sorted out in Table 2:
The factors in Table 2 are summarized below.
• Traditional mode: Time and preparation efficiency required in the traditional model;
• AI model: Time and preparation efficiency required in the AI mode;
• Performance times:Performance time required in both modes;
• Preparation time:Preparation time required in both modes;
• End time:End time required in both modes;
• Salary cycle:Salary counting cycle in both modes; and
• Preparation efficiency:Preparation efficiency in both modes.
In Table 2, the increase calculation is the ratio of the difference between the traditional mode mean and the AI mode means. The T
and P are obtained from the results of a bivariate T-test performed by the SPSS analysis software on two different modes of data. A
significant statistical difference between the two data groups was considered when at T < 10.000 and P < 0.01.
4.5. Audience and practitioner satisfaction questionnaire
After investigating the performance efficiency and the compensation of all parties, this study investigated the satisfaction of the
audience in the surveyed area and their practitioners with the opera performance using the AI mode, and calculated in Table 3.
The factors in Table 2 are summarized below:
• AI model: The satisfaction of the audience, practitioners and producers with the stage in the AI mode;
• Audience degree of satisfaction: Audience satisfaction with the stage in both modes;
• Audience complaint rate:Audience complaint rate about the stage in both modes;
• Performer degree of satisfaction:Performer satisfaction with both modes;
Table 1
Compensation and income calculation of actors, backstage and producers (Data source: The author calculated the proceeds).
Grouping

The average price
yuan/RMB

The average daily wage for an actor
yuan/RMB

Background daily wage
yuan/RMB

Yield of the producer
%

traditional mode
AI mode
t
P

1827.5
363.8
0.136
0.002

826.5
967.3
8.283
0.008

1512.5
846.9
3.152
0.006

12.6
18.6
6.351
0.007

5

Computers and Electrical Engineering 103 (2022) 108395

Z. Yang

Fig. 4. Visualization of the salary and income survey of actors, backstage, and producers.
Table 2
Performance organization efficiency test table (Data source: The author calculated the proceeds).
grouping

Performance times
h

Preparation time
d

End time
d

Salary cycle
d

Preparation efficiency
%

Traditional mode
AI mode
t
P

2
2
99.999
0.000

5.0
2.1
3.752
0.006

1.3
1.1
1.784
0.004

6.3
3.2
3.526
0.006

1.39
2.78
3.471
0.006

Table 3
Satisfaction survey results table (Data source: The author calculated the proceeds).
GROUPING

audience
degree of satisfaction

complaint rate

performer
degree of satisfaction

backstage
degree of satisfaction

Producer
degree of satisfaction

traditional mode
AI model
t
P

63.7
70.2
0.658
0.003

6.3
3.8
3.239
0.006

68.4
75.5
1.472
0.004

57.4
70.8
1.937
0.004

80.9
94.3
1.653
0.004

• Backstage degree of satisfaction:Background staff satisfaction with both models;
• Producer degree of satisfaction:Investor satisfaction with both models;and
• Traditional mode: The traditional mode satisfies the audience, practitioners and producers with the stage.
Fig. 5 and Table 3 show the influence of the AI mode on the stage project. Both the preparation and completion times are
significantly shorter than the typical manner of a production stage project. At the same time of performance, the AI preparation time is
considerably less than the classic mode preparation time. In other words, AI enhances the overall efficiency of stage preparation,

Fig. 5. Visual figure of the satisfaction survey.
6

Computers and Electrical Engineering 103 (2022) 108395

Z. Yang

allowing for more stage performances to be prepared at the same time.
According to Table 3, the audience response to two various types of opera stage response is not different, but actor and background
staff satisfaction differs. The classic-style stage scenario needs a large number of people and material resources, particularly in the
background crew. And, while background staff salaries are decreased in AI mode, the cost of material resources is also significantly cut.
Similarly, the AI model has a favorable impression among the producers. Although the ticket price has been cut, the efficiency has been
substantially increased, as have the producers’ returns.
5. Conclusion
The AI system takes data from cameras, GPS, the car’s radar, and cloud services to generate control signals that allow the vehicle to
function. AI is a broad tool that enables people to reimagine how we combine information, analyze data, and apply the resultant
insights to make better decisions—and it is already impacting every aspect of life. We presented the AI mode of opera culture
development mode and production process, and compare it with the traditional Chinese traditional opera development mode. We
studied the AI mode using 3D printing technology, CNC embroidery sewing technology, tilt photography cloud platform, and other
technology opera stage production. Different from the traditional mode of the opera production process, AI mode according to the way
of five elements of the required props production process, make the production process clear, more convenient, and fast. Compared
with the traditional mode of the opera stage, all walks of life also appreciate the opera stage of new AI more. Large props employed a
tilt photography platform for multi-angle shooting to acquire props-related data to create AI engraved props that perform the same
purpose as traditional hand-made props. After entering the data into the computer, smart3D data synthesis had utilized to create a 3D
model of the props. Large props have then given an electronic mold cut and manufactured using a 3D printer. Small props function in
the same way. We began by scanning its texture structure with a laser scanner. The computer had then used to examine the texture.
Following that, we created a 3D model of the prop using smart3D data synthesis. In embroidery, needle analysis and needle sequence
code input were employed. To improve details and complete props, we employed a digital embroidered sewing machine.
Data availability
The data underlying the results presented in the study are available within the manuscript.
Funding statement
This work was supported by Shanxi Philosophy and Social Science Foundation Project: Research on the Inheritance and Innovation
of Shanxi Opera Helmet Making Technique in the Context of Intangible Cultural Heritage (Project No. 2019B356). The fourth batch of
projects funded by young academic leaders of taiyuan normal University.
Declaration of Competing Interest
There is no potential conflict of interest in our paper, and all authors have seen the manuscript and approved to submit to your
journal. We confirm that the content of the manuscript has not been published or submitted for publication elsewhere.
Data availability
No data was used for the research described in the article.
